{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import itertools\n",
    "import json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import utils as ut\n",
    "import LIM_class\n",
    "from LSTM_enc_dec import *\n",
    "\n",
    "plt.style.use(\"../plotting.mplstyle\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "data = xr.open_dataset(\"./data/ts_Amon_CESM2_piControl_r1i1p1f1.nc\")[\"ts\"]\n",
    "#data = xr.open_dataset(\"./data/zos_Amon_CESM2_piControl_r1i1p1f1.nc\")[\"zos\"]\n",
    "#data_old = xr.open_dataset(\"./data/ssta_1950_2021.nc\")[\"ssta\"]\n",
    "mask = xr.open_dataset(\"./data/sftlf_fx_CESM2_historical_r1i1p1f1.nc\")[\"sftlf\"]\n",
    "\n",
    "#14400 orginial size\n",
    "data = data[:, :, :]\n",
    "\n",
    "data = ut.apply_mask(mask, data)\n",
    "#print(\"Data : {} + shape {}\".format(data, data.shape))\n",
    "\n",
    "data_anomalies = ut.calculate_monthly_anomalies(data)\n",
    "#print(\"Month mean : {} + shape : {}\".format(data_anomalies, data_anomalies.shape))\n",
    "\n",
    "data_cropped =ut.crop_xarray(data_anomalies)\n",
    "#print(\"Data cropped : {} + shape : {}\".format(data_cropped, data_cropped.shape))\n",
    "\n",
    "\n",
    "pca_10 = ut.SpatioTemporalPCA(data_cropped, n_components=20)\n",
    "#pca_10 = ut.SpatioTemporalPCA(data_anomalies, n_components=20)\n",
    "eof_10 = pca_10.eofs()\n",
    "pc_10 = pca_10.principal_components()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from LSTM_model import *\n",
    "#\n",
    "# # Set random seed for reproducibility\n",
    "# torch.manual_seed(42)\n",
    "#\n",
    "def hyperparameter_training_loop(data, hyperparams):\n",
    "\n",
    "    # Generate all possible combinations of hyperparameters\n",
    "    combinations = list(itertools.product(*hyperparams.values()))\n",
    "\n",
    "    overall_best_model = {\"hidden_size\": None,\n",
    "                         \"learning_rate\": None,\n",
    "                         \"num_epochs\": None,\n",
    "                         \"loss\": float('inf')}\n",
    "\n",
    "    # Iterate over each hyperparameter combination\n",
    "    for i, params in enumerate(combinations):\n",
    "        print(f\"Testing parameter combination {i+1}/{len(combinations)}: {params}\")\n",
    "\n",
    "        # Create a new model with the current hyperparameters\n",
    "        hidden_size = params[0]\n",
    "        learning_rate = params[1]\n",
    "        num_epochs = params[2]\n",
    "        num_layers = params[3]\n",
    "        sequence_length = params[4]\n",
    "        batch_size = params[5]\n",
    "\n",
    "        dataloader = create_dataloader(data, sequence_length=sequence_length, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = LSTMNetwork(1, hidden_size, num_layers)\n",
    "        losses = train(model, dataloader, num_epochs, learning_rate)\n",
    "\n",
    "        # Save the model and hyperparameters to a file\n",
    "        result = {\n",
    "            'hyperparameters': {\n",
    "                'hidden_size': hidden_size,\n",
    "                'learning_rate': learning_rate,\n",
    "                'num_epochs': num_epochs,\n",
    "                'num_layers': num_layers,\n",
    "                'sequence_length': sequence_length,\n",
    "                'best_loss': losses[-1],\n",
    "                \"losses\": losses\n",
    "            }\n",
    "        }\n",
    "        if losses[-1] < overall_best_model[\"loss\"]:\n",
    "            overall_best_model[\"hidden_size\"] = params[0]\n",
    "            overall_best_model[\"learning_rate\"] = params[1]\n",
    "            overall_best_model[\"num_epochs\"] = params[2]\n",
    "            overall_best_model[\"loss\"] = losses[-1]\n",
    "            overall_best_model[\"losses\"] = losses\n",
    "\n",
    "        filename = f\"./model_trained_lstm/fnn_model_{i+1}.pt\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(result, f)\n",
    "\n",
    "        print(f\"Saved model and hyperparameters to {filename}\\n\")\n",
    "\n",
    "    return overall_best_model\n",
    "#\n",
    "#\n",
    "# # Create the DataLoader for first principal component\n",
    "# data = np.array(data)[0]\n",
    "# print(\"Data : {} + shape: {} + type: {}\".format(data, data.shape, type(data)))\n",
    "#\n",
    "# # Hyperparameter search space\n",
    "# hyperparams = {\n",
    "#     'hidden_size': [32],\n",
    "#     'learning_rate': [0.001, 0.002],\n",
    "#     'num_epochs': [1000],\n",
    "#     'num_layers': [3],\n",
    "#     'sequence_length': [5],\n",
    "#     'batch_size': [1]\n",
    "# }\n",
    "#\n",
    "# #Train the model\n",
    "# #train(model, dataloader, num_epochs, learning_rate)\n",
    "# best_model = hyperparameter_training_loop(data, hyperparams)\n",
    "#\n",
    "# print(f\"Best model: {best_model}\")\n",
    "# plot_loss_evolution(best_model[\"losses\"], np.arange(0,best_model[\"num_epochs\"], 100, dtype=int), best_model[\"learning_rate\"], best_model[\"hidden_size\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data : [[  3.082717     7.58872     11.522211   ...   2.1110816   -2.2536314\n",
      "  -10.422921  ]\n",
      " [ 15.300908    13.185972     6.481787   ...  26.23216     23.710655\n",
      "   19.59892   ]\n",
      " [ -1.5274546    4.64411      4.499988   ...  -9.4210825  -11.31246\n",
      "  -15.245653  ]\n",
      " ...\n",
      " [  0.07792819   1.0995704    1.4193639  ...  -1.4664601    1.7521834\n",
      "   -2.5803611 ]\n",
      " [  0.8366144    2.314835     1.0267301  ...   0.29932857  -0.27528232\n",
      "   -0.15596846]\n",
      " [  0.8229446    0.4607976    0.8099255  ...  -1.9031905   -1.2379901\n",
      "   -1.0049288 ]] + shape: (20, 14400) + type: <class 'numpy.ndarray'>\n",
      "Input data : [[[ 3.08271694e+00  7.58871984e+00  1.15222111e+01  2.02901573e+01\n",
      "    2.70137196e+01  3.14075832e+01  4.32124710e+01  5.43983459e+01\n",
      "    6.27646065e+01  6.35853958e+01  6.44254684e+01  7.03778000e+01\n",
      "    7.13412628e+01  6.47799149e+01  5.62321281e+01  5.41466408e+01\n",
      "    4.06710472e+01  2.21597424e+01 -1.01463091e+00 -1.78049965e+01]\n",
      "  [ 1.53009081e+01  1.31859722e+01  6.48178720e+00  2.30049849e+00\n",
      "    1.75349474e+00 -6.57406092e-01 -9.28707242e-01 -5.42045164e+00\n",
      "   -6.63977480e+00 -7.52440166e+00 -9.25686264e+00 -4.37797117e+00\n",
      "   -4.50488997e+00 -5.75212812e+00 -1.38797477e-01  1.13901024e+01\n",
      "    2.83691692e+01  3.72372627e+01  3.48059196e+01  3.14343662e+01]\n",
      "  [-1.52745461e+00  4.64411020e+00  4.49998808e+00 -2.64983320e+00\n",
      "   -5.96516562e+00 -4.98770142e+00 -8.29640293e+00 -1.20457458e+01\n",
      "   -8.68928909e+00  1.83014131e+00  1.57618022e+00 -5.58384037e+00\n",
      "   -7.30926609e+00 -1.03106480e+01 -1.40667267e+01 -1.70529804e+01\n",
      "   -1.60504303e+01 -1.65349255e+01 -1.97992973e+01 -1.92302380e+01]\n",
      "  [-7.90364456e+00 -3.74645889e-02  1.85949111e+00  9.99462068e-01\n",
      "    1.31856298e+00  1.68999600e+00  3.21913195e+00  1.36649519e-01\n",
      "   -3.99433827e+00 -9.62414455e+00 -8.21875381e+00 -6.26499510e+00\n",
      "    1.88952339e+00  3.54166508e-01  4.16127503e-01 -2.47663522e+00\n",
      "    4.76234055e+00  1.18406305e+01  4.52725029e+00  4.61129475e+00]]\n",
      "\n",
      " [[ 1.53009081e+01  1.31859722e+01  6.48178720e+00  2.30049849e+00\n",
      "    1.75349474e+00 -6.57406092e-01 -9.28707242e-01 -5.42045164e+00\n",
      "   -6.63977480e+00 -7.52440166e+00 -9.25686264e+00 -4.37797117e+00\n",
      "   -4.50488997e+00 -5.75212812e+00 -1.38797477e-01  1.13901024e+01\n",
      "    2.83691692e+01  3.72372627e+01  3.48059196e+01  3.14343662e+01]\n",
      "  [-1.52745461e+00  4.64411020e+00  4.49998808e+00 -2.64983320e+00\n",
      "   -5.96516562e+00 -4.98770142e+00 -8.29640293e+00 -1.20457458e+01\n",
      "   -8.68928909e+00  1.83014131e+00  1.57618022e+00 -5.58384037e+00\n",
      "   -7.30926609e+00 -1.03106480e+01 -1.40667267e+01 -1.70529804e+01\n",
      "   -1.60504303e+01 -1.65349255e+01 -1.97992973e+01 -1.92302380e+01]\n",
      "  [-7.90364456e+00 -3.74645889e-02  1.85949111e+00  9.99462068e-01\n",
      "    1.31856298e+00  1.68999600e+00  3.21913195e+00  1.36649519e-01\n",
      "   -3.99433827e+00 -9.62414455e+00 -8.21875381e+00 -6.26499510e+00\n",
      "    1.88952339e+00  3.54166508e-01  4.16127503e-01 -2.47663522e+00\n",
      "    4.76234055e+00  1.18406305e+01  4.52725029e+00  4.61129475e+00]\n",
      "  [ 6.36035347e+00  8.22894764e+00  2.46226335e+00  2.89394999e+00\n",
      "    4.15182781e+00 -1.40019488e+00  1.58622611e+00  2.02821755e+00\n",
      "    6.18854046e-01 -4.64583063e+00 -5.90423727e+00 -5.97956665e-02\n",
      "   -4.71904248e-01 -5.23955297e+00 -5.69601393e+00 -5.50622416e+00\n",
      "   -3.17264128e+00 -7.30391645e+00 -1.18041277e+01 -9.46842384e+00]]\n",
      "\n",
      " [[-1.52745461e+00  4.64411020e+00  4.49998808e+00 -2.64983320e+00\n",
      "   -5.96516562e+00 -4.98770142e+00 -8.29640293e+00 -1.20457458e+01\n",
      "   -8.68928909e+00  1.83014131e+00  1.57618022e+00 -5.58384037e+00\n",
      "   -7.30926609e+00 -1.03106480e+01 -1.40667267e+01 -1.70529804e+01\n",
      "   -1.60504303e+01 -1.65349255e+01 -1.97992973e+01 -1.92302380e+01]\n",
      "  [-7.90364456e+00 -3.74645889e-02  1.85949111e+00  9.99462068e-01\n",
      "    1.31856298e+00  1.68999600e+00  3.21913195e+00  1.36649519e-01\n",
      "   -3.99433827e+00 -9.62414455e+00 -8.21875381e+00 -6.26499510e+00\n",
      "    1.88952339e+00  3.54166508e-01  4.16127503e-01 -2.47663522e+00\n",
      "    4.76234055e+00  1.18406305e+01  4.52725029e+00  4.61129475e+00]\n",
      "  [ 6.36035347e+00  8.22894764e+00  2.46226335e+00  2.89394999e+00\n",
      "    4.15182781e+00 -1.40019488e+00  1.58622611e+00  2.02821755e+00\n",
      "    6.18854046e-01 -4.64583063e+00 -5.90423727e+00 -5.97956665e-02\n",
      "   -4.71904248e-01 -5.23955297e+00 -5.69601393e+00 -5.50622416e+00\n",
      "   -3.17264128e+00 -7.30391645e+00 -1.18041277e+01 -9.46842384e+00]\n",
      "  [-2.66638160e+00  5.03649521e+00 -2.28837276e+00 -1.95964205e+00\n",
      "    5.28014302e-01  3.72030663e+00  3.70536971e+00  5.83707237e+00\n",
      "    8.22718811e+00  5.31808901e+00  5.97979212e+00  5.49358273e+00\n",
      "    5.33328247e+00 -5.41476297e+00 -8.39903927e+00 -2.93412256e+00\n",
      "    8.66362476e+00  7.32846642e+00  2.59407353e+00  5.17512417e+00]]\n",
      "\n",
      " [[-7.90364456e+00 -3.74645889e-02  1.85949111e+00  9.99462068e-01\n",
      "    1.31856298e+00  1.68999600e+00  3.21913195e+00  1.36649519e-01\n",
      "   -3.99433827e+00 -9.62414455e+00 -8.21875381e+00 -6.26499510e+00\n",
      "    1.88952339e+00  3.54166508e-01  4.16127503e-01 -2.47663522e+00\n",
      "    4.76234055e+00  1.18406305e+01  4.52725029e+00  4.61129475e+00]\n",
      "  [ 6.36035347e+00  8.22894764e+00  2.46226335e+00  2.89394999e+00\n",
      "    4.15182781e+00 -1.40019488e+00  1.58622611e+00  2.02821755e+00\n",
      "    6.18854046e-01 -4.64583063e+00 -5.90423727e+00 -5.97956665e-02\n",
      "   -4.71904248e-01 -5.23955297e+00 -5.69601393e+00 -5.50622416e+00\n",
      "   -3.17264128e+00 -7.30391645e+00 -1.18041277e+01 -9.46842384e+00]\n",
      "  [-2.66638160e+00  5.03649521e+00 -2.28837276e+00 -1.95964205e+00\n",
      "    5.28014302e-01  3.72030663e+00  3.70536971e+00  5.83707237e+00\n",
      "    8.22718811e+00  5.31808901e+00  5.97979212e+00  5.49358273e+00\n",
      "    5.33328247e+00 -5.41476297e+00 -8.39903927e+00 -2.93412256e+00\n",
      "    8.66362476e+00  7.32846642e+00  2.59407353e+00  5.17512417e+00]\n",
      "  [-2.74336123e+00  4.26574349e-01  4.61626142e-01 -1.68241465e+00\n",
      "   -3.45975184e+00 -6.21603918e+00 -4.84028339e+00  1.98533106e+00\n",
      "    4.80649900e+00  8.64783382e+00  8.87433910e+00  1.03173037e+01\n",
      "    6.96268606e+00  3.79392719e+00  6.88858569e-01 -1.25339150e+00\n",
      "    1.88161933e+00 -4.41954899e+00  2.18637061e+00  5.52071905e+00]]\n",
      "\n",
      " [[ 6.36035347e+00  8.22894764e+00  2.46226335e+00  2.89394999e+00\n",
      "    4.15182781e+00 -1.40019488e+00  1.58622611e+00  2.02821755e+00\n",
      "    6.18854046e-01 -4.64583063e+00 -5.90423727e+00 -5.97956665e-02\n",
      "   -4.71904248e-01 -5.23955297e+00 -5.69601393e+00 -5.50622416e+00\n",
      "   -3.17264128e+00 -7.30391645e+00 -1.18041277e+01 -9.46842384e+00]\n",
      "  [-2.66638160e+00  5.03649521e+00 -2.28837276e+00 -1.95964205e+00\n",
      "    5.28014302e-01  3.72030663e+00  3.70536971e+00  5.83707237e+00\n",
      "    8.22718811e+00  5.31808901e+00  5.97979212e+00  5.49358273e+00\n",
      "    5.33328247e+00 -5.41476297e+00 -8.39903927e+00 -2.93412256e+00\n",
      "    8.66362476e+00  7.32846642e+00  2.59407353e+00  5.17512417e+00]\n",
      "  [-2.74336123e+00  4.26574349e-01  4.61626142e-01 -1.68241465e+00\n",
      "   -3.45975184e+00 -6.21603918e+00 -4.84028339e+00  1.98533106e+00\n",
      "    4.80649900e+00  8.64783382e+00  8.87433910e+00  1.03173037e+01\n",
      "    6.96268606e+00  3.79392719e+00  6.88858569e-01 -1.25339150e+00\n",
      "    1.88161933e+00 -4.41954899e+00  2.18637061e+00  5.52071905e+00]\n",
      "  [-8.85981083e-01 -1.81991136e+00 -1.10945094e+00 -2.68760872e+00\n",
      "   -3.24439555e-01  2.95100689e+00  3.81925678e+00  4.60382032e+00\n",
      "    2.03551912e+00  3.94671798e+00  1.12440670e+00 -3.60248828e+00\n",
      "   -3.25774407e+00 -2.38989997e+00 -3.81289220e+00 -1.51723146e+00\n",
      "    2.84584570e+00  9.28518677e+00  2.06154180e+00  4.35232258e+00]]] + shape: (5, 4, 20) + type: <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [12], line 39\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# specify model parameters and train\u001B[39;00m\n\u001B[0;32m     38\u001B[0m model \u001B[38;5;241m=\u001B[39m LSTM_seq2seq(input_size \u001B[38;5;241m=\u001B[39m X_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m], hidden_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m32\u001B[39m)\n\u001B[1;32m---> 39\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m500\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_len\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m12\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_prediction\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrecursive\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mteacher_forcing_ratio\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.6\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdynamic_tf\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoss : \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m + shape: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m + type: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(loss, loss\u001B[38;5;241m.\u001B[39mshape, \u001B[38;5;28mtype\u001B[39m(loss)))\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Climate_Science_Research_Project\\LIM\\LSTM_enc_dec.py:224\u001B[0m, in \u001B[0;36mLSTM_seq2seq.train_model\u001B[1;34m(self, input_tensor, target_tensor, n_epochs, target_len, batch_size, training_prediction, teacher_forcing_ratio, learning_rate, dynamic_tf)\u001B[0m\n\u001B[0;32m    221\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    223\u001B[0m \u001B[38;5;66;03m# loss for epoch\u001B[39;00m\n\u001B[1;32m--> 224\u001B[0m batch_loss \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m n_batches\n\u001B[0;32m    225\u001B[0m losses[it] \u001B[38;5;241m=\u001B[39m batch_loss\n\u001B[0;32m    227\u001B[0m \u001B[38;5;66;03m# dynamic teacher forcing\u001B[39;00m\n",
      "\u001B[1;31mZeroDivisionError\u001B[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# LSTM encoder-decoder\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create the DataLoader for first principal component\n",
    "data = pca_10.principal_components()\n",
    "data = np.array(data)\n",
    "print(\"Data : {} + shape: {} + type: {}\".format(data, data.shape, type(data)))\n",
    "\n",
    "# Hyperparameter search space\n",
    "hyperparams = {\n",
    "    'hidden_size': [32],\n",
    "    'learning_rate': [0.001, 0.002],\n",
    "    'num_epochs': [1000],\n",
    "    'num_layers': [3],\n",
    "    'sequence_length': [5],\n",
    "    'batch_size': [1]\n",
    "}\n",
    "\n",
    "#Train the model\n",
    "\n",
    "index_train = int(0.8 * len(data[0, :]))\n",
    "data_train = data[:, :index_train]\n",
    "data_test = data[:, index_train:]\n",
    "\n",
    "input_data, target_data = windowed_dataset(data_train, input_window=5, output_window=12)\n",
    "input_data_test, target_data_test = windowed_dataset(data_test)\n",
    "\n",
    "print(\"Input data : {} + shape: {} + type: {}\".format(input_data, input_data.shape, type(input_data)))\n",
    "\n",
    "\n",
    "\n",
    "# convert windowed data from np.array to PyTorch tensor\n",
    "X_train, Y_train, X_test, Y_test = numpy_to_torch(input_data, target_data, input_data_test, target_data_test)\n",
    "\n",
    "# specify model parameters and train\n",
    "model = LSTM_seq2seq(input_size = X_train.shape[2], hidden_size = 32)\n",
    "loss = model.train_model(X_train, Y_train, n_epochs = 500, target_len = 12, batch_size = 32, training_prediction = 'recursive', teacher_forcing_ratio = 0.6, learning_rate = 0.01, dynamic_tf = False)\n",
    "print(\"Loss : {} + shape: {} + type: {}\".format(loss, loss.shape, type(loss)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}