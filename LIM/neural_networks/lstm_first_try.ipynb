{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import json\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from LIM import utils as ut\n",
    "from LSTM_enc_dec import *\n",
    "\n",
    "plt.style.use(\"../plotting.mplstyle\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cropped : <xarray.DataArray (lat: 64, lon: 49, time: 14400)>\n",
      "array([[[ 2.02209473e-01,  1.17340088e-01,  4.94384766e-01, ...,\n",
      "          8.75854492e-01,  6.95953369e-01,  1.23394775e+00],\n",
      "        [ 2.11151123e-01,  1.29272461e-01,  4.34478760e-01, ...,\n",
      "          8.53332520e-01,  6.09649658e-01,  1.13095093e+00],\n",
      "        [ 2.19390869e-01,  1.32568359e-01,  3.57666016e-01, ...,\n",
      "          8.30566406e-01,  5.58593750e-01,  1.03283691e+00],\n",
      "        ...,\n",
      "        [-1.58905029e-01, -2.84118652e-02,  8.29162598e-02, ...,\n",
      "          4.74670410e-01,  9.83276367e-02,  1.40136719e-01],\n",
      "        [-7.95898438e-02, -9.41680908e-01, -1.06283569e+00, ...,\n",
      "         -4.00665283e-01, -3.01940918e-01,  3.83422852e-01],\n",
      "        [            nan,             nan,             nan, ...,\n",
      "                     nan,             nan,             nan]],\n",
      "\n",
      "       [[ 1.75354004e-01,  1.05651855e-01,  3.49700928e-01, ...,\n",
      "          1.02838135e+00,  7.58544922e-01,  1.18096924e+00],\n",
      "        [ 1.99768066e-01,  1.15692139e-01,  2.83386230e-01, ...,\n",
      "          1.02593994e+00,  6.95922852e-01,  1.08932495e+00],\n",
      "        [ 2.22137451e-01,  1.03363037e-01,  2.00622559e-01, ...,\n",
      "          1.03060913e+00,  6.62139893e-01,  1.00393677e+00],\n",
      "...\n",
      "         -7.13378906e-01, -7.30468750e-01, -7.02819824e-01],\n",
      "        [-4.63867188e-02,  1.04919434e-01,  1.94091797e-01, ...,\n",
      "         -6.59820557e-01, -7.27813721e-01, -7.36083984e-01],\n",
      "        [-9.59472656e-02,  5.75561523e-02,  1.66503906e-01, ...,\n",
      "         -5.77239990e-01, -7.09381104e-01, -7.59490967e-01]],\n",
      "\n",
      "       [[-5.09338379e-02,  2.47406006e-01,  2.19787598e-01, ...,\n",
      "         -2.80517578e-01, -1.89697266e-01, -2.36419678e-01],\n",
      "        [-5.35888672e-02,  2.35260010e-01,  2.02758789e-01, ...,\n",
      "         -2.13439941e-01, -1.47216797e-01, -2.50885010e-01],\n",
      "        [-5.85937500e-02,  2.21160889e-01,  1.85516357e-01, ...,\n",
      "         -1.98730469e-01, -1.80877686e-01, -3.30413818e-01],\n",
      "        ...,\n",
      "        [ 5.18798828e-02,  2.69989014e-01,  3.14514160e-01, ...,\n",
      "         -5.53314209e-01, -5.90789795e-01, -5.72540283e-01],\n",
      "        [-1.37329102e-02,  1.71173096e-01,  2.62756348e-01, ...,\n",
      "         -5.26580811e-01, -6.16729736e-01, -6.18194580e-01],\n",
      "        [-7.83386230e-02,  1.02050781e-01,  2.13775635e-01, ...,\n",
      "         -4.65209961e-01, -6.18286133e-01, -6.55487061e-01]]],\n",
      "      dtype=float32)\n",
      "Coordinates:\n",
      "  * lat      (lat) float64 -29.69 -28.74 -27.8 -26.86 ... 26.86 27.8 28.74 29.69\n",
      "  * lon      (lon) float64 -130.0 -128.8 -127.5 -126.2 ... -72.5 -71.25 -70.0\n",
      "  * time     (time) object 0001-01-15 12:00:00 ... 1200-12-15 12:00:00\n",
      "    month    (time) int64 1 2 3 4 5 6 7 8 9 10 11 ... 2 3 4 5 6 7 8 9 10 11 12 + shape : (64, 49, 14400)\n"
     ]
    }
   ],
   "source": [
    "data = xr.open_dataset(\"C:/Users/felix/PycharmProjects/ML_Climate_Science_Research_Project/LIM/data/ts_Amon_CESM2_piControl_r1i1p1f1.nc\")[\"ts\"]\n",
    "#data = xr.open_dataset(\"./data/zos_Amon_CESM2_piControl_r1i1p1f1.nc\")[\"zos\"]\n",
    "#data_old = xr.open_dataset(\"./data/ssta_1950_2021.nc\")[\"ssta\"]\n",
    "mask = xr.open_dataset(\"C:/Users/felix/PycharmProjects/ML_Climate_Science_Research_Project/LIM/data/sftlf_fx_CESM2_historical_r1i1p1f1.nc\")[\"sftlf\"]\n",
    "\n",
    "#14400 orginial size\n",
    "data = data[:, :, :]\n",
    "\n",
    "data = ut.apply_mask(mask, data)\n",
    "#print(\"Data : {} + shape {}\".format(data, data.shape))\n",
    "\n",
    "data_anomalies = ut.calculate_monthly_anomalies(data)\n",
    "#print(\"Month mean : {} + shape : {}\".format(data_anomalies, data_anomalies.shape))\n",
    "\n",
    "data_cropped =ut.crop_xarray(data_anomalies)\n",
    "#print(\"Data cropped : {} + shape : {}\".format(data_cropped, data_cropped.shape))\n",
    "\n",
    "\n",
    "pca_10 = ut.SpatioTemporalPCA(data_cropped, n_components=20)\n",
    "#pca_10 = ut.SpatioTemporalPCA(data_anomalies, n_components=20)\n",
    "eof_10 = pca_10.eofs()\n",
    "pc_10 = pca_10.principal_components()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from LSTM_model import *\n",
    "#\n",
    "# # Set random seed for reproducibility\n",
    "# torch.manual_seed(42)\n",
    "#\n",
    "def hyperparameter_training_loop(data, hyperparams):\n",
    "\n",
    "    # Generate all possible combinations of hyperparameters\n",
    "    combinations = list(itertools.product(*hyperparams.values()))\n",
    "\n",
    "    overall_best_model = {\"hidden_size\": None,\n",
    "                         \"learning_rate\": None,\n",
    "                         \"num_epochs\": None,\n",
    "                         \"loss\": float('inf')}\n",
    "\n",
    "    # Iterate over each hyperparameter combination\n",
    "    for i, params in enumerate(combinations):\n",
    "        print(f\"Testing parameter combination {i+1}/{len(combinations)}: {params}\")\n",
    "\n",
    "        # Create a new model with the current hyperparameters\n",
    "        hidden_size = params[0]\n",
    "        learning_rate = params[1]\n",
    "        num_epochs = params[2]\n",
    "        num_layers = params[3]\n",
    "        sequence_length = params[4]\n",
    "        batch_size = params[5]\n",
    "\n",
    "        dataloader = create_dataloader(data, sequence_length=sequence_length, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = LSTMNetwork(1, hidden_size, num_layers)\n",
    "        losses = train(model, dataloader, num_epochs, learning_rate)\n",
    "\n",
    "        # Save the model and hyperparameters to a file\n",
    "        result = {\n",
    "            'hyperparameters': {\n",
    "                'hidden_size': hidden_size,\n",
    "                'learning_rate': learning_rate,\n",
    "                'num_epochs': num_epochs,\n",
    "                'num_layers': num_layers,\n",
    "                'sequence_length': sequence_length,\n",
    "                'best_loss': losses[-1],\n",
    "                \"losses\": losses\n",
    "            }\n",
    "        }\n",
    "        if losses[-1] < overall_best_model[\"loss\"]:\n",
    "            overall_best_model[\"hidden_size\"] = params[0]\n",
    "            overall_best_model[\"learning_rate\"] = params[1]\n",
    "            overall_best_model[\"num_epochs\"] = params[2]\n",
    "            overall_best_model[\"loss\"] = losses[-1]\n",
    "            overall_best_model[\"losses\"] = losses\n",
    "\n",
    "        filename = f\"./model_trained_lstm/fnn_model_{i+1}.pt\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(result, f)\n",
    "\n",
    "        print(f\"Saved model and hyperparameters to {filename}\\n\")\n",
    "\n",
    "    return overall_best_model\n",
    "#\n",
    "#\n",
    "# # Create the DataLoader for first principal component\n",
    "# data = np.array(data)[0]\n",
    "# print(\"Data : {} + shape: {} + type: {}\".format(data, data.shape, type(data)))\n",
    "#\n",
    "# # Hyperparameter search space\n",
    "# hyperparams = {\n",
    "#     'hidden_size': [32],\n",
    "#     'learning_rate': [0.001, 0.002],\n",
    "#     'num_epochs': [1000],\n",
    "#     'num_layers': [3],\n",
    "#     'sequence_length': [5],\n",
    "#     'batch_size': [1]\n",
    "# }\n",
    "#\n",
    "# #Train the model\n",
    "# #train(model, dataloader, num_epochs, learning_rate)\n",
    "# best_model = hyperparameter_training_loop(data, hyperparams)\n",
    "#\n",
    "# print(f\"Best model: {best_model}\")\n",
    "# plot_loss_evolution(best_model[\"losses\"], np.arange(0,best_model[\"num_epochs\"], 100, dtype=int), best_model[\"learning_rate\"], best_model[\"hidden_size\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data preparation for LSTM\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create the DataLoader for first principal component\n",
    "data = pca_10.principal_components()\n",
    "data = np.array(data)\n",
    "#print(\"Data : {} + shape: {} + type: {}\".format(data, data.shape, type(data)))\n",
    "\n",
    "data = torch.from_numpy(data).type(torch.Tensor)\n",
    "\n",
    "# Reshape the data if necessary (assuming a 2D tensor)\n",
    "if len(data.shape) == 1:\n",
    "    data = data.unsqueeze(1)\n",
    "\n",
    "# Calculate the mean and standard deviation along the feature dimension\n",
    "mean = torch.mean(data, dim=1, keepdim=True)\n",
    "std = torch.std(data, dim=1, keepdim=True)\n",
    "\n",
    "# Apply normalization using the mean and standard deviation\n",
    "data = (data - mean) / std\n",
    "\n",
    "index_train = int(0.8 * len(data[0, :]))\n",
    "data_train = data[:, :index_train]\n",
    "data_test = data[:, index_train:]\n",
    "\n",
    "input_data, target_data = windowed_dataset(data_train, input_window=5, output_window=12)\n",
    "input_data_test, target_data_test = windowed_dataset(data_test, input_window=5, output_window=12)\n",
    "\n",
    "#print(\"Input data : {} + shape: {} + type: {}\".format(input_data, input_data.shape, type(input_data)))\n",
    "\n",
    "\n",
    "\n",
    "# convert windowed data from np.array to PyTorch tensor\n",
    "X_train, Y_train, X_test, Y_test = numpy_to_torch(input_data, target_data, input_data_test, target_data_test)\n",
    "\n",
    "print(\"X_train : {} + shape: {} + type: {}\".format(X_train, X_train.shape, type(X_train)))\n",
    "print(\"X_test : {} + shape: {} + type: {}\".format(X_test, X_test.shape, type(X_test)))\n",
    "print(X_train.shape[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"X-train shape : \", X_train.shape)\n",
    "print(\"Y-train shape : \", Y_train.shape)\n",
    "# specify model parameters and train\n",
    "model = LSTM_seq2seq(input_size = X_train.shape[2], hidden_size = 32)\n",
    "loss = model.train_model(X_train, Y_train, n_epochs = 200, target_len = 12, batch_size = 2, training_prediction = 'mixed-teacher-forcing', teacher_forcing_ratio = 0.6, learning_rate = 0.01, dynamic_tf = True)\n",
    "#print(\"Loss : {} + shape: {} + type: {}\".format(loss, loss.shape, type(loss)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
