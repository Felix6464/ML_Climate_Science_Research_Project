
 20%|███████████████████▌                                                                              | 20/100 [00:01<00:06, 11.78it/s, loss_test=1.090]
Epoch: 00, Training Loss: 0.9953, Test Loss: 1.0888
Epoch: 01, Training Loss: 0.9961, Test Loss: 1.0622
Epoch: 02, Training Loss: 0.9899, Test Loss: 1.0809
Epoch: 03, Training Loss: 0.9931, Test Loss: 1.0740
Epoch: 04, Training Loss: 0.9928, Test Loss: 1.0844
Epoch: 05, Training Loss: 0.9942, Test Loss: 1.0775
Epoch: 06, Training Loss: 0.9929, Test Loss: 1.0895
Epoch: 07, Training Loss: 0.9930, Test Loss: 1.0788
Epoch: 08, Training Loss: 0.9954, Test Loss: 1.0744
Epoch: 09, Training Loss: 0.9897, Test Loss: 1.0662
Epoch: 10, Training Loss: 0.9852, Test Loss: 1.0684
Epoch: 11, Training Loss: 0.9892, Test Loss: 1.0758
Epoch: 12, Training Loss: 0.9832, Test Loss: 1.0717
Epoch: 13, Training Loss: 0.9877, Test Loss: 1.0920
Epoch: 14, Training Loss: 0.9828, Test Loss: 1.0775
Epoch: 15, Training Loss: 0.9860, Test Loss: 1.0828
Epoch: 16, Training Loss: 0.9860, Test Loss: 1.0783
Epoch: 17, Training Loss: 0.9868, Test Loss: 1.0892
Epoch: 18, Training Loss: 0.9865, Test Loss: 1.0984

 44%|███████████████████████████████████████████                                                       | 44/100 [00:03<00:04, 12.23it/s, loss_test=1.028]
Epoch: 20, Training Loss: 0.9810, Test Loss: 1.0819
Epoch: 21, Training Loss: 0.9834, Test Loss: 1.0746
Epoch: 22, Training Loss: 0.9798, Test Loss: 1.0636
Epoch: 23, Training Loss: 0.9801, Test Loss: 1.0835
Epoch: 24, Training Loss: 0.9841, Test Loss: 1.0890
Epoch: 25, Training Loss: 0.9822, Test Loss: 1.0911
Epoch: 26, Training Loss: 0.9848, Test Loss: 1.0501
Epoch: 27, Training Loss: 0.9826, Test Loss: 1.0680
Epoch: 28, Training Loss: 0.9788, Test Loss: 1.0779
Epoch: 29, Training Loss: 0.9776, Test Loss: 1.0619
Epoch: 30, Training Loss: 0.9707, Test Loss: 1.0775
Epoch: 31, Training Loss: 0.9771, Test Loss: 1.0700
Epoch: 32, Training Loss: 0.9744, Test Loss: 1.0745
Epoch: 33, Training Loss: 0.9694, Test Loss: 1.0680
Epoch: 34, Training Loss: 0.9655, Test Loss: 1.0800
Epoch: 35, Training Loss: 0.9613, Test Loss: 1.0832
Epoch: 36, Training Loss: 0.9538, Test Loss: 1.0558
Epoch: 37, Training Loss: 0.9559, Test Loss: 1.0478
Epoch: 38, Training Loss: 0.9509, Test Loss: 1.0494
Epoch: 39, Training Loss: 0.9420, Test Loss: 1.0580
Epoch: 40, Training Loss: 0.9398, Test Loss: 1.0603
Epoch: 41, Training Loss: 0.9293, Test Loss: 1.0667
Epoch: 42, Training Loss: 0.9209, Test Loss: 1.0452
Epoch: 43, Training Loss: 0.9178, Test Loss: 1.0322

 70%|████████████████████████████████████████████████████████████████████▌                             | 70/100 [00:05<00:02, 12.22it/s, loss_test=0.934]
Epoch: 45, Training Loss: 0.9064, Test Loss: 1.0315
Epoch: 46, Training Loss: 0.8982, Test Loss: 1.0206
Epoch: 47, Training Loss: 0.8920, Test Loss: 1.0125
Epoch: 48, Training Loss: 0.8854, Test Loss: 0.9984
Epoch: 49, Training Loss: 0.8799, Test Loss: 0.9907
Epoch: 50, Training Loss: 0.8729, Test Loss: 0.9775
Epoch: 51, Training Loss: 0.8722, Test Loss: 0.9751
Epoch: 52, Training Loss: 0.8632, Test Loss: 0.9925
Epoch: 53, Training Loss: 0.8575, Test Loss: 1.0062
Epoch: 54, Training Loss: 0.8542, Test Loss: 0.9823
Epoch: 55, Training Loss: 0.8453, Test Loss: 0.9807
Epoch: 56, Training Loss: 0.8407, Test Loss: 0.9801
Epoch: 57, Training Loss: 0.8329, Test Loss: 0.9791
Epoch: 58, Training Loss: 0.8273, Test Loss: 0.9652
Epoch: 59, Training Loss: 0.8213, Test Loss: 0.9633
Epoch: 60, Training Loss: 0.8162, Test Loss: 0.9471
Epoch: 61, Training Loss: 0.8106, Test Loss: 0.9546
Epoch: 62, Training Loss: 0.8008, Test Loss: 0.9666
Epoch: 63, Training Loss: 0.7940, Test Loss: 0.9446
Epoch: 64, Training Loss: 0.7895, Test Loss: 0.9511
Epoch: 65, Training Loss: 0.7866, Test Loss: 0.9300
Epoch: 66, Training Loss: 0.7786, Test Loss: 0.9323
Epoch: 67, Training Loss: 0.7727, Test Loss: 0.9299
Epoch: 68, Training Loss: 0.7658, Test Loss: 0.9179

 94%|████████████████████████████████████████████████████████████████████████████████████████████      | 94/100 [00:07<00:00, 12.01it/s, loss_test=0.906]
Epoch: 70, Training Loss: 0.7562, Test Loss: 0.9313
Epoch: 71, Training Loss: 0.7503, Test Loss: 0.9293
Epoch: 72, Training Loss: 0.7461, Test Loss: 0.9172
Epoch: 73, Training Loss: 0.7411, Test Loss: 0.9176
Epoch: 74, Training Loss: 0.7359, Test Loss: 0.9162
Epoch: 75, Training Loss: 0.7321, Test Loss: 0.9235
Epoch: 76, Training Loss: 0.7280, Test Loss: 0.9233
Epoch: 77, Training Loss: 0.7269, Test Loss: 0.9240
Epoch: 78, Training Loss: 0.7209, Test Loss: 0.9068
Epoch: 79, Training Loss: 0.7176, Test Loss: 0.9063
Epoch: 80, Training Loss: 0.7099, Test Loss: 0.9278
Epoch: 81, Training Loss: 0.7091, Test Loss: 0.9154
Epoch: 82, Training Loss: 0.7065, Test Loss: 0.9162
Epoch: 83, Training Loss: 0.7024, Test Loss: 0.9308
Epoch: 84, Training Loss: 0.6988, Test Loss: 0.9162
Epoch: 85, Training Loss: 0.6940, Test Loss: 0.9145
Epoch: 86, Training Loss: 0.6910, Test Loss: 0.9122
Epoch: 87, Training Loss: 0.6871, Test Loss: 0.9089
Epoch: 88, Training Loss: 0.6865, Test Loss: 0.9212
Epoch: 89, Training Loss: 0.6797, Test Loss: 0.9054
Epoch: 90, Training Loss: 0.6753, Test Loss: 0.9217
Epoch: 91, Training Loss: 0.6746, Test Loss: 0.9046
Epoch: 92, Training Loss: 0.6685, Test Loss: 0.9161
Epoch: 93, Training Loss: 0.6677, Test Loss: 0.9103

100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.25it/s, loss_test=0.923]
Epoch: 95, Training Loss: 0.6602, Test Loss: 0.9093
Epoch: 96, Training Loss: 0.6568, Test Loss: 0.9136
Epoch: 97, Training Loss: 0.6539, Test Loss: 0.9002
Epoch: 98, Training Loss: 0.6512, Test Loss: 0.9039
Epoch: 99, Training Loss: 0.6493, Test Loss: 0.9230
Model saved as model_1387407np.pt
Config : {'wandb': True, 'name': 'lstm-enc-dec-0.0001-2-12160000-1387407np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 100, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-DATA', 'teacher_forcing_ratio': -4.198030811863873e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9952882766723633, 0.9960569024085999, 0.9898703217506408, 0.9930643320083619, 0.9927853226661683, 0.9941654324531555, 0.9928700566291809, 0.9929891347885131, 0.9953736782073974, 0.9897421002388, 0.9852080106735229, 0.9892200708389283, 0.9832308053970337, 0.9876808643341064, 0.9827877521514893, 0.985961127281189, 0.9859706997871399, 0.9868229031562805, 0.9864797472953797, 0.9850546836853027, 0.9809925556182861, 0.9833792090415955, 0.9797601580619812, 0.9800894260406494, 0.9841432094573974, 0.9822247982025146, 0.9847559094429016, 0.9825818538665771, 0.9787795066833496, 0.9775677919387817, 0.9706832766532898, 0.9770516276359558, 0.9743640542030334, 0.9694156646728516, 0.9654789566993713, 0.9613034725189209, 0.9537509918212891, 0.9558995366096497, 0.9508980512619019, 0.9419595956802368, 0.9397954106330871, 0.9293063640594482, 0.9208991050720214, 0.9177635788917542, 0.9094753861427307, 0.9064187049865723, 0.8982047796249389, 0.8919550538063049, 0.8853688716888428, 0.8798731088638305, 0.8729032278060913, 0.8721528053283691, 0.8631814122200012, 0.8574931144714355, 0.8542171239852905, 0.8453008532524109, 0.8407435178756714, 0.8329061150550843, 0.8272696733474731, 0.8213432550430297, 0.8161924600601196, 0.8106215953826904, 0.8007719159126282, 0.7939785361289978, 0.7895387291908265, 0.7865540504455566, 0.778571093082428, 0.7727168560028076, 0.7657500147819519, 0.7607701778411865, 0.7562136650085449, 0.7503352522850036, 0.7460855364799499, 0.7411165595054626, 0.735878872871399, 0.7320975542068482, 0.7280116200447082, 0.726930809020996, 0.7209131002426148, 0.7176265716552734, 0.7099064469337464, 0.7090852379798889, 0.7064789772033692, 0.7024186491966248, 0.6987580776214599, 0.6940136790275574, 0.6910257458686828, 0.6871037125587464, 0.686532199382782, 0.6796607732772827, 0.6753403902053833, 0.6746102809906006, 0.6685034394264221, 0.6676689147949219, 0.6641624808311463, 0.6601568579673767, 0.656796908378601, 0.6538680195808411, 0.6511524438858032, 0.6493471264839172], 'loss_test': [1.0888230800628662, 1.062193512916565, 1.0808525085449219, 1.0739834308624268, 1.0843775272369385, 1.0775256156921387, 1.0895482301712036, 1.0788464546203613, 1.0743952989578247, 1.0661579370498657, 1.0684309005737305, 1.0757849216461182, 1.0717235803604126, 1.0920037031173706, 1.0775097608566284, 1.0827523469924927, 1.078281044960022, 1.0892436504364014, 1.0983738899230957, 1.090002417564392, 1.081868290901184, 1.074552059173584, 1.0635887384414673, 1.083452820777893, 1.0889769792556763, 1.0910605192184448, 1.0500534772872925, 1.0680155754089355, 1.077897310256958, 1.0619159936904907, 1.0775260925292969, 1.0699925422668457, 1.0745211839675903, 1.0679504871368408, 1.0800050497055054, 1.0831700563430786, 1.055814266204834, 1.047829508781433, 1.0494292974472046, 1.0580347776412964, 1.0603244304656982, 1.0666567087173462, 1.045215368270874, 1.0322341918945312, 1.0278782844543457, 1.0314656496047974, 1.020585536956787, 1.0124924182891846, 0.9984091520309448, 0.9906802773475647, 0.9774561524391174, 0.9751441478729248, 0.9925068616867065, 1.0061832666397095, 0.9823091626167297, 0.9806873202323914, 0.9800577759742737, 0.9791386127471924, 0.9652469158172607, 0.9633047580718994, 0.947128415107727, 0.9546388387680054, 0.9665918946266174, 0.9446398019790649, 0.9510835409164429, 0.929999828338623, 0.9323322176933289, 0.9298601150512695, 0.9179373979568481, 0.9336137771606445, 0.9313135147094727, 0.9293314814567566, 0.9172472953796387, 0.9176051020622253, 0.9162209630012512, 0.923525869846344, 0.9232532382011414, 0.923987865447998, 0.9068464636802673, 0.9062747955322266, 0.9277942180633545, 0.9154385328292847, 0.9161756038665771, 0.9308320879936218, 0.9162107706069946, 0.9144763946533203, 0.9122127890586853, 0.9088977575302124, 0.9211804270744324, 0.9053502678871155, 0.9216585159301758, 0.9046241044998169, 0.9160826206207275, 0.9102955460548401, 0.9061838984489441, 0.9092800617218018, 0.9135729670524597, 0.9002012610435486, 0.9039450883865356, 0.9230350852012634], 'identifier': '1387407np'}