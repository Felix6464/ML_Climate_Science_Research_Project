

  3%|██▌                                                                           | 1/30 [00:02<01:26,  2.99s/it, loss_test=1.003]

  7%|█████▏                                                                        | 2/30 [00:05<01:20,  2.87s/it, loss_test=0.966]
Epoch: 01, Training Loss: 0.9123, Test Loss: 0.9657

 10%|███████▊                                                                      | 3/30 [00:08<01:13,  2.72s/it, loss_test=0.880]


 17%|█████████████                                                                 | 5/30 [00:13<01:08,  2.74s/it, loss_test=0.795]
Epoch: 04, Training Loss: 0.7749, Test Loss: 0.7949


 23%|██████████████████▏                                                           | 7/30 [00:19<01:04,  2.80s/it, loss_test=0.738]
Epoch: 06, Training Loss: 0.7162, Test Loss: 0.7381


 30%|███████████████████████▍                                                      | 9/30 [00:25<00:58,  2.80s/it, loss_test=0.699]

 33%|█████████████████████████▋                                                   | 10/30 [00:27<00:54,  2.73s/it, loss_test=0.689]
Epoch: 09, Training Loss: 0.6672, Test Loss: 0.6890


 40%|██████████████████████████████▊                                              | 12/30 [00:33<00:48,  2.71s/it, loss_test=0.673]

 43%|█████████████████████████████████▎                                           | 13/30 [00:35<00:45,  2.67s/it, loss_test=0.667]
Epoch: 12, Training Loss: 0.6412, Test Loss: 0.6669


 50%|██████████████████████████████████████▌                                      | 15/30 [00:41<00:41,  2.74s/it, loss_test=0.657]

 53%|█████████████████████████████████████████                                    | 16/30 [00:44<00:38,  2.78s/it, loss_test=0.653]
Epoch: 15, Training Loss: 0.6253, Test Loss: 0.6531


 60%|██████████████████████████████████████████████▏                              | 18/30 [00:49<00:32,  2.70s/it, loss_test=0.648]

 63%|████████████████████████████████████████████████▊                            | 19/30 [00:51<00:29,  2.65s/it, loss_test=0.646]
Epoch: 18, Training Loss: 0.6138, Test Loss: 0.6456


 70%|█████████████████████████████████████████████████████▉                       | 21/30 [00:57<00:23,  2.66s/it, loss_test=0.643]

 73%|████████████████████████████████████████████████████████▍                    | 22/30 [00:59<00:21,  2.67s/it, loss_test=0.640]
Epoch: 21, Training Loss: 0.6053, Test Loss: 0.6402


 80%|█████████████████████████████████████████████████████████████▌               | 24/30 [01:05<00:16,  2.67s/it, loss_test=0.639]

 83%|████████████████████████████████████████████████████████████████▏            | 25/30 [01:07<00:13,  2.68s/it, loss_test=0.638]
Epoch: 24, Training Loss: 0.5979, Test Loss: 0.6380


 90%|█████████████████████████████████████████████████████████████████████▎       | 27/30 [01:13<00:08,  2.69s/it, loss_test=0.634]

 93%|███████████████████████████████████████████████████████████████████████▊     | 28/30 [01:16<00:05,  2.72s/it, loss_test=0.634]
Epoch: 27, Training Loss: 0.5918, Test Loss: 0.6345


100%|█████████████████████████████████████████████████████████████████████████████| 30/30 [01:21<00:00,  2.72s/it, loss_test=0.633]
Epoch: 29, Training Loss: 0.5883, Test Loss: 0.6329
Model saved as model_94386np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-1230000-94386np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-50E-DATA', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9998692259466722, 0.9122506881052731, 0.8579783779711811, 0.8122984372033664, 0.7749062209772918, 0.7435367549855285, 0.7161830367486169, 0.6938570068657763, 0.67862432354067, 0.6672098142969096, 0.6572348691203111, 0.6486484832558895, 0.6412410571531284, 0.6351834755002356, 0.6297428567716681, 0.6253103804003242, 0.6208528898244986, 0.6172278812326537, 0.6138225925480661, 0.6107675798831542, 0.6078614523074378, 0.6053172115899302, 0.6026059283069306, 0.600265989274335, 0.5979424155562933, 0.5958572366486298, 0.593677779282529, 0.5918183670453498, 0.5900136700437113, 0.5882893285137013], 'loss_test': [1.0027508191440417, 0.9657493052275284, 0.8800252533477285, 0.8343612098175547, 0.7948925857958586, 0.7633809473203577, 0.7381465720093768, 0.714626528646635, 0.6990190951720529, 0.6889916269675546, 0.6804792660733928, 0.6732832828293676, 0.6668902868809907, 0.6616187782391257, 0.6573962970920231, 0.6531249673470206, 0.651610703571983, 0.6480782096800597, 0.6456019502619038, 0.6444553940192513, 0.6430084096348804, 0.6401985520901887, 0.6399245184400807, 0.6385062168473783, 0.6379965258681256, 0.6357073822747106, 0.6344620144885519, 0.6344897423101508, 0.6331861990949382, 0.632937411899152], 'identifier': '94386np'}