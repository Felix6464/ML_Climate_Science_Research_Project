

  3%|██▊                                                                                 | 1/30 [00:09<04:25,  9.16s/it, loss_test=1.006]
Epoch: 00, Training Loss: 0.9035, Test Loss: 1.0055


 10%|████████▍                                                                           | 3/30 [00:27<04:10,  9.26s/it, loss_test=0.711]

 13%|███████████▏                                                                        | 4/30 [00:37<04:02,  9.33s/it, loss_test=0.674]

 17%|██████████████                                                                      | 5/30 [00:46<03:50,  9.23s/it, loss_test=0.650]
Epoch: 04, Training Loss: 0.6366, Test Loss: 0.6505


 23%|███████████████████▌                                                                | 7/30 [01:03<03:26,  8.99s/it, loss_test=0.629]
Epoch: 06, Training Loss: 0.6168, Test Loss: 0.6286


 30%|█████████████████████████▏                                                          | 9/30 [01:21<03:08,  9.00s/it, loss_test=0.615]
Epoch: 08, Training Loss: 0.6049, Test Loss: 0.6154


 37%|██████████████████████████████▍                                                    | 11/30 [01:40<02:51,  9.03s/it, loss_test=0.608]
Epoch: 10, Training Loss: 0.5970, Test Loss: 0.6078


 43%|███████████████████████████████████▉                                               | 13/30 [01:57<02:32,  8.99s/it, loss_test=0.602]
Epoch: 12, Training Loss: 0.5914, Test Loss: 0.6025


 50%|█████████████████████████████████████████▌                                         | 15/30 [02:16<02:16,  9.11s/it, loss_test=0.599]

 53%|████████████████████████████████████████████▎                                      | 16/30 [02:25<02:07,  9.10s/it, loss_test=0.597]
Epoch: 15, Training Loss: 0.5854, Test Loss: 0.5972


 60%|█████████████████████████████████████████████████▊                                 | 18/30 [02:43<01:49,  9.12s/it, loss_test=0.595]
Epoch: 17, Training Loss: 0.5823, Test Loss: 0.5947


 67%|███████████████████████████████████████████████████████▎                           | 20/30 [03:01<01:31,  9.13s/it, loss_test=0.593]
Epoch: 19, Training Loss: 0.5799, Test Loss: 0.5931


 73%|████████████████████████████████████████████████████████████▊                      | 22/30 [03:20<01:13,  9.14s/it, loss_test=0.591]
Epoch: 21, Training Loss: 0.5778, Test Loss: 0.5912

 77%|███████████████████████████████████████████████████████████████▋                   | 23/30 [03:29<01:04,  9.15s/it, loss_test=0.591]


 83%|█████████████████████████████████████████████████████████████████████▏             | 25/30 [03:47<00:45,  9.13s/it, loss_test=0.590]

 87%|███████████████████████████████████████████████████████████████████████▉           | 26/30 [03:56<00:36,  9.05s/it, loss_test=0.590]
Epoch: 25, Training Loss: 0.5746, Test Loss: 0.5898


 93%|█████████████████████████████████████████████████████████████████████████████▍     | 28/30 [04:14<00:17,  8.96s/it, loss_test=0.589]
Epoch: 27, Training Loss: 0.5734, Test Loss: 0.5888


100%|███████████████████████████████████████████████████████████████████████████████████| 30/30 [04:31<00:00,  9.05s/it, loss_test=0.589]
Epoch: 29, Training Loss: 0.5723, Test Loss: 0.5886
Model saved as model_1902812np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-12100000-1902812np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-SPREAD', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9034619412142715, 0.7402813473900596, 0.6853070917365315, 0.6554130993701599, 0.6366041493721497, 0.6251085243382297, 0.6168133522564675, 0.6102995143268571, 0.6048997175562513, 0.6005852590332101, 0.5969638272082849, 0.5939791550784758, 0.5913639072970156, 0.589039065134831, 0.5871935110170763, 0.5853699408608042, 0.5837388020077031, 0.5823130608696641, 0.5810322365263006, 0.5798895920152629, 0.5787915992431152, 0.5777606402998006, 0.5769240921670264, 0.5760720939863295, 0.575308505650405, 0.5745824401850229, 0.5740173822575874, 0.5734332368705736, 0.5728175307149852, 0.5723475304060367], 'loss_test': [1.0055178491733012, 0.7922184047026511, 0.7107720057933758, 0.6742188437626913, 0.6504903110938195, 0.6366991427464362, 0.6286372213791578, 0.620805887457652, 0.6154047101736069, 0.6112197431234213, 0.6077910497402533, 0.6049309949844311, 0.6024659073505646, 0.600342720364913, 0.598745095424163, 0.5971781993523623, 0.5962316894378418, 0.5947247082606341, 0.5937115164139332, 0.5931234772388752, 0.5924196610083947, 0.591226210196813, 0.5908162746673975, 0.5903730793641164, 0.589884129472268, 0.5897544901340436, 0.589727792220238, 0.5888403657919321, 0.5892941649907675, 0.5885881605820779], 'identifier': '1902812np'}