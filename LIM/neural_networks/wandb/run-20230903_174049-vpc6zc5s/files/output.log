
 47%|███████████████████████████████▋                                    | 14/30 [00:01<00:01, 10.99it/s, loss_test=1.082]
Epoch: 00, Training Loss: 0.9891, Test Loss: 1.0750
Epoch: 01, Training Loss: 0.9914, Test Loss: 1.0730
Epoch: 02, Training Loss: 0.9975, Test Loss: 1.0844
Epoch: 03, Training Loss: 0.9875, Test Loss: 1.0902
Epoch: 04, Training Loss: 0.9908, Test Loss: 1.0869
Epoch: 05, Training Loss: 0.9845, Test Loss: 1.0865
Epoch: 06, Training Loss: 0.9894, Test Loss: 1.0961
Epoch: 07, Training Loss: 0.9890, Test Loss: 1.0758
Epoch: 08, Training Loss: 0.9882, Test Loss: 1.0818
Epoch: 09, Training Loss: 0.9911, Test Loss: 1.0739
Epoch: 10, Training Loss: 0.9909, Test Loss: 1.0584
Epoch: 11, Training Loss: 0.9866, Test Loss: 1.0733
Epoch: 12, Training Loss: 0.9848, Test Loss: 1.0841
Epoch: 13, Training Loss: 0.9897, Test Loss: 1.0742
Epoch: 14, Training Loss: 0.9842, Test Loss: 1.0815
Epoch: 15, Training Loss: 0.9891, Test Loss: 1.0856
Epoch: 16, Training Loss: 0.9842, Test Loss: 1.0849

100%|████████████████████████████████████████████████████████████████████| 30/30 [00:02<00:00, 10.27it/s, loss_test=1.065]
Epoch: 18, Training Loss: 0.9845, Test Loss: 1.0649
Epoch: 19, Training Loss: 0.9838, Test Loss: 1.0940
Epoch: 20, Training Loss: 0.9838, Test Loss: 1.0730
Epoch: 21, Training Loss: 0.9839, Test Loss: 1.0807
Epoch: 22, Training Loss: 0.9838, Test Loss: 1.0801
Epoch: 23, Training Loss: 0.9822, Test Loss: 1.0873
Epoch: 24, Training Loss: 0.9855, Test Loss: 1.0887
Epoch: 25, Training Loss: 0.9816, Test Loss: 1.0787
Epoch: 26, Training Loss: 0.9788, Test Loss: 1.0816
Epoch: 27, Training Loss: 0.9766, Test Loss: 1.0848
Epoch: 28, Training Loss: 0.9756, Test Loss: 1.0862
Epoch: 29, Training Loss: 0.9668, Test Loss: 1.0648
Model saved as model_4726435np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-121000-4726435np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-50E-DATA', 'teacher_forcing_ratio': 0.19999999999999973, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9890921831130981, 0.9914303898811341, 0.9974596381187439, 0.9874904036521912, 0.9908319711685181, 0.9845440983772278, 0.9893629908561706, 0.9889594554901123, 0.98819979429245, 0.9911461591720581, 0.9908765912055969, 0.9865653157234192, 0.9847754716873169, 0.9896888017654419, 0.9842203855514526, 0.9891448259353638, 0.9841786026954651, 0.990558922290802, 0.9845050692558288, 0.9838340997695922, 0.9837735056877136, 0.9839273929595947, 0.9837528824806213, 0.9821983218193054, 0.9854521512985229, 0.9816073775291443, 0.9787734627723694, 0.9765578389167786, 0.9756116747856141, 0.9668079853057862], 'loss_test': [1.0749741792678833, 1.0730490684509277, 1.0843857526779175, 1.0902061462402344, 1.0868886709213257, 1.0864524841308594, 1.0960721969604492, 1.0758333206176758, 1.0817638635635376, 1.0738948583602905, 1.0583950281143188, 1.0733460187911987, 1.0841354131698608, 1.074249505996704, 1.0815320014953613, 1.0856175422668457, 1.0848520994186401, 1.0835049152374268, 1.0649425983428955, 1.0940077304840088, 1.07303786277771, 1.0807297229766846, 1.0801266431808472, 1.087286114692688, 1.088712453842163, 1.0787334442138672, 1.0816044807434082, 1.0847827196121216, 1.0862241983413696, 1.0647557973861694], 'identifier': '4726435np'}