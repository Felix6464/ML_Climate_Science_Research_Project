
 20%|███████████████████▌                                                                              | 20/100 [00:01<00:06, 12.48it/s, loss_test=1.097]
Epoch: 00, Training Loss: 0.9925, Test Loss: 1.0735
Epoch: 01, Training Loss: 0.9910, Test Loss: 1.0876
Epoch: 02, Training Loss: 0.9912, Test Loss: 1.0899
Epoch: 03, Training Loss: 0.9934, Test Loss: 1.0857
Epoch: 04, Training Loss: 0.9913, Test Loss: 1.0698
Epoch: 05, Training Loss: 0.9924, Test Loss: 1.0767
Epoch: 06, Training Loss: 0.9862, Test Loss: 1.0811
Epoch: 07, Training Loss: 0.9890, Test Loss: 1.0809
Epoch: 08, Training Loss: 0.9896, Test Loss: 1.0935
Epoch: 09, Training Loss: 0.9872, Test Loss: 1.0677
Epoch: 10, Training Loss: 0.9886, Test Loss: 1.0919
Epoch: 11, Training Loss: 0.9872, Test Loss: 1.0880
Epoch: 12, Training Loss: 0.9887, Test Loss: 1.0748
Epoch: 13, Training Loss: 0.9880, Test Loss: 1.0885
Epoch: 14, Training Loss: 0.9877, Test Loss: 1.0821
Epoch: 15, Training Loss: 0.9850, Test Loss: 1.0836
Epoch: 16, Training Loss: 0.9868, Test Loss: 1.0733
Epoch: 17, Training Loss: 0.9854, Test Loss: 1.0699
Epoch: 18, Training Loss: 0.9810, Test Loss: 1.0860

 44%|███████████████████████████████████████████                                                       | 44/100 [00:03<00:04, 12.57it/s, loss_test=0.982]
Epoch: 20, Training Loss: 0.9856, Test Loss: 1.0717
Epoch: 21, Training Loss: 0.9852, Test Loss: 1.0750
Epoch: 22, Training Loss: 0.9838, Test Loss: 1.0777
Epoch: 23, Training Loss: 0.9819, Test Loss: 1.0702
Epoch: 24, Training Loss: 0.9832, Test Loss: 1.0737
Epoch: 25, Training Loss: 0.9772, Test Loss: 1.0918
Epoch: 26, Training Loss: 0.9821, Test Loss: 1.0684
Epoch: 27, Training Loss: 0.9780, Test Loss: 1.0825
Epoch: 28, Training Loss: 0.9745, Test Loss: 1.0703
Epoch: 29, Training Loss: 0.9685, Test Loss: 1.0606
Epoch: 30, Training Loss: 0.9655, Test Loss: 1.0795
Epoch: 31, Training Loss: 0.9577, Test Loss: 1.0633
Epoch: 32, Training Loss: 0.9538, Test Loss: 1.0473
Epoch: 33, Training Loss: 0.9461, Test Loss: 1.0480
Epoch: 34, Training Loss: 0.9370, Test Loss: 1.0611
Epoch: 35, Training Loss: 0.9310, Test Loss: 1.0462
Epoch: 36, Training Loss: 0.9263, Test Loss: 1.0377
Epoch: 37, Training Loss: 0.9205, Test Loss: 1.0288
Epoch: 38, Training Loss: 0.9136, Test Loss: 1.0150
Epoch: 39, Training Loss: 0.9052, Test Loss: 1.0231
Epoch: 40, Training Loss: 0.9061, Test Loss: 1.0114
Epoch: 41, Training Loss: 0.9001, Test Loss: 0.9975
Epoch: 42, Training Loss: 0.8953, Test Loss: 0.9992
Epoch: 43, Training Loss: 0.8887, Test Loss: 1.0062

 68%|██████████████████████████████████████████████████████████████████▋                               | 68/100 [00:05<00:02, 11.73it/s, loss_test=0.934]
Epoch: 45, Training Loss: 0.8847, Test Loss: 0.9990
Epoch: 46, Training Loss: 0.8839, Test Loss: 0.9868
Epoch: 47, Training Loss: 0.8769, Test Loss: 0.9795
Epoch: 48, Training Loss: 0.8724, Test Loss: 0.9986
Epoch: 49, Training Loss: 0.8713, Test Loss: 0.9837
Epoch: 50, Training Loss: 0.8642, Test Loss: 0.9893
Epoch: 51, Training Loss: 0.8647, Test Loss: 0.9728
Epoch: 52, Training Loss: 0.8587, Test Loss: 0.9858
Epoch: 53, Training Loss: 0.8543, Test Loss: 0.9585
Epoch: 54, Training Loss: 0.8534, Test Loss: 0.9586
Epoch: 55, Training Loss: 0.8480, Test Loss: 0.9537
Epoch: 56, Training Loss: 0.8446, Test Loss: 0.9652
Epoch: 57, Training Loss: 0.8435, Test Loss: 0.9605
Epoch: 58, Training Loss: 0.8360, Test Loss: 0.9479
Epoch: 59, Training Loss: 0.8356, Test Loss: 0.9412
Epoch: 60, Training Loss: 0.8331, Test Loss: 0.9540
Epoch: 61, Training Loss: 0.8261, Test Loss: 0.9381
Epoch: 62, Training Loss: 0.8252, Test Loss: 0.9482
Epoch: 63, Training Loss: 0.8216, Test Loss: 0.9389
Epoch: 64, Training Loss: 0.8183, Test Loss: 0.9315
Epoch: 65, Training Loss: 0.8122, Test Loss: 0.9526
Epoch: 66, Training Loss: 0.8156, Test Loss: 0.9477
Epoch: 67, Training Loss: 0.8125, Test Loss: 0.9335

 94%|████████████████████████████████████████████████████████████████████████████████████████████      | 94/100 [00:07<00:00, 12.32it/s, loss_test=0.920]
Epoch: 69, Training Loss: 0.8029, Test Loss: 0.9537
Epoch: 70, Training Loss: 0.8034, Test Loss: 0.9279
Epoch: 71, Training Loss: 0.8028, Test Loss: 0.9259
Epoch: 72, Training Loss: 0.7955, Test Loss: 0.9274
Epoch: 73, Training Loss: 0.7935, Test Loss: 0.9343
Epoch: 74, Training Loss: 0.7953, Test Loss: 0.9175
Epoch: 75, Training Loss: 0.7876, Test Loss: 0.9267
Epoch: 76, Training Loss: 0.7869, Test Loss: 0.9310
Epoch: 77, Training Loss: 0.7856, Test Loss: 0.9366
Epoch: 78, Training Loss: 0.7834, Test Loss: 0.9433
Epoch: 79, Training Loss: 0.7803, Test Loss: 0.9134
Epoch: 80, Training Loss: 0.7753, Test Loss: 0.9305
Epoch: 81, Training Loss: 0.7719, Test Loss: 0.9151
Epoch: 82, Training Loss: 0.7671, Test Loss: 0.9105
Epoch: 83, Training Loss: 0.7647, Test Loss: 0.9274
Epoch: 84, Training Loss: 0.7622, Test Loss: 0.9207
Epoch: 85, Training Loss: 0.7607, Test Loss: 0.9106
Epoch: 86, Training Loss: 0.7528, Test Loss: 0.9112
Epoch: 87, Training Loss: 0.7492, Test Loss: 0.9362
Epoch: 88, Training Loss: 0.7499, Test Loss: 0.9297
Epoch: 89, Training Loss: 0.7441, Test Loss: 0.9256
Epoch: 90, Training Loss: 0.7424, Test Loss: 0.9304
Epoch: 91, Training Loss: 0.7395, Test Loss: 0.9347

100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.18it/s, loss_test=0.906]
Epoch: 93, Training Loss: 0.7297, Test Loss: 0.9197
Epoch: 94, Training Loss: 0.7260, Test Loss: 0.9157
Epoch: 95, Training Loss: 0.7214, Test Loss: 0.9224
Epoch: 96, Training Loss: 0.7215, Test Loss: 0.9096
Epoch: 97, Training Loss: 0.7169, Test Loss: 0.9257
Epoch: 98, Training Loss: 0.7164, Test Loss: 0.9274
Epoch: 99, Training Loss: 0.7090, Test Loss: 0.9056
Model saved as model_3497988np.pt
Config : {'wandb': True, 'name': 'lstm-enc-dec-0.0001-2-12110000-3497988np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 100, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-DATA', 'teacher_forcing_ratio': -4.198030811863873e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9924697637557983, 0.9910409331321717, 0.9912068367004394, 0.9933504343032837, 0.991330087184906, 0.9923909664154053, 0.9862367749214173, 0.9890172839164734, 0.9895683288574219, 0.987230908870697, 0.9885733246803283, 0.9871643662452698, 0.9887368679046631, 0.9879867315292359, 0.9876631379127503, 0.9850007057189941, 0.9867673993110657, 0.9854162454605102, 0.9809572696685791, 0.9806313514709473, 0.9855718016624451, 0.9852240085601807, 0.9838218927383423, 0.9819332957267761, 0.9832016110420227, 0.9771571278572082, 0.9821391820907592, 0.9780378103256225, 0.9744746208190918, 0.9685140252113342, 0.965472674369812, 0.957746422290802, 0.9538001298904419, 0.9461410403251648, 0.9370369791984559, 0.931037986278534, 0.9262831211090088, 0.9204919695854187, 0.9136270642280578, 0.9052250742912292, 0.9061307549476624, 0.9000537157058716, 0.8953252077102661, 0.8887078404426575, 0.8898288369178772, 0.884656286239624, 0.883860981464386, 0.8768918633460998, 0.8723561406135559, 0.8712903261184692, 0.8641668438911438, 0.8647213816642761, 0.8586998343467712, 0.8543159008026123, 0.8534385919570923, 0.848007881641388, 0.8445736289024353, 0.8434545159339905, 0.8360209703445435, 0.83559148311615, 0.8331404209136963, 0.8260944962501526, 0.8252275586128235, 0.8216168642044067, 0.818335235118866, 0.8121729135513306, 0.8155726909637451, 0.8125080823898315, 0.8084484934806824, 0.8028837442398071, 0.8034392833709717, 0.8028366327285766, 0.7954617142677307, 0.793496561050415, 0.7953343272209168, 0.7876186966896057, 0.7869070887565612, 0.7856342315673828, 0.7834060192108154, 0.7803092718124389, 0.7752625346183777, 0.7719257593154907, 0.7670636296272277, 0.7647357821464539, 0.7621839880943299, 0.7606740117073059, 0.7528268456459045, 0.7491730213165283, 0.7499149799346924, 0.7440883874893188, 0.7424027800559998, 0.7394966602325439, 0.730922520160675, 0.7297403454780579, 0.7260325670242309, 0.7214091897010804, 0.7214617729187012, 0.7168737173080444, 0.7164068937301635, 0.7089709520339966], 'loss_test': [1.073484182357788, 1.087624430656433, 1.0899087190628052, 1.0857077836990356, 1.0697559118270874, 1.076655626296997, 1.081096887588501, 1.0809454917907715, 1.0935498476028442, 1.067728877067566, 1.0918678045272827, 1.0879522562026978, 1.0747904777526855, 1.0884785652160645, 1.082115650177002, 1.0835609436035156, 1.0732501745224, 1.0698823928833008, 1.086016058921814, 1.09666109085083, 1.0716886520385742, 1.0749963521957397, 1.0777238607406616, 1.0701724290847778, 1.0736994743347168, 1.09181809425354, 1.0684304237365723, 1.0824875831604004, 1.0703258514404297, 1.0606017112731934, 1.0794934034347534, 1.0632808208465576, 1.0472561120986938, 1.0480155944824219, 1.0611013174057007, 1.046228051185608, 1.0377217531204224, 1.0288153886795044, 1.0150105953216553, 1.0231060981750488, 1.0114197731018066, 0.9975063800811768, 0.9992392659187317, 1.0062483549118042, 0.9818269610404968, 0.9989540576934814, 0.9867653250694275, 0.9795397520065308, 0.9985636472702026, 0.9836814403533936, 0.9893057346343994, 0.9727778434753418, 0.9858264923095703, 0.9584646821022034, 0.9585667252540588, 0.953660249710083, 0.9651991128921509, 0.96047443151474, 0.9479032158851624, 0.9411724805831909, 0.9540011882781982, 0.9380749464035034, 0.9482025504112244, 0.9389136433601379, 0.9314836263656616, 0.9525853991508484, 0.9476662874221802, 0.9335142374038696, 0.9338964819908142, 0.9537282586097717, 0.9278507232666016, 0.9259456992149353, 0.9274024367332458, 0.9343082308769226, 0.9174630045890808, 0.9267055988311768, 0.9309875965118408, 0.9365731477737427, 0.943303644657135, 0.9133707880973816, 0.9304735064506531, 0.9150874018669128, 0.9104552865028381, 0.927424967288971, 0.9206700921058655, 0.910557210445404, 0.9112467765808105, 0.9361977577209473, 0.9297324419021606, 0.9255507588386536, 0.9304326772689819, 0.9346846342086792, 0.922336995601654, 0.9197478890419006, 0.9156592488288879, 0.9223994016647339, 0.9096001982688904, 0.9257323741912842, 0.9274120926856995, 0.9056177735328674], 'identifier': '3497988np'}