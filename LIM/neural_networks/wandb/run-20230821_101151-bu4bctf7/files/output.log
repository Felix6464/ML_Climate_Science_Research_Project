
 20%|███████████████████▌                                                                              | 20/100 [00:01<00:06, 12.16it/s, loss_test=1.070]
Epoch: 00, Training Loss: 0.9901, Test Loss: 1.1093
Epoch: 01, Training Loss: 0.9914, Test Loss: 1.0944
Epoch: 02, Training Loss: 0.9896, Test Loss: 1.0744
Epoch: 03, Training Loss: 0.9849, Test Loss: 1.0954
Epoch: 04, Training Loss: 0.9889, Test Loss: 1.0879
Epoch: 05, Training Loss: 0.9872, Test Loss: 1.1020
Epoch: 06, Training Loss: 0.9890, Test Loss: 1.0883
Epoch: 07, Training Loss: 0.9901, Test Loss: 1.0811
Epoch: 08, Training Loss: 0.9892, Test Loss: 1.0786
Epoch: 09, Training Loss: 0.9923, Test Loss: 1.0874
Epoch: 10, Training Loss: 0.9871, Test Loss: 1.0806
Epoch: 11, Training Loss: 0.9868, Test Loss: 1.0999
Epoch: 12, Training Loss: 0.9903, Test Loss: 1.0875
Epoch: 13, Training Loss: 0.9869, Test Loss: 1.0774
Epoch: 14, Training Loss: 0.9843, Test Loss: 1.0998
Epoch: 15, Training Loss: 0.9832, Test Loss: 1.0730
Epoch: 16, Training Loss: 0.9850, Test Loss: 1.0780
Epoch: 17, Training Loss: 0.9879, Test Loss: 1.0772
Epoch: 18, Training Loss: 0.9841, Test Loss: 1.0942
Epoch: 19, Training Loss: 0.9791, Test Loss: 1.0870

 46%|█████████████████████████████████████████████                                                     | 46/100 [00:03<00:04, 12.47it/s, loss_test=0.984]
Epoch: 21, Training Loss: 0.9830, Test Loss: 1.0960
Epoch: 22, Training Loss: 0.9846, Test Loss: 1.0809
Epoch: 23, Training Loss: 0.9831, Test Loss: 1.0737
Epoch: 24, Training Loss: 0.9811, Test Loss: 1.0885
Epoch: 25, Training Loss: 0.9796, Test Loss: 1.0793
Epoch: 26, Training Loss: 0.9777, Test Loss: 1.0772
Epoch: 27, Training Loss: 0.9821, Test Loss: 1.0757
Epoch: 28, Training Loss: 0.9770, Test Loss: 1.0729
Epoch: 29, Training Loss: 0.9735, Test Loss: 1.0867
Epoch: 30, Training Loss: 0.9724, Test Loss: 1.0698
Epoch: 31, Training Loss: 0.9638, Test Loss: 1.0822
Epoch: 32, Training Loss: 0.9597, Test Loss: 1.0644
Epoch: 33, Training Loss: 0.9538, Test Loss: 1.0366
Epoch: 34, Training Loss: 0.9421, Test Loss: 1.0450
Epoch: 35, Training Loss: 0.9349, Test Loss: 1.0462
Epoch: 36, Training Loss: 0.9254, Test Loss: 1.0393
Epoch: 37, Training Loss: 0.9160, Test Loss: 1.0180
Epoch: 38, Training Loss: 0.9112, Test Loss: 1.0225
Epoch: 39, Training Loss: 0.9023, Test Loss: 1.0068
Epoch: 40, Training Loss: 0.9001, Test Loss: 1.0118
Epoch: 41, Training Loss: 0.8928, Test Loss: 1.0109
Epoch: 42, Training Loss: 0.8902, Test Loss: 0.9988
Epoch: 43, Training Loss: 0.8826, Test Loss: 0.9968
Epoch: 44, Training Loss: 0.8810, Test Loss: 0.9903
Epoch: 45, Training Loss: 0.8775, Test Loss: 0.9842
Epoch: 46, Training Loss: 0.8722, Test Loss: 0.9889
Epoch: 47, Training Loss: 0.8670, Test Loss: 0.9668
Epoch: 48, Training Loss: 0.8622, Test Loss: 0.9479
Epoch: 49, Training Loss: 0.8566, Test Loss: 0.9563
Epoch: 50, Training Loss: 0.8530, Test Loss: 0.9540
Epoch: 51, Training Loss: 0.8491, Test Loss: 0.9556
Epoch: 52, Training Loss: 0.8482, Test Loss: 0.9445
Epoch: 53, Training Loss: 0.8435, Test Loss: 0.9479
Epoch: 54, Training Loss: 0.8352, Test Loss: 0.9516
Epoch: 55, Training Loss: 0.8316, Test Loss: 0.9425
Epoch: 56, Training Loss: 0.8294, Test Loss: 0.9540
Epoch: 57, Training Loss: 0.8227, Test Loss: 0.9405
Epoch: 58, Training Loss: 0.8167, Test Loss: 0.9327
Epoch: 59, Training Loss: 0.8121, Test Loss: 0.9256
Epoch: 60, Training Loss: 0.8084, Test Loss: 0.9268
Epoch: 61, Training Loss: 0.8065, Test Loss: 0.9249
Epoch: 62, Training Loss: 0.8030, Test Loss: 0.9324
Epoch: 63, Training Loss: 0.7978, Test Loss: 0.9186
Epoch: 64, Training Loss: 0.7879, Test Loss: 0.9260
Epoch: 65, Training Loss: 0.7901, Test Loss: 0.9112
Epoch: 66, Training Loss: 0.7845, Test Loss: 0.9013
Epoch: 67, Training Loss: 0.7795, Test Loss: 0.9214

 70%|████████████████████████████████████████████████████████████████████▌                             | 70/100 [00:05<00:02, 12.27it/s, loss_test=0.900]
Epoch: 69, Training Loss: 0.7731, Test Loss: 0.8996
Epoch: 70, Training Loss: 0.7707, Test Loss: 0.9200
Epoch: 71, Training Loss: 0.7638, Test Loss: 0.9013
Epoch: 72, Training Loss: 0.7586, Test Loss: 0.8999
Epoch: 73, Training Loss: 0.7573, Test Loss: 0.8926
Epoch: 74, Training Loss: 0.7513, Test Loss: 0.8992
Epoch: 75, Training Loss: 0.7503, Test Loss: 0.9040
Epoch: 76, Training Loss: 0.7455, Test Loss: 0.9006
Epoch: 77, Training Loss: 0.7405, Test Loss: 0.9077
Epoch: 78, Training Loss: 0.7370, Test Loss: 0.9011
Epoch: 79, Training Loss: 0.7338, Test Loss: 0.8924
Epoch: 80, Training Loss: 0.7308, Test Loss: 0.8946
Epoch: 81, Training Loss: 0.7280, Test Loss: 0.9077
Epoch: 82, Training Loss: 0.7214, Test Loss: 0.8949
Epoch: 83, Training Loss: 0.7189, Test Loss: 0.8918
Epoch: 84, Training Loss: 0.7156, Test Loss: 0.8960
Epoch: 85, Training Loss: 0.7072, Test Loss: 0.8978
Epoch: 86, Training Loss: 0.7056, Test Loss: 0.8992
Epoch: 87, Training Loss: 0.6987, Test Loss: 0.8819
Epoch: 88, Training Loss: 0.6982, Test Loss: 0.8824
Epoch: 89, Training Loss: 0.6916, Test Loss: 0.8949
Epoch: 90, Training Loss: 0.6875, Test Loss: 0.8976
Epoch: 91, Training Loss: 0.6855, Test Loss: 0.8979
Epoch: 92, Training Loss: 0.6803, Test Loss: 0.8937


100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.15it/s, loss_test=0.885]
Epoch: 94, Training Loss: 0.6722, Test Loss: 0.9047
Epoch: 95, Training Loss: 0.6696, Test Loss: 0.8947
Epoch: 96, Training Loss: 0.6664, Test Loss: 0.8847
Epoch: 97, Training Loss: 0.6598, Test Loss: 0.8826
Epoch: 98, Training Loss: 0.6573, Test Loss: 0.8874
Epoch: 99, Training Loss: 0.6537, Test Loss: 0.8849
Model saved as model_9935428np.pt
Config : {'wandb': True, 'name': 'lstm-enc-dec-0.0001-2-12190000-9935428np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 100, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-DATA', 'teacher_forcing_ratio': -4.198030811863873e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9901164770126343, 0.9913958668708801, 0.9896194696426391, 0.9849474787712097, 0.9888584852218628, 0.9872424483299256, 0.9890479207038879, 0.9901093602180481, 0.9891616225242614, 0.9923226237297058, 0.9870545029640198, 0.9868196249008179, 0.9903460741043091, 0.9869329333305359, 0.984296464920044, 0.9831724524497986, 0.9850434064865112, 0.9878508448600769, 0.9840880990028381, 0.9791244506835938, 0.9814833998680115, 0.9829923033714294, 0.9845766067504883, 0.983095383644104, 0.9810903072357178, 0.9795738101005554, 0.9777018904685975, 0.9820907235145568, 0.9769824266433715, 0.9734800219535827, 0.9724205374717713, 0.9638374209403991, 0.9596577763557435, 0.9538313508033752, 0.9420704960823059, 0.934919023513794, 0.9254034638404847, 0.9160189032554626, 0.9112354516983032, 0.9022796273231506, 0.9000540375709534, 0.8928417205810547, 0.8901970028877259, 0.8825998783111573, 0.8810386180877685, 0.8775246024131775, 0.872212815284729, 0.8670430779457092, 0.862241792678833, 0.8566393852233887, 0.8529566764831543, 0.8491056799888611, 0.8482253551483154, 0.8435405373573304, 0.8351563453674317, 0.8316499710083007, 0.8293519616127014, 0.8226864814758301, 0.8167347431182861, 0.8121132373809814, 0.8083958625793457, 0.8064539432525635, 0.803021514415741, 0.7978012204170227, 0.787894606590271, 0.7900659203529358, 0.7845349669456482, 0.7794947504997254, 0.776685631275177, 0.7731050014495849, 0.77067129611969, 0.7637606382369995, 0.7585753560066223, 0.7573199152946473, 0.7512889981269837, 0.7502536177635193, 0.745454478263855, 0.7405329704284668, 0.7370139598846436, 0.7337824583053589, 0.7307565808296204, 0.7279513597488403, 0.7213544845581055, 0.7189369678497315, 0.7155774354934692, 0.7072284102439881, 0.7056362271308899, 0.6987142086029052, 0.6982018828392029, 0.6916284918785095, 0.6875284790992737, 0.6855324029922485, 0.6803014993667602, 0.67679922580719, 0.6721921443939209, 0.6695510029792786, 0.6663810253143311, 0.6598037362098694, 0.657327675819397, 0.6537152886390686], 'loss_test': [1.1092966794967651, 1.094438076019287, 1.0744127035140991, 1.0953574180603027, 1.087855339050293, 1.1020097732543945, 1.088285207748413, 1.0810918807983398, 1.0786470174789429, 1.087388277053833, 1.0806288719177246, 1.0999232530593872, 1.0875381231307983, 1.0774378776550293, 1.099753737449646, 1.0730290412902832, 1.078008770942688, 1.077201247215271, 1.0942444801330566, 1.08696448802948, 1.0697746276855469, 1.0959669351577759, 1.0809372663497925, 1.07371985912323, 1.0884912014007568, 1.0792993307113647, 1.0771628618240356, 1.0757261514663696, 1.0729079246520996, 1.0866687297821045, 1.0697927474975586, 1.0822196006774902, 1.0643632411956787, 1.036636233329773, 1.0449626445770264, 1.0462344884872437, 1.0393321514129639, 1.0180140733718872, 1.0224757194519043, 1.0067731142044067, 1.0118478536605835, 1.010859489440918, 0.9987539649009705, 0.9967839121818542, 0.9903429746627808, 0.9841798543930054, 0.9888828992843628, 0.9667709469795227, 0.9479024410247803, 0.9563125967979431, 0.9540491700172424, 0.9555684924125671, 0.9444569945335388, 0.9479349255561829, 0.9516098499298096, 0.9424717426300049, 0.9539746046066284, 0.9404826760292053, 0.9326909780502319, 0.9255794286727905, 0.9267815947532654, 0.9249330759048462, 0.9324127435684204, 0.9185909628868103, 0.9260191321372986, 0.9112294912338257, 0.9013472199440002, 0.9213744401931763, 0.9177627563476562, 0.899550199508667, 0.9199936985969543, 0.901326596736908, 0.8999123573303223, 0.8925750851631165, 0.899217426776886, 0.9039930701255798, 0.9006422758102417, 0.9077238440513611, 0.90107661485672, 0.892413854598999, 0.8945589065551758, 0.9077236652374268, 0.8949498534202576, 0.8917754292488098, 0.896041989326477, 0.8977614045143127, 0.8991981148719788, 0.8819373250007629, 0.8823831677436829, 0.8949041962623596, 0.8976306915283203, 0.8979018330574036, 0.8936995267868042, 0.8897579908370972, 0.904746949672699, 0.8947426080703735, 0.8847388625144958, 0.8825762867927551, 0.8874233961105347, 0.8848533630371094], 'identifier': '9935428np'}