
 20%|███████████████████▌                                                                              | 20/100 [00:01<00:06, 12.62it/s, loss_test=1.077]
Epoch: 00, Training Loss: 0.9904, Test Loss: 1.0789
Epoch: 01, Training Loss: 0.9918, Test Loss: 1.0655
Epoch: 02, Training Loss: 0.9901, Test Loss: 1.0844
Epoch: 03, Training Loss: 0.9923, Test Loss: 1.0891
Epoch: 04, Training Loss: 0.9927, Test Loss: 1.0911
Epoch: 05, Training Loss: 0.9942, Test Loss: 1.0914
Epoch: 06, Training Loss: 0.9922, Test Loss: 1.0962
Epoch: 07, Training Loss: 0.9922, Test Loss: 1.0687
Epoch: 08, Training Loss: 0.9881, Test Loss: 1.0901
Epoch: 09, Training Loss: 0.9900, Test Loss: 1.0891
Epoch: 10, Training Loss: 0.9895, Test Loss: 1.0939
Epoch: 11, Training Loss: 0.9845, Test Loss: 1.0807
Epoch: 12, Training Loss: 0.9853, Test Loss: 1.0876
Epoch: 13, Training Loss: 0.9906, Test Loss: 1.0716
Epoch: 14, Training Loss: 0.9860, Test Loss: 1.0759
Epoch: 15, Training Loss: 0.9884, Test Loss: 1.0781
Epoch: 16, Training Loss: 0.9892, Test Loss: 1.0668
Epoch: 17, Training Loss: 0.9872, Test Loss: 1.0920
Epoch: 18, Training Loss: 0.9904, Test Loss: 1.0904
Epoch: 19, Training Loss: 0.9901, Test Loss: 1.0955

 44%|███████████████████████████████████████████                                                       | 44/100 [00:03<00:04, 11.40it/s, loss_test=1.003]
Epoch: 21, Training Loss: 0.9793, Test Loss: 1.0860
Epoch: 22, Training Loss: 0.9809, Test Loss: 1.0732
Epoch: 23, Training Loss: 0.9830, Test Loss: 1.0677
Epoch: 24, Training Loss: 0.9822, Test Loss: 1.0790
Epoch: 25, Training Loss: 0.9794, Test Loss: 1.0673
Epoch: 26, Training Loss: 0.9818, Test Loss: 1.0827
Epoch: 27, Training Loss: 0.9793, Test Loss: 1.0856
Epoch: 28, Training Loss: 0.9782, Test Loss: 1.0791
Epoch: 29, Training Loss: 0.9705, Test Loss: 1.0734
Epoch: 30, Training Loss: 0.9715, Test Loss: 1.0755
Epoch: 31, Training Loss: 0.9709, Test Loss: 1.0704
Epoch: 32, Training Loss: 0.9606, Test Loss: 1.0791
Epoch: 33, Training Loss: 0.9564, Test Loss: 1.0619
Epoch: 34, Training Loss: 0.9543, Test Loss: 1.0593
Epoch: 35, Training Loss: 0.9470, Test Loss: 1.0534
Epoch: 36, Training Loss: 0.9469, Test Loss: 1.0622
Epoch: 37, Training Loss: 0.9422, Test Loss: 1.0592
Epoch: 38, Training Loss: 0.9366, Test Loss: 1.0423
Epoch: 39, Training Loss: 0.9264, Test Loss: 1.0303
Epoch: 40, Training Loss: 0.9250, Test Loss: 1.0337
Epoch: 41, Training Loss: 0.9152, Test Loss: 1.0248
Epoch: 42, Training Loss: 0.9109, Test Loss: 1.0156
Epoch: 43, Training Loss: 0.8998, Test Loss: 1.0054

 70%|████████████████████████████████████████████████████████████████████▌                             | 70/100 [00:05<00:02, 12.86it/s, loss_test=0.947]
Epoch: 45, Training Loss: 0.8823, Test Loss: 1.0087
Epoch: 46, Training Loss: 0.8777, Test Loss: 0.9911
Epoch: 47, Training Loss: 0.8693, Test Loss: 0.9855
Epoch: 48, Training Loss: 0.8630, Test Loss: 0.9871
Epoch: 49, Training Loss: 0.8585, Test Loss: 0.9795
Epoch: 50, Training Loss: 0.8563, Test Loss: 0.9740
Epoch: 51, Training Loss: 0.8486, Test Loss: 0.9599
Epoch: 52, Training Loss: 0.8450, Test Loss: 0.9735
Epoch: 53, Training Loss: 0.8387, Test Loss: 0.9590
Epoch: 54, Training Loss: 0.8376, Test Loss: 0.9629
Epoch: 55, Training Loss: 0.8315, Test Loss: 0.9439
Epoch: 56, Training Loss: 0.8301, Test Loss: 0.9452
Epoch: 57, Training Loss: 0.8240, Test Loss: 0.9500
Epoch: 58, Training Loss: 0.8213, Test Loss: 0.9659
Epoch: 59, Training Loss: 0.8207, Test Loss: 0.9491
Epoch: 60, Training Loss: 0.8154, Test Loss: 0.9549
Epoch: 61, Training Loss: 0.8096, Test Loss: 0.9451
Epoch: 62, Training Loss: 0.8033, Test Loss: 0.9282
Epoch: 63, Training Loss: 0.8004, Test Loss: 0.9659
Epoch: 64, Training Loss: 0.7987, Test Loss: 0.9276
Epoch: 65, Training Loss: 0.7933, Test Loss: 0.9417
Epoch: 66, Training Loss: 0.7910, Test Loss: 0.9285
Epoch: 67, Training Loss: 0.7862, Test Loss: 0.9335
Epoch: 68, Training Loss: 0.7794, Test Loss: 0.9331

 94%|████████████████████████████████████████████████████████████████████████████████████████████      | 94/100 [00:07<00:00, 11.89it/s, loss_test=0.907]
Epoch: 70, Training Loss: 0.7712, Test Loss: 0.9348
Epoch: 71, Training Loss: 0.7692, Test Loss: 0.9257
Epoch: 72, Training Loss: 0.7628, Test Loss: 0.9294
Epoch: 73, Training Loss: 0.7626, Test Loss: 0.9459
Epoch: 74, Training Loss: 0.7559, Test Loss: 0.9299
Epoch: 75, Training Loss: 0.7514, Test Loss: 0.9261
Epoch: 76, Training Loss: 0.7467, Test Loss: 0.9376
Epoch: 77, Training Loss: 0.7446, Test Loss: 0.9306
Epoch: 78, Training Loss: 0.7406, Test Loss: 0.9120
Epoch: 79, Training Loss: 0.7377, Test Loss: 0.9199
Epoch: 80, Training Loss: 0.7327, Test Loss: 0.9225
Epoch: 81, Training Loss: 0.7313, Test Loss: 0.9155
Epoch: 82, Training Loss: 0.7271, Test Loss: 0.9294
Epoch: 83, Training Loss: 0.7204, Test Loss: 0.9105
Epoch: 84, Training Loss: 0.7220, Test Loss: 0.9190
Epoch: 85, Training Loss: 0.7158, Test Loss: 0.9160
Epoch: 86, Training Loss: 0.7112, Test Loss: 0.9001
Epoch: 87, Training Loss: 0.7063, Test Loss: 0.9178
Epoch: 88, Training Loss: 0.7051, Test Loss: 0.8980
Epoch: 89, Training Loss: 0.6988, Test Loss: 0.8991
Epoch: 90, Training Loss: 0.6964, Test Loss: 0.9100
Epoch: 91, Training Loss: 0.6951, Test Loss: 0.9073
Epoch: 92, Training Loss: 0.6933, Test Loss: 0.9098
Epoch: 93, Training Loss: 0.6878, Test Loss: 0.8907

100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.17it/s, loss_test=0.899]
Epoch: 95, Training Loss: 0.6786, Test Loss: 0.8832
Epoch: 96, Training Loss: 0.6771, Test Loss: 0.9089
Epoch: 97, Training Loss: 0.6751, Test Loss: 0.8938
Epoch: 98, Training Loss: 0.6710, Test Loss: 0.9050
Epoch: 99, Training Loss: 0.6631, Test Loss: 0.8994
Model saved as model_4632170np.pt
Config : {'wandb': True, 'name': 'lstm-enc-dec-0.0001-2-1280000-4632170np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 100, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-DATA', 'teacher_forcing_ratio': -4.198030811863873e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9903914928436279, 0.9917808771133423, 0.9901493668556214, 0.992342472076416, 0.9926694154739379, 0.9941741704940796, 0.9921646833419799, 0.9922057390213013, 0.9881319522857666, 0.9899559497833252, 0.9895072817802429, 0.9844512820243836, 0.9853410482406616, 0.990571916103363, 0.9860135912895203, 0.9884371519088745, 0.9891667366027832, 0.9871800899505615, 0.9904366612434388, 0.9901286244392395, 0.9865869283676147, 0.9793123841285706, 0.9808880805969238, 0.983005940914154, 0.9822186231613159, 0.9794373035430908, 0.9817904114723206, 0.9792550802230835, 0.9782282710075378, 0.9705002307891846, 0.9715237259864807, 0.9709214329719543, 0.9606478333473205, 0.9564350128173829, 0.9543185114860535, 0.9470227599143982, 0.9469088673591614, 0.9421943187713623, 0.9365895509719848, 0.9263580441474915, 0.924955403804779, 0.915206253528595, 0.9109362840652466, 0.8997521758079529, 0.893734335899353, 0.8823248386383057, 0.8777358174324036, 0.8692942500114441, 0.8630337834358215, 0.8585087656974792, 0.8562647342681885, 0.8486144185066223, 0.8450310945510864, 0.838699221611023, 0.8375549554824829, 0.8315286040306091, 0.8301238298416138, 0.8240498542785645, 0.8213178038597106, 0.8207272291183472, 0.8154459834098816, 0.8095624923706055, 0.8032906770706176, 0.8003926277160645, 0.7986536622047424, 0.7933415770530701, 0.7909532427787781, 0.7861878991127014, 0.779390835762024, 0.7735199332237244, 0.7711622238159179, 0.7691507339477539, 0.762810206413269, 0.7626028776168823, 0.755913496017456, 0.7514034032821655, 0.7467086434364318, 0.7446480989456177, 0.7406147956848145, 0.7377287864685058, 0.7326872944831848, 0.7313063144683838, 0.7271067380905152, 0.7203889966011048, 0.7220149517059327, 0.7158043265342713, 0.7111878633499146, 0.7063487052917481, 0.705051326751709, 0.6988211274147034, 0.696400249004364, 0.6950560450553894, 0.6932641386985778, 0.6877674102783203, 0.6849422216415405, 0.6786285161972045, 0.677050769329071, 0.6751282811164856, 0.6709588885307312, 0.6630889534950256], 'loss_test': [1.0788514614105225, 1.065464973449707, 1.0843513011932373, 1.0891329050064087, 1.091090440750122, 1.0913763046264648, 1.0961965322494507, 1.0686967372894287, 1.0901401042938232, 1.0890939235687256, 1.093889594078064, 1.0807000398635864, 1.0875517129898071, 1.07163405418396, 1.0759247541427612, 1.0780820846557617, 1.0667953491210938, 1.092032790184021, 1.0903866291046143, 1.0954993963241577, 1.0769323110580444, 1.0859754085540771, 1.0731910467147827, 1.067728042602539, 1.079010009765625, 1.0672783851623535, 1.0827181339263916, 1.0856257677078247, 1.0790739059448242, 1.0734155178070068, 1.0755033493041992, 1.0704156160354614, 1.0791255235671997, 1.0618669986724854, 1.0593070983886719, 1.0533664226531982, 1.0621980428695679, 1.0592312812805176, 1.0423355102539062, 1.030346393585205, 1.0337454080581665, 1.0247994661331177, 1.015628457069397, 1.0054253339767456, 1.0029683113098145, 1.0086957216262817, 0.9911177158355713, 0.9854907989501953, 0.9871481657028198, 0.9795445799827576, 0.9740440845489502, 0.9599207639694214, 0.9735321998596191, 0.9590259194374084, 0.9628578424453735, 0.9438642859458923, 0.9452425837516785, 0.9500041007995605, 0.9658606648445129, 0.949057936668396, 0.9549405574798584, 0.9450996518135071, 0.9282272458076477, 0.9658517241477966, 0.9276180863380432, 0.9417349100112915, 0.928518533706665, 0.9334503412246704, 0.9330822825431824, 0.9472056031227112, 0.9347613453865051, 0.9257141351699829, 0.9294281005859375, 0.9459114074707031, 0.9299294352531433, 0.9260796904563904, 0.9376362562179565, 0.9306210875511169, 0.911987841129303, 0.9198973178863525, 0.9225456714630127, 0.915485143661499, 0.929427981376648, 0.9105344414710999, 0.9189902544021606, 0.9159931540489197, 0.9000830054283142, 0.9178446531295776, 0.8979918956756592, 0.8991247415542603, 0.909953236579895, 0.9072977304458618, 0.9098289012908936, 0.8906599283218384, 0.9068705439567566, 0.883164644241333, 0.9089483618736267, 0.8938409090042114, 0.9050272703170776, 0.8993764519691467], 'identifier': '4632170np'}