

  3%|███                                                                                       | 1/30 [00:09<04:24,  9.13s/it, loss_test=1.005]

  7%|██████                                                                                    | 2/30 [00:17<04:08,  8.86s/it, loss_test=0.801]
Epoch: 01, Training Loss: 0.7492, Test Loss: 0.8007


 13%|████████████                                                                              | 4/30 [00:35<03:54,  9.02s/it, loss_test=0.673]

 17%|███████████████                                                                           | 5/30 [00:45<03:47,  9.11s/it, loss_test=0.651]

 20%|██████████████████                                                                        | 6/30 [00:54<03:35,  9.00s/it, loss_test=0.637]
Epoch: 05, Training Loss: 0.6257, Test Loss: 0.6374


 27%|████████████████████████                                                                  | 8/30 [01:11<03:15,  8.90s/it, loss_test=0.622]
Epoch: 07, Training Loss: 0.6111, Test Loss: 0.6222


 33%|█████████████████████████████▋                                                           | 10/30 [01:29<02:57,  8.87s/it, loss_test=0.612]

 37%|████████████████████████████████▋                                                        | 11/30 [01:38<02:48,  8.87s/it, loss_test=0.609]
Epoch: 10, Training Loss: 0.5973, Test Loss: 0.6088


 43%|██████████████████████████████████████▌                                                  | 13/30 [01:56<02:31,  8.91s/it, loss_test=0.603]
Epoch: 12, Training Loss: 0.5914, Test Loss: 0.6027

 47%|█████████████████████████████████████████▌                                               | 14/30 [02:05<02:24,  9.01s/it, loss_test=0.601]


 53%|███████████████████████████████████████████████▍                                         | 16/30 [02:23<02:08,  9.17s/it, loss_test=0.598]
Epoch: 15, Training Loss: 0.5852, Test Loss: 0.5977


 60%|█████████████████████████████████████████████████████▍                                   | 18/30 [02:41<01:48,  9.07s/it, loss_test=0.595]
Epoch: 17, Training Loss: 0.5821, Test Loss: 0.5949

 63%|████████████████████████████████████████████████████████▎                                | 19/30 [02:50<01:38,  8.96s/it, loss_test=0.594]


 70%|██████████████████████████████████████████████████████████████▎                          | 21/30 [03:08<01:19,  8.87s/it, loss_test=0.593]
Epoch: 20, Training Loss: 0.5785, Test Loss: 0.5925


 77%|████████████████████████████████████████████████████████████████████▏                    | 23/30 [03:25<01:01,  8.77s/it, loss_test=0.591]

 80%|███████████████████████████████████████████████████████████████████████▏                 | 24/30 [03:33<00:52,  8.69s/it, loss_test=0.591]
Epoch: 23, Training Loss: 0.5760, Test Loss: 0.5911

 83%|██████████████████████████████████████████████████████████████████████████▏              | 25/30 [03:42<00:43,  8.63s/it, loss_test=0.590]


 90%|████████████████████████████████████████████████████████████████████████████████         | 27/30 [03:59<00:25,  8.54s/it, loss_test=0.589]

 93%|███████████████████████████████████████████████████████████████████████████████████      | 28/30 [04:08<00:17,  8.56s/it, loss_test=0.590]
Epoch: 27, Training Loss: 0.5734, Test Loss: 0.5899


100%|█████████████████████████████████████████████████████████████████████████████████████████| 30/30 [04:25<00:00,  8.86s/it, loss_test=0.589]
Epoch: 29, Training Loss: 0.5724, Test Loss: 0.5894
Model saved as model_2611751np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-12100000-2611751np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-SPREAD', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9065074142300602, 0.7491632880090358, 0.6879852188157511, 0.6557250641859494, 0.6377599982769935, 0.625666597823957, 0.6175265682267619, 0.611120261661299, 0.6057876347403823, 0.6011629008548164, 0.5973404675394625, 0.5940809232411367, 0.5913815855324923, 0.5889751140451257, 0.5869046164737953, 0.5851672828852476, 0.5835357698110434, 0.5820924928991786, 0.5807614893048674, 0.5795378879313067, 0.5785379361756992, 0.577581524412274, 0.5766992419412285, 0.5759610253157633, 0.5751809390473278, 0.5745311465673831, 0.5739315586649018, 0.573401064663143, 0.5729112442814823, 0.5723536900984936], 'loss_test': [1.0052003593016894, 0.8006919144819944, 0.7187545131414365, 0.6727588776594553, 0.6509461437280362, 0.6374038438766431, 0.6286166883431948, 0.62222609267785, 0.6166534293920566, 0.6122128921441543, 0.6087685590371107, 0.6056997898297433, 0.6027143246088272, 0.6008866700606469, 0.5990484987313931, 0.5977348929796463, 0.5964667934637803, 0.5949038851719636, 0.594037766640003, 0.5932639802877719, 0.592513558574212, 0.5922053353144572, 0.5913785921457486, 0.5911074437392063, 0.5903787578527744, 0.5900113414495419, 0.5893413057694068, 0.5898545063458956, 0.5891550676180766, 0.5893527800456072], 'identifier': '2611751np'}