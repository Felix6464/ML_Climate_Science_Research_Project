

  3%|██▌                                                                           | 1/30 [00:17<08:28, 17.54s/it, loss_test=0.995]
Epoch: 00, Training Loss: 0.8190, Test Loss: 0.9948

  7%|█████▏                                                                        | 2/30 [00:35<08:10, 17.52s/it, loss_test=0.709]


 13%|██████████▍                                                                   | 4/30 [01:09<07:31, 17.37s/it, loss_test=0.645]
Epoch: 03, Training Loss: 0.6379, Test Loss: 0.6449

 17%|█████████████                                                                 | 5/30 [01:27<07:13, 17.35s/it, loss_test=0.633]

 20%|███████████████▌                                                              | 6/30 [01:44<06:57, 17.38s/it, loss_test=0.625]

 23%|██████████████████▏                                                           | 7/30 [02:01<06:37, 17.29s/it, loss_test=0.619]

 27%|████████████████████▊                                                         | 8/30 [02:19<06:23, 17.41s/it, loss_test=0.615]


 33%|█████████████████████████▋                                                   | 10/30 [02:53<05:46, 17.32s/it, loss_test=0.609]
Epoch: 09, Training Loss: 0.6046, Test Loss: 0.6089

 37%|████████████████████████████▏                                                | 11/30 [03:11<05:30, 17.41s/it, loss_test=0.607]

 40%|██████████████████████████████▊                                              | 12/30 [03:28<05:12, 17.37s/it, loss_test=0.605]

 43%|█████████████████████████████████▎                                           | 13/30 [03:46<04:57, 17.52s/it, loss_test=0.603]

 47%|███████████████████████████████████▉                                         | 14/30 [04:03<04:38, 17.39s/it, loss_test=0.602]


 53%|█████████████████████████████████████████                                    | 16/30 [04:38<04:03, 17.42s/it, loss_test=0.600]

 57%|███████████████████████████████████████████▋                                 | 17/30 [04:55<03:46, 17.40s/it, loss_test=0.598]
Epoch: 16, Training Loss: 0.5937, Test Loss: 0.5984


 63%|████████████████████████████████████████████████▊                            | 19/30 [05:30<03:10, 17.31s/it, loss_test=0.597]
Epoch: 18, Training Loss: 0.5919, Test Loss: 0.5970

 67%|███████████████████████████████████████████████████▎                         | 20/30 [05:47<02:53, 17.34s/it, loss_test=0.596]


 73%|████████████████████████████████████████████████████████▍                    | 22/30 [06:22<02:18, 17.33s/it, loss_test=0.595]
Epoch: 21, Training Loss: 0.5898, Test Loss: 0.5949


 80%|█████████████████████████████████████████████████████████████▌               | 24/30 [06:56<01:43, 17.21s/it, loss_test=0.594]
Epoch: 23, Training Loss: 0.5886, Test Loss: 0.5940

 83%|████████████████████████████████████████████████████████████████▏            | 25/30 [07:13<01:26, 17.27s/it, loss_test=0.594]


 90%|█████████████████████████████████████████████████████████████████████▎       | 27/30 [07:48<00:51, 17.20s/it, loss_test=0.593]
Epoch: 26, Training Loss: 0.5872, Test Loss: 0.5930

 93%|███████████████████████████████████████████████████████████████████████▊     | 28/30 [08:05<00:34, 17.38s/it, loss_test=0.592]


100%|█████████████████████████████████████████████████████████████████████████████| 30/30 [08:40<00:00, 17.35s/it, loss_test=0.592]
Epoch: 29, Training Loss: 0.5860, Test Loss: 0.5917
Model saved as model_1122600np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-12200000-1122600np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-30E-HORIZON', 'teacher_forcing_ratio': 0.19999999999999973, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 85790, 'loss_train': [0.8189705030588742, 0.6835377002024149, 0.6537918444085535, 0.6378501011817038, 0.6273913793572568, 0.6199904675889429, 0.61455932044154, 0.6104935861353686, 0.6072759044246726, 0.6046410434745586, 0.6023820316366176, 0.6004500376556515, 0.5987547961049198, 0.5972949882112069, 0.5959582333704363, 0.5947772640213439, 0.5936961648994264, 0.5927588812059366, 0.5919329930311589, 0.591159722560715, 0.5904737627517163, 0.5897911744497287, 0.5891967048802075, 0.588632890366679, 0.588088848780626, 0.5876084265639121, 0.5871537441195203, 0.5867507211789011, 0.5863095361599656, 0.5859714701758103], 'loss_test': [0.9948148039671091, 0.7092260590348488, 0.6643066089122723, 0.6448547459947758, 0.6330877164235482, 0.625195127649185, 0.6193680299016145, 0.6149180439802316, 0.6117361233784602, 0.6088584065437317, 0.6066674972191836, 0.6049772734061266, 0.6034121671930338, 0.6020891549877632, 0.6006038584388219, 0.5997090465747393, 0.5983902785258416, 0.5979293772043326, 0.5969959140205995, 0.5961781346645111, 0.5953338591334147, 0.5948553700477649, 0.5947038535124216, 0.5939996850032073, 0.5936398725861158, 0.5933169884941517, 0.5930118914215993, 0.5924340664194181, 0.5922836808440013, 0.5917446172008147], 'identifier': '1122600np'}