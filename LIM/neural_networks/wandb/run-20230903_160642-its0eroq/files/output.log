

  3%|██▌                                                                           | 1/30 [00:18<09:07, 18.88s/it, loss_test=0.996]

  7%|█████▏                                                                        | 2/30 [00:36<08:35, 18.39s/it, loss_test=0.677]

 10%|███████▊                                                                      | 3/30 [00:53<07:58, 17.72s/it, loss_test=0.627]

 13%|██████████▍                                                                   | 4/30 [01:10<07:33, 17.44s/it, loss_test=0.608]

 17%|█████████████                                                                 | 5/30 [01:27<07:12, 17.32s/it, loss_test=0.598]

 20%|███████████████▌                                                              | 6/30 [01:45<06:56, 17.35s/it, loss_test=0.592]
Epoch: 05, Training Loss: 0.5886, Test Loss: 0.5924


 27%|████████████████████▊                                                         | 8/30 [02:19<06:19, 17.25s/it, loss_test=0.586]

 30%|███████████████████████▍                                                      | 9/30 [02:36<06:02, 17.26s/it, loss_test=0.584]

 33%|█████████████████████████▋                                                   | 10/30 [02:54<05:44, 17.24s/it, loss_test=0.583]

 37%|████████████████████████████▏                                                | 11/30 [03:11<05:26, 17.20s/it, loss_test=0.582]
Epoch: 10, Training Loss: 0.5785, Test Loss: 0.5819


 43%|█████████████████████████████████▎                                           | 13/30 [03:45<04:51, 17.15s/it, loss_test=0.580]
Epoch: 12, Training Loss: 0.5770, Test Loss: 0.5802


 50%|██████████████████████████████████████▌                                      | 15/30 [04:19<04:16, 17.13s/it, loss_test=0.580]

 53%|█████████████████████████████████████████                                    | 16/30 [04:37<04:01, 17.25s/it, loss_test=0.579]
Epoch: 15, Training Loss: 0.5756, Test Loss: 0.5795


 60%|██████████████████████████████████████████████▏                              | 18/30 [05:12<03:29, 17.42s/it, loss_test=0.579]

 63%|████████████████████████████████████████████████▊                            | 19/30 [05:29<03:11, 17.38s/it, loss_test=0.579]

 67%|███████████████████████████████████████████████████▎                         | 20/30 [05:47<02:54, 17.44s/it, loss_test=0.579]
Epoch: 19, Training Loss: 0.5745, Test Loss: 0.5785


 73%|████████████████████████████████████████████████████████▍                    | 22/30 [06:22<02:19, 17.41s/it, loss_test=0.578]

 77%|███████████████████████████████████████████████████████████                  | 23/30 [06:39<02:01, 17.33s/it, loss_test=0.578]

 80%|█████████████████████████████████████████████████████████████▌               | 24/30 [06:56<01:43, 17.30s/it, loss_test=0.579]

 83%|████████████████████████████████████████████████████████████████▏            | 25/30 [07:13<01:26, 17.28s/it, loss_test=0.578]
Epoch: 24, Training Loss: 0.5736, Test Loss: 0.5784


 90%|█████████████████████████████████████████████████████████████████████▎       | 27/30 [07:48<00:51, 17.29s/it, loss_test=0.578]

 93%|███████████████████████████████████████████████████████████████████████▊     | 28/30 [08:05<00:34, 17.27s/it, loss_test=0.578]
Epoch: 27, Training Loss: 0.5732, Test Loss: 0.5783


100%|█████████████████████████████████████████████████████████████████████████████| 30/30 [08:40<00:00, 17.35s/it, loss_test=0.578]
Epoch: 29, Training Loss: 0.5729, Test Loss: 0.5783
Model saved as model_1570307np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-12200000-1570307np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-30E-HORIZON', 'teacher_forcing_ratio': 0.19999999999999973, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 164382, 'loss_train': [0.7825420427954971, 0.6478646789683405, 0.6160854833560151, 0.6018232838450935, 0.5936864222393926, 0.5886392152756589, 0.5852429687376973, 0.5827976998558638, 0.5809604719703828, 0.5795955770842438, 0.5785326899897584, 0.5776853325273177, 0.5770138878944481, 0.5764557285692751, 0.5760185093587402, 0.5756299123781489, 0.5753182901882405, 0.5750294981587402, 0.5747707808988419, 0.5745226487803655, 0.5743286395334696, 0.5741417784813011, 0.5739425153003738, 0.5737823371699613, 0.5736382745431305, 0.5734743805839071, 0.5733377714824589, 0.5731897751672052, 0.5730922585873024, 0.57293694562467], 'loss_test': [0.9955409278090184, 0.6769322506510295, 0.6266218809745251, 0.608223947768028, 0.5982880943860763, 0.5924367409868118, 0.5887058104077975, 0.5858505914608637, 0.5840663424669168, 0.5826661921082399, 0.5819296342058059, 0.5810180159333425, 0.5802022018111669, 0.5795565809194858, 0.5795783687096375, 0.5794864910153242, 0.5793961767966931, 0.5790246381209447, 0.5786729250580837, 0.5785256799979087, 0.5784327703026625, 0.5783976134963524, 0.578294864640786, 0.578504031476302, 0.5783880819112827, 0.5783976742472404, 0.5781428387913948, 0.5783458040692867, 0.5782249390314786, 0.5782992935333496], 'identifier': '1570307np'}