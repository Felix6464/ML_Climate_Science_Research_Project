

  3%|███▌                                                                                                      | 1/30 [00:17<08:20, 17.25s/it, loss_test=1.002]
Epoch: 00, Training Loss: 0.8362, Test Loss: 1.0023


 10%|██████████▌                                                                                               | 3/30 [00:51<07:42, 17.13s/it, loss_test=0.653]
Epoch: 02, Training Loss: 0.6374, Test Loss: 0.6535


 17%|█████████████████▋                                                                                        | 5/30 [01:25<07:10, 17.21s/it, loss_test=0.617]
Epoch: 04, Training Loss: 0.6082, Test Loss: 0.6166


 23%|████████████████████████▋                                                                                 | 7/30 [02:00<06:33, 17.13s/it, loss_test=0.602]
Epoch: 06, Training Loss: 0.5951, Test Loss: 0.6017


 30%|███████████████████████████████▊                                                                          | 9/30 [02:33<05:57, 17.02s/it, loss_test=0.594]
Epoch: 08, Training Loss: 0.5882, Test Loss: 0.5939


 37%|██████████████████████████████████████▌                                                                  | 11/30 [03:07<05:22, 16.96s/it, loss_test=0.590]
Epoch: 10, Training Loss: 0.5838, Test Loss: 0.5896


 43%|█████████████████████████████████████████████▌                                                           | 13/30 [03:41<04:48, 16.99s/it, loss_test=0.587]
Epoch: 12, Training Loss: 0.5810, Test Loss: 0.5867


 50%|████████████████████████████████████████████████████▌                                                    | 15/30 [04:15<04:14, 16.96s/it, loss_test=0.585]
Epoch: 14, Training Loss: 0.5792, Test Loss: 0.5848


 57%|███████████████████████████████████████████████████████████▌                                             | 17/30 [04:50<03:43, 17.22s/it, loss_test=0.584]

 60%|███████████████████████████████████████████████████████████████                                          | 18/30 [05:07<03:27, 17.28s/it, loss_test=0.584]
Epoch: 17, Training Loss: 0.5774, Test Loss: 0.5835


 67%|██████████████████████████████████████████████████████████████████████                                   | 20/30 [05:42<02:53, 17.32s/it, loss_test=0.583]

 70%|█████████████████████████████████████████████████████████████████████████▌                               | 21/30 [05:59<02:35, 17.24s/it, loss_test=0.583]

 73%|█████████████████████████████████████████████████████████████████████████████                            | 22/30 [06:16<02:17, 17.17s/it, loss_test=0.582]

 77%|████████████████████████████████████████████████████████████████████████████████▌                        | 23/30 [06:33<02:00, 17.17s/it, loss_test=0.583]
Epoch: 22, Training Loss: 0.5757, Test Loss: 0.5827


 83%|███████████████████████████████████████████████████████████████████████████████████████▌                 | 25/30 [07:07<01:25, 17.08s/it, loss_test=0.582]

 87%|███████████████████████████████████████████████████████████████████████████████████████████              | 26/30 [07:24<01:08, 17.01s/it, loss_test=0.582]

 90%|██████████████████████████████████████████████████████████████████████████████████████████████▌          | 27/30 [07:41<00:51, 17.04s/it, loss_test=0.582]

 93%|██████████████████████████████████████████████████████████████████████████████████████████████████       | 28/30 [07:58<00:34, 17.02s/it, loss_test=0.582]
Epoch: 27, Training Loss: 0.5746, Test Loss: 0.5820


100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [08:32<00:00, 17.08s/it, loss_test=0.582]
Epoch: 29, Training Loss: 0.5742, Test Loss: 0.5823
Model saved as model_4498234np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec_XLIM-0.0001-2-12200000-4498234np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 400000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-30E-HORIZON', 'teacher_forcing_ratio': 0.19999999999999973, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.8362497302881644, 0.6776741817798073, 0.6373636891617213, 0.6192751592817595, 0.6082302602953793, 0.6005588797724585, 0.5951423053335729, 0.5911897299274435, 0.5881575460512487, 0.585780914562728, 0.5838372418887007, 0.5822656521640125, 0.5809955989016596, 0.5799616054995608, 0.579156162481404, 0.5783904630551072, 0.5778699452355709, 0.5773688655104642, 0.576945505824966, 0.5765551184691755, 0.5762302387993159, 0.5759119082238842, 0.5756501723404663, 0.575400658244947, 0.5751832501122631, 0.5749819057312779, 0.5747483841672689, 0.5745590385884619, 0.5743856674907192, 0.5741683957997747], 'loss_test': [1.002347285548846, 0.7220227834887993, 0.6534790587730896, 0.6298183766313088, 0.6166368123048391, 0.6072734873264264, 0.6017115805775691, 0.5972237260295794, 0.5938686592838703, 0.5911702777330692, 0.5896299041998692, 0.5877197994253575, 0.58674634152498, 0.5857232304719778, 0.5847969595820476, 0.5842281480630239, 0.5838144990878228, 0.5835107939365582, 0.5833929444734867, 0.582636802815474, 0.5825591704402214, 0.5824951751109881, 0.5826750688063793, 0.5823521864337798, 0.5820266694212571, 0.5821176253450222, 0.5818355263043673, 0.5819757989583871, 0.5821464619575403, 0.5823116632990348], 'identifier': '4498234np'}