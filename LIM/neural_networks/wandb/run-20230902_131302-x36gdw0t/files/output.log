

  3%|██▊                                                                                 | 1/30 [00:16<08:12, 16.99s/it, loss_test=1.007]

  7%|█████▌                                                                              | 2/30 [00:27<06:06, 13.08s/it, loss_test=0.812]

 10%|████████▍                                                                           | 3/30 [00:41<06:01, 13.40s/it, loss_test=0.724]

 13%|███████████▏                                                                        | 4/30 [00:58<06:32, 15.11s/it, loss_test=0.679]
Epoch: 03, Training Loss: 0.6593, Test Loss: 0.6792


 20%|████████████████▊                                                                   | 6/30 [01:25<05:40, 14.20s/it, loss_test=0.641]

 23%|███████████████████▌                                                                | 7/30 [01:42<05:49, 15.21s/it, loss_test=0.631]
Epoch: 06, Training Loss: 0.6197, Test Loss: 0.6305



 30%|█████████████████████████▏                                                          | 9/30 [02:17<05:41, 16.27s/it, loss_test=0.618]
Epoch: 08, Training Loss: 0.6075, Test Loss: 0.6181


 37%|██████████████████████████████▍                                                    | 11/30 [02:37<04:06, 12.96s/it, loss_test=0.609]
Epoch: 10, Training Loss: 0.5984, Test Loss: 0.6091


 43%|███████████████████████████████████▉                                               | 13/30 [02:55<03:06, 10.95s/it, loss_test=0.603]
Epoch: 12, Training Loss: 0.5919, Test Loss: 0.6030


 50%|█████████████████████████████████████████▌                                         | 15/30 [03:13<02:30, 10.07s/it, loss_test=0.599]

 53%|████████████████████████████████████████████▎                                      | 16/30 [03:23<02:17,  9.83s/it, loss_test=0.597]
Epoch: 15, Training Loss: 0.5854, Test Loss: 0.5973


 60%|█████████████████████████████████████████████████▊                                 | 18/30 [03:41<01:54,  9.54s/it, loss_test=0.595]

 63%|████████████████████████████████████████████████████▌                              | 19/30 [03:50<01:43,  9.38s/it, loss_test=0.594]
Epoch: 18, Training Loss: 0.5808, Test Loss: 0.5941


 70%|██████████████████████████████████████████████████████████                         | 21/30 [04:09<01:24,  9.40s/it, loss_test=0.592]
Epoch: 20, Training Loss: 0.5785, Test Loss: 0.5924


 77%|███████████████████████████████████████████████████████████████▋                   | 23/30 [04:27<01:03,  9.08s/it, loss_test=0.591]

 80%|██████████████████████████████████████████████████████████████████▍                | 24/30 [04:35<00:53,  8.88s/it, loss_test=0.590]
Epoch: 23, Training Loss: 0.5759, Test Loss: 0.5905

 83%|█████████████████████████████████████████████████████████████████████▏             | 25/30 [04:44<00:44,  8.94s/it, loss_test=0.591]


 90%|██████████████████████████████████████████████████████████████████████████▋        | 27/30 [05:04<00:28,  9.44s/it, loss_test=0.590]
Epoch: 26, Training Loss: 0.5738, Test Loss: 0.5898


 97%|████████████████████████████████████████████████████████████████████████████████▏  | 29/30 [05:31<00:11, 11.79s/it, loss_test=0.590]

100%|███████████████████████████████████████████████████████████████████████████████████| 30/30 [05:47<00:00, 11.57s/it, loss_test=0.589]
Epoch: 29, Training Loss: 0.5722, Test Loss: 0.5892
Model saved as model_4440213np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-12100000-4440213np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-SPREAD', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9090532651751033, 0.7563745855411768, 0.6937439596696651, 0.6593471554827778, 0.6408926259467017, 0.6284722170550308, 0.6196504569315648, 0.6129855312707223, 0.6075002761769207, 0.6025621778580732, 0.5984145245709263, 0.5948722001178798, 0.5918708095402071, 0.5893905514325851, 0.5872361275739285, 0.5853545421209091, 0.5835757504452715, 0.5821043297703012, 0.5808081268827557, 0.5796117653776874, 0.5785053424782806, 0.5775415025132916, 0.5767113710497762, 0.5759296749101017, 0.5751484365035326, 0.5745043150889568, 0.5738396332377479, 0.5732341289738596, 0.572732667019079, 0.572161349948946], 'loss_test': [1.0065851035790565, 0.8118210457838498, 0.7243397560639259, 0.6792388554566946, 0.6541244204227741, 0.6406571849798545, 0.6305273412129818, 0.6235806678350155, 0.6180710261448835, 0.6130796919266382, 0.6091397599532054, 0.6055592424594439, 0.6029695375607564, 0.6009283631275861, 0.5986473743732159, 0.5972809275755515, 0.5962950892937489, 0.5948466712083572, 0.5940532371019706, 0.5931760875078348, 0.5923566902295138, 0.5915003357789456, 0.5912547398072022, 0.5904750063633307, 0.5906054140665592, 0.5898219431057955, 0.5897855995557247, 0.5895904314059478, 0.5898211170465518, 0.5891602853169808], 'identifier': '4440213np'}