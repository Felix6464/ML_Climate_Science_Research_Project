
  3%|██▌                                                                           | 1/30 [00:01<00:34,  1.19s/it, loss_test=0.992]
Epoch: 00, Training Loss: 1.0068, Test Loss: 0.9919

 10%|███████▊                                                                      | 3/30 [00:03<00:31,  1.18s/it, loss_test=0.991]

 13%|██████████▍                                                                   | 4/30 [00:04<00:30,  1.17s/it, loss_test=0.989]
Epoch: 03, Training Loss: 0.9915, Test Loss: 0.9895

 20%|███████████████▌                                                              | 6/30 [00:07<00:28,  1.17s/it, loss_test=0.926]
Epoch: 05, Training Loss: 0.9204, Test Loss: 0.9256

 27%|████████████████████▊                                                         | 8/30 [00:09<00:25,  1.15s/it, loss_test=0.875]
Epoch: 07, Training Loss: 0.8732, Test Loss: 0.8749

 33%|█████████████████████████▋                                                   | 10/30 [00:11<00:22,  1.14s/it, loss_test=0.840]

 37%|████████████████████████████▏                                                | 11/30 [00:12<00:21,  1.15s/it, loss_test=0.827]
Epoch: 10, Training Loss: 0.8211, Test Loss: 0.8271

 43%|█████████████████████████████████▎                                           | 13/30 [00:15<00:20,  1.18s/it, loss_test=0.804]
Epoch: 12, Training Loss: 0.7939, Test Loss: 0.8036

 50%|██████████████████████████████████████▌                                      | 15/30 [00:17<00:17,  1.19s/it, loss_test=0.783]

 53%|█████████████████████████████████████████                                    | 16/30 [00:18<00:16,  1.19s/it, loss_test=0.778]
Epoch: 15, Training Loss: 0.7612, Test Loss: 0.7783

 60%|██████████████████████████████████████████████▏                              | 18/30 [00:21<00:14,  1.19s/it, loss_test=0.763]
Epoch: 17, Training Loss: 0.7419, Test Loss: 0.7632

 67%|███████████████████████████████████████████████████▎                         | 20/30 [00:23<00:12,  1.21s/it, loss_test=0.750]
Epoch: 19, Training Loss: 0.7241, Test Loss: 0.7499

 70%|█████████████████████████████████████████████████████▉                       | 21/30 [00:24<00:11,  1.22s/it, loss_test=0.744]

 77%|███████████████████████████████████████████████████████████                  | 23/30 [00:27<00:08,  1.26s/it, loss_test=0.736]
Epoch: 22, Training Loss: 0.7018, Test Loss: 0.7359

 80%|█████████████████████████████████████████████████████████████▌               | 24/30 [00:29<00:07,  1.25s/it, loss_test=0.729]
Epoch: 24, Training Loss: 0.6898, Test Loss: 0.7294

 87%|██████████████████████████████████████████████████████████████████▋          | 26/30 [00:30<00:04,  1.19s/it, loss_test=0.726]

 93%|███████████████████████████████████████████████████████████████████████▊     | 28/30 [00:33<00:02,  1.21s/it, loss_test=0.723]
Epoch: 27, Training Loss: 0.6726, Test Loss: 0.7226

100%|█████████████████████████████████████████████████████████████████████████████| 30/30 [00:35<00:00,  1.19s/it, loss_test=0.718]
Epoch: 29, Training Loss: 0.6623, Test Loss: 0.7176
Model saved as model_9251776np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-128000-9251776np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-50E-DATA', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [1.0068138297214064, 1.004138964553212, 1.0013086213621982, 0.9915195453998654, 0.9544892519019371, 0.9203768677489702, 0.8956227995628534, 0.8732335179351097, 0.8535852252050887, 0.8363658910573915, 0.8211143557415452, 0.8068255172219387, 0.7938650430634965, 0.7814578885255858, 0.7711622631827066, 0.7612449041632718, 0.7515903849934422, 0.7418641212374665, 0.7335266595663026, 0.7241106379863828, 0.7158870599990668, 0.7079107206921245, 0.7018429914186167, 0.6951484583144965, 0.6898328883703365, 0.6834539812664653, 0.678087806978891, 0.6726078169290409, 0.6673365055128585, 0.6623179330382236], 'loss_test': [0.9918525318304697, 0.9908866683642069, 0.9912242442369461, 0.9894799143075943, 0.9663624962170919, 0.9256116896867752, 0.8965323766072592, 0.8748865524927775, 0.8570952415466309, 0.8402442038059235, 0.8270564377307892, 0.8161515643199285, 0.8035959998766581, 0.7940912544727325, 0.7833775728940964, 0.7782728672027588, 0.7710251361131668, 0.7632471521695455, 0.7547733883062998, 0.7498817493518194, 0.7442296097675959, 0.7399283001820246, 0.7359101623296738, 0.7332988232374191, 0.7294126699368159, 0.7264413237571716, 0.7233952482541403, 0.7226365208625793, 0.7197178800900778, 0.7176331728696823], 'identifier': '9251776np'}