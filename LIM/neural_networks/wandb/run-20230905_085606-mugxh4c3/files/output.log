

  3%|██▋                                                                            | 1/30 [00:09<04:30,  9.33s/it, loss_test=0.994]
Epoch: 00, Training Loss: 0.6769, Test Loss: 0.9936

  7%|█████▎                                                                         | 2/30 [00:18<04:12,  9.00s/it, loss_test=0.477]

 10%|███████▉                                                                       | 3/30 [00:27<04:03,  9.03s/it, loss_test=0.402]

 13%|██████████▌                                                                    | 4/30 [00:36<03:53,  8.97s/it, loss_test=0.373]

 17%|█████████████▏                                                                 | 5/30 [00:44<03:43,  8.92s/it, loss_test=0.358]

 20%|███████████████▊                                                               | 6/30 [00:54<03:36,  9.00s/it, loss_test=0.349]

 23%|██████████████████▍                                                            | 7/30 [01:03<03:28,  9.07s/it, loss_test=0.344]


 30%|███████████████████████▋                                                       | 9/30 [01:21<03:12,  9.18s/it, loss_test=0.340]
Epoch: 08, Training Loss: 0.3369, Test Loss: 0.3403

 33%|██████████████████████████                                                    | 10/30 [01:30<03:02,  9.11s/it, loss_test=0.339]

 37%|████████████████████████████▌                                                 | 11/30 [01:39<02:50,  8.97s/it, loss_test=0.338]


 43%|█████████████████████████████████▊                                            | 13/30 [01:57<02:34,  9.07s/it, loss_test=0.337]
Epoch: 12, Training Loss: 0.3337, Test Loss: 0.3369


 50%|███████████████████████████████████████                                       | 15/30 [02:16<02:16,  9.13s/it, loss_test=0.336]
Epoch: 14, Training Loss: 0.3329, Test Loss: 0.3361


 57%|████████████████████████████████████████████▏                                 | 17/30 [02:33<01:57,  9.01s/it, loss_test=0.336]
Epoch: 16, Training Loss: 0.3322, Test Loss: 0.3356


 63%|█████████████████████████████████████████████████▍                            | 19/30 [02:52<01:39,  9.09s/it, loss_test=0.335]
Epoch: 18, Training Loss: 0.3318, Test Loss: 0.3352

 67%|████████████████████████████████████████████████████                          | 20/30 [03:01<01:31,  9.13s/it, loss_test=0.335]


 73%|█████████████████████████████████████████████████████████▏                    | 22/30 [03:20<01:13,  9.24s/it, loss_test=0.335]

 77%|███████████████████████████████████████████████████████████▊                  | 23/30 [03:30<01:05,  9.40s/it, loss_test=0.335]

 80%|██████████████████████████████████████████████████████████████▍               | 24/30 [03:39<00:57,  9.51s/it, loss_test=0.335]
Epoch: 23, Training Loss: 0.3309, Test Loss: 0.3347


 87%|███████████████████████████████████████████████████████████████████▌          | 26/30 [03:58<00:37,  9.43s/it, loss_test=0.335]
Epoch: 25, Training Loss: 0.3306, Test Loss: 0.3347

 90%|██████████████████████████████████████████████████████████████████████▏       | 27/30 [04:07<00:27,  9.27s/it, loss_test=0.335]

 93%|████████████████████████████████████████████████████████████████████████▊     | 28/30 [04:17<00:18,  9.40s/it, loss_test=0.334]


100%|██████████████████████████████████████████████████████████████████████████████| 30/30 [04:35<00:00,  9.20s/it, loss_test=0.335]
Epoch: 29, Training Loss: 0.3302, Test Loss: 0.3346
Model saved as model_448978np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-4200000-448978np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 4, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-30E-HORIZON', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 900, 'num_of_params': 217886, 'loss_train': [0.6769245006246296, 0.42966945958813724, 0.38371416236540645, 0.3623541781690725, 0.3508366492507879, 0.3444355669255008, 0.34077934848531494, 0.3384699669052239, 0.336912460618355, 0.3357857666698379, 0.3349331824853675, 0.33428894996315867, 0.33371630908149374, 0.333262150181834, 0.3328989743913736, 0.3325378958336934, 0.33223991192815944, 0.3319913243222215, 0.3317705618059101, 0.33154326412837004, 0.3313680744890979, 0.33118950606264985, 0.3310553239009191, 0.33090916644076307, 0.33076155455638157, 0.3306113493791547, 0.33051713733965393, 0.33043415665844655, 0.3303135073414006, 0.33021891397941255], 'loss_test': [0.9935916079542576, 0.47665599724039054, 0.4016680646783266, 0.37274715992120594, 0.3575381079736428, 0.34920323993533087, 0.3444936421628182, 0.34186035757645583, 0.3402900404463976, 0.339009376290517, 0.338096489604467, 0.3374127007256716, 0.33689303457354886, 0.3366589741064952, 0.33613579510114133, 0.33614509772413814, 0.3356314027347626, 0.3353385291993618, 0.3351996021393018, 0.3352054435855303, 0.3350822101227748, 0.3349226760940674, 0.33492622362115443, 0.33470640665827656, 0.3346054354348244, 0.3346978801374252, 0.33451607641883385, 0.33444797133023924, 0.3345654042294392, 0.3346150188873976], 'identifier': '448978np'}