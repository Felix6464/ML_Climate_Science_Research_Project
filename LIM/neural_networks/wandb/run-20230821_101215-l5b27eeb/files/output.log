
 20%|███████████████████▌                                                                              | 20/100 [00:01<00:06, 11.96it/s, loss_test=1.087]
Epoch: 00, Training Loss: 0.9935, Test Loss: 1.0923
Epoch: 01, Training Loss: 0.9936, Test Loss: 1.0787
Epoch: 02, Training Loss: 0.9942, Test Loss: 1.1020
Epoch: 03, Training Loss: 0.9954, Test Loss: 1.0603
Epoch: 04, Training Loss: 0.9907, Test Loss: 1.0737
Epoch: 05, Training Loss: 0.9916, Test Loss: 1.0742
Epoch: 06, Training Loss: 0.9952, Test Loss: 1.0870
Epoch: 07, Training Loss: 0.9889, Test Loss: 1.0764
Epoch: 08, Training Loss: 0.9864, Test Loss: 1.0789
Epoch: 09, Training Loss: 0.9867, Test Loss: 1.0746
Epoch: 10, Training Loss: 0.9900, Test Loss: 1.0846
Epoch: 11, Training Loss: 0.9867, Test Loss: 1.0802
Epoch: 12, Training Loss: 0.9872, Test Loss: 1.0730
Epoch: 13, Training Loss: 0.9901, Test Loss: 1.0803
Epoch: 14, Training Loss: 0.9911, Test Loss: 1.0850
Epoch: 15, Training Loss: 0.9919, Test Loss: 1.0661
Epoch: 16, Training Loss: 0.9846, Test Loss: 1.0877
Epoch: 17, Training Loss: 0.9817, Test Loss: 1.0864
Epoch: 18, Training Loss: 0.9874, Test Loss: 1.0884
Epoch: 19, Training Loss: 0.9875, Test Loss: 1.0547

 44%|███████████████████████████████████████████                                                       | 44/100 [00:03<00:04, 12.08it/s, loss_test=1.008]
Epoch: 21, Training Loss: 0.9853, Test Loss: 1.0753
Epoch: 22, Training Loss: 0.9842, Test Loss: 1.0757
Epoch: 23, Training Loss: 0.9863, Test Loss: 1.0854
Epoch: 24, Training Loss: 0.9837, Test Loss: 1.0862
Epoch: 25, Training Loss: 0.9813, Test Loss: 1.0736
Epoch: 26, Training Loss: 0.9847, Test Loss: 1.0706
Epoch: 27, Training Loss: 0.9780, Test Loss: 1.0638
Epoch: 28, Training Loss: 0.9792, Test Loss: 1.0654
Epoch: 29, Training Loss: 0.9785, Test Loss: 1.0800
Epoch: 30, Training Loss: 0.9754, Test Loss: 1.0854
Epoch: 31, Training Loss: 0.9710, Test Loss: 1.1066
Epoch: 32, Training Loss: 0.9687, Test Loss: 1.0714
Epoch: 33, Training Loss: 0.9599, Test Loss: 1.0554
Epoch: 34, Training Loss: 0.9578, Test Loss: 1.0657
Epoch: 35, Training Loss: 0.9472, Test Loss: 1.0497
Epoch: 36, Training Loss: 0.9432, Test Loss: 1.0515
Epoch: 37, Training Loss: 0.9312, Test Loss: 1.0372
Epoch: 38, Training Loss: 0.9329, Test Loss: 1.0382
Epoch: 39, Training Loss: 0.9269, Test Loss: 1.0436
Epoch: 40, Training Loss: 0.9221, Test Loss: 1.0373
Epoch: 41, Training Loss: 0.9091, Test Loss: 1.0266
Epoch: 42, Training Loss: 0.9007, Test Loss: 1.0039
Epoch: 43, Training Loss: 0.9001, Test Loss: 1.0002

 70%|████████████████████████████████████████████████████████████████████▌                             | 70/100 [00:05<00:02, 11.96it/s, loss_test=0.929]
Epoch: 45, Training Loss: 0.8902, Test Loss: 1.0044
Epoch: 46, Training Loss: 0.8872, Test Loss: 0.9972
Epoch: 47, Training Loss: 0.8788, Test Loss: 1.0149
Epoch: 48, Training Loss: 0.8756, Test Loss: 1.0063
Epoch: 49, Training Loss: 0.8694, Test Loss: 0.9784
Epoch: 50, Training Loss: 0.8590, Test Loss: 0.9919
Epoch: 51, Training Loss: 0.8561, Test Loss: 0.9790
Epoch: 52, Training Loss: 0.8498, Test Loss: 0.9797
Epoch: 53, Training Loss: 0.8469, Test Loss: 0.9653
Epoch: 54, Training Loss: 0.8396, Test Loss: 0.9799
Epoch: 55, Training Loss: 0.8380, Test Loss: 0.9658
Epoch: 56, Training Loss: 0.8301, Test Loss: 0.9686
Epoch: 57, Training Loss: 0.8242, Test Loss: 0.9467
Epoch: 58, Training Loss: 0.8214, Test Loss: 0.9661
Epoch: 59, Training Loss: 0.8174, Test Loss: 0.9541
Epoch: 60, Training Loss: 0.8129, Test Loss: 0.9462
Epoch: 61, Training Loss: 0.8071, Test Loss: 0.9478
Epoch: 62, Training Loss: 0.8073, Test Loss: 0.9481
Epoch: 63, Training Loss: 0.7987, Test Loss: 0.9423
Epoch: 64, Training Loss: 0.7950, Test Loss: 0.9371
Epoch: 65, Training Loss: 0.7928, Test Loss: 0.9294
Epoch: 66, Training Loss: 0.7921, Test Loss: 0.9254
Epoch: 67, Training Loss: 0.7823, Test Loss: 0.9383

 94%|████████████████████████████████████████████████████████████████████████████████████████████      | 94/100 [00:07<00:00, 12.34it/s, loss_test=0.937]
Epoch: 69, Training Loss: 0.7768, Test Loss: 0.9290
Epoch: 70, Training Loss: 0.7740, Test Loss: 0.9344
Epoch: 71, Training Loss: 0.7698, Test Loss: 0.9318
Epoch: 72, Training Loss: 0.7675, Test Loss: 0.9342
Epoch: 73, Training Loss: 0.7637, Test Loss: 0.9369
Epoch: 74, Training Loss: 0.7588, Test Loss: 0.9282
Epoch: 75, Training Loss: 0.7555, Test Loss: 0.9324
Epoch: 76, Training Loss: 0.7522, Test Loss: 0.9321
Epoch: 77, Training Loss: 0.7488, Test Loss: 0.9058
Epoch: 78, Training Loss: 0.7451, Test Loss: 0.9169
Epoch: 79, Training Loss: 0.7394, Test Loss: 0.9270
Epoch: 80, Training Loss: 0.7365, Test Loss: 0.9091
Epoch: 81, Training Loss: 0.7363, Test Loss: 0.9185
Epoch: 82, Training Loss: 0.7324, Test Loss: 0.9226
Epoch: 83, Training Loss: 0.7271, Test Loss: 0.9210
Epoch: 84, Training Loss: 0.7236, Test Loss: 0.9199
Epoch: 85, Training Loss: 0.7175, Test Loss: 0.9156
Epoch: 86, Training Loss: 0.7155, Test Loss: 0.9152
Epoch: 87, Training Loss: 0.7125, Test Loss: 0.9196
Epoch: 88, Training Loss: 0.7068, Test Loss: 0.9201
Epoch: 89, Training Loss: 0.7060, Test Loss: 0.9185
Epoch: 90, Training Loss: 0.6975, Test Loss: 0.9120
Epoch: 91, Training Loss: 0.6980, Test Loss: 0.9129
Epoch: 92, Training Loss: 0.6904, Test Loss: 0.9162

100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.10it/s, loss_test=0.911]
Epoch: 94, Training Loss: 0.6833, Test Loss: 0.9185
Epoch: 95, Training Loss: 0.6830, Test Loss: 0.9131
Epoch: 96, Training Loss: 0.6803, Test Loss: 0.9169
Epoch: 97, Training Loss: 0.6778, Test Loss: 0.9234
Epoch: 98, Training Loss: 0.6719, Test Loss: 0.9087
Epoch: 99, Training Loss: 0.6677, Test Loss: 0.9113
Model saved as model_3172157np.pt
Config : {'wandb': True, 'name': 'lstm-enc-dec-0.0001-2-12200000-3172157np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 100, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-DATA', 'teacher_forcing_ratio': -4.198030811863873e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9935389637947083, 0.9936259746551513, 0.9942379117012023, 0.9954033732414246, 0.9907095909118653, 0.9916332483291626, 0.9951544642448426, 0.9888694405555725, 0.9864223599433899, 0.9867280006408692, 0.9900099396705627, 0.9866944551467896, 0.9872358441352844, 0.9901300311088562, 0.9910855531692505, 0.9919095039367676, 0.9846142649650573, 0.9816707372665405, 0.9873545169830322, 0.9874980092048645, 0.9843944430351257, 0.9853379249572753, 0.9841764330863952, 0.9863255858421326, 0.9836656332015992, 0.9813096404075623, 0.9846702575683594, 0.9780405402183533, 0.9791904568672181, 0.9785249948501586, 0.9754468441009522, 0.9709952235221863, 0.9686882376670838, 0.9599245071411133, 0.9577859520912171, 0.9471826791763306, 0.9431561350822448, 0.9311809182167053, 0.9329177498817444, 0.9268645882606507, 0.9220735669136048, 0.9090605258941651, 0.9006638765335083, 0.9000884652137756, 0.8916127562522889, 0.8901612877845764, 0.8872120261192322, 0.8787585973739624, 0.8756239533424377, 0.86937917470932, 0.8590327143669129, 0.8561077952384949, 0.8498170614242554, 0.8469191431999207, 0.8395946502685547, 0.8379560470581054, 0.8300587773323059, 0.8241891384124755, 0.8214401602745056, 0.8174195051193237, 0.8128705859184265, 0.8071211099624633, 0.8073471665382386, 0.7987073063850403, 0.7949594855308533, 0.7927604675292969, 0.7921022295951843, 0.7823016285896301, 0.7813422322273255, 0.7767853498458862, 0.7739660739898682, 0.7698164820671082, 0.7675177454948425, 0.7637351989746094, 0.7588388562202454, 0.7554579138755798, 0.7522277593612671, 0.7488472580909729, 0.7451311230659485, 0.7393602132797241, 0.7365277528762817, 0.7363037228584289, 0.7323584914207458, 0.7270990133285522, 0.7235972881317139, 0.7174812197685242, 0.7154870510101319, 0.712500250339508, 0.7068454265594483, 0.7060069918632508, 0.6975413918495178, 0.6980329036712647, 0.6903637409210205, 0.6870343089103699, 0.6833171486854553, 0.6830419421195983, 0.6802950501441956, 0.677836787700653, 0.6719488263130188, 0.6676965236663819], 'loss_test': [1.0922801494598389, 1.0787488222122192, 1.1019903421401978, 1.060306191444397, 1.073655605316162, 1.0742136240005493, 1.0870152711868286, 1.0764268636703491, 1.0789098739624023, 1.0745790004730225, 1.0846039056777954, 1.0801925659179688, 1.0729832649230957, 1.0803234577178955, 1.084999442100525, 1.0661171674728394, 1.0876997709274292, 1.0864081382751465, 1.088409662246704, 1.0547288656234741, 1.0870592594146729, 1.0752803087234497, 1.075723648071289, 1.0853568315505981, 1.0862065553665161, 1.0735872983932495, 1.070562481880188, 1.0638127326965332, 1.0654290914535522, 1.0799660682678223, 1.0854475498199463, 1.1065831184387207, 1.071433663368225, 1.0554451942443848, 1.0656757354736328, 1.0497068166732788, 1.0514516830444336, 1.0371547937393188, 1.0382320880889893, 1.04362154006958, 1.0373419523239136, 1.0265681743621826, 1.0038830041885376, 1.0002326965332031, 1.0080662965774536, 1.0044013261795044, 0.9971771240234375, 1.0148969888687134, 1.0062798261642456, 0.9784262776374817, 0.9919204115867615, 0.979048490524292, 0.9796513319015503, 0.9652990102767944, 0.9798657298088074, 0.9657918810844421, 0.9685636758804321, 0.9467435479164124, 0.9661009311676025, 0.9541383981704712, 0.9461938142776489, 0.9477949738502502, 0.9481493830680847, 0.942338228225708, 0.9370968341827393, 0.9294331073760986, 0.9253519773483276, 0.938345193862915, 0.9170443415641785, 0.9289613962173462, 0.9343719482421875, 0.931807279586792, 0.9342325925827026, 0.9368797540664673, 0.9282084107398987, 0.9324321746826172, 0.9321131706237793, 0.9057703614234924, 0.916920006275177, 0.9270341992378235, 0.909050703048706, 0.918471097946167, 0.9226077795028687, 0.9210347533226013, 0.9199059009552002, 0.9155857563018799, 0.9152494668960571, 0.9196417927742004, 0.9201120138168335, 0.9185448884963989, 0.9119552969932556, 0.9128875732421875, 0.9161655306816101, 0.9371128082275391, 0.9184872508049011, 0.9131361246109009, 0.9168522357940674, 0.9233819842338562, 0.9087229371070862, 0.9112590551376343], 'identifier': '3172157np'}