

  3%|██▎                                                                  | 1/30 [00:05<02:30,  5.18s/it, loss_test=1.020]
Epoch: 00, Training Loss: 0.9478, Test Loss: 1.0205


 10%|██████▉                                                              | 3/30 [00:15<02:21,  5.23s/it, loss_test=0.782]
Epoch: 02, Training Loss: 0.7513, Test Loss: 0.7822


 17%|███████████▌                                                         | 5/30 [00:26<02:09,  5.18s/it, loss_test=0.711]

 20%|█████████████▊                                                       | 6/30 [00:31<02:04,  5.19s/it, loss_test=0.681]
Epoch: 05, Training Loss: 0.6587, Test Loss: 0.6814


 27%|██████████████████▍                                                  | 8/30 [00:41<01:55,  5.26s/it, loss_test=0.652]
Epoch: 07, Training Loss: 0.6332, Test Loss: 0.6517


 33%|██████████████████████▋                                             | 10/30 [00:52<01:44,  5.20s/it, loss_test=0.638]

 37%|████████████████████████▉                                           | 11/30 [00:57<01:39,  5.21s/it, loss_test=0.633]
Epoch: 10, Training Loss: 0.6145, Test Loss: 0.6330


 43%|█████████████████████████████▍                                      | 13/30 [01:08<01:30,  5.30s/it, loss_test=0.626]

 47%|███████████████████████████████▋                                    | 14/30 [01:13<01:24,  5.29s/it, loss_test=0.622]
Epoch: 13, Training Loss: 0.6030, Test Loss: 0.6225


 53%|████████████████████████████████████▎                               | 16/30 [01:24<01:14,  5.34s/it, loss_test=0.618]

 57%|██████████████████████████████████████▌                             | 17/30 [01:29<01:08,  5.29s/it, loss_test=0.616]
Epoch: 16, Training Loss: 0.5946, Test Loss: 0.6158


 63%|███████████████████████████████████████████                         | 19/30 [01:39<00:57,  5.21s/it, loss_test=0.613]
Epoch: 18, Training Loss: 0.5901, Test Loss: 0.6126


 70%|███████████████████████████████████████████████▌                    | 21/30 [01:49<00:46,  5.16s/it, loss_test=0.610]
Epoch: 20, Training Loss: 0.5863, Test Loss: 0.6099


 77%|████████████████████████████████████████████████████▏               | 23/30 [02:00<00:36,  5.21s/it, loss_test=0.607]

 80%|██████████████████████████████████████████████████████▍             | 24/30 [02:05<00:31,  5.33s/it, loss_test=0.606]

 83%|████████████████████████████████████████████████████████▋           | 25/30 [02:11<00:27,  5.45s/it, loss_test=0.606]
Epoch: 24, Training Loss: 0.5804, Test Loss: 0.6056


 90%|█████████████████████████████████████████████████████████████▏      | 27/30 [02:22<00:16,  5.39s/it, loss_test=0.604]

 93%|███████████████████████████████████████████████████████████████▍    | 28/30 [02:27<00:10,  5.34s/it, loss_test=0.604]
Epoch: 27, Training Loss: 0.5770, Test Loss: 0.6044


100%|████████████████████████████████████████████████████████████████████| 30/30 [02:38<00:00,  5.27s/it, loss_test=0.603]
Epoch: 29, Training Loss: 0.5749, Test Loss: 0.6033
Model saved as model_77057np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-1260000-77057np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-50E-DATA', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9478415966760821, 0.8140962510937597, 0.7513158483112731, 0.7167714118230634, 0.6845202435080598, 0.6587440834903135, 0.6433064943043197, 0.6332394082735224, 0.6257084311871994, 0.619652026855364, 0.6145179471591624, 0.610247160421639, 0.6063938671495857, 0.6030157179367251, 0.5999585226541613, 0.5971315790240358, 0.5945943450418915, 0.5922928490653271, 0.5901311521486539, 0.5882487182573575, 0.5863324042137076, 0.584677752379964, 0.5831411002976138, 0.581735817397513, 0.5803967096456667, 0.5792132408880606, 0.5780519316109215, 0.5769567177063082, 0.5759590093682452, 0.5749309697165722], 'loss_test': [1.0204709588840444, 0.8813317225825402, 0.7821859672505368, 0.7423683738195768, 0.7110097632613234, 0.6813522083784944, 0.6629749754423736, 0.651694582995548, 0.6438317510389513, 0.637504046322197, 0.6329693473795409, 0.6290687303389272, 0.6255301160197104, 0.6224866778619828, 0.6204590797424316, 0.6180565222617118, 0.6157601315488097, 0.6140044613551068, 0.6125827950816001, 0.6111698317271407, 0.6098901488447702, 0.6089983986270043, 0.6072502520776564, 0.60619838840218, 0.6056207232577826, 0.6050494095330597, 0.6044806395807574, 0.6043523460306147, 0.6036201830833189, 0.6033177971839905], 'identifier': '77057np'}