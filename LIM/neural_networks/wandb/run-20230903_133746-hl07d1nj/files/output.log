

  3%|██▌                                                                           | 1/30 [00:11<05:28, 11.34s/it, loss_test=0.994]
Epoch: 00, Training Loss: 0.6823, Test Loss: 0.9945


 10%|███████▊                                                                      | 3/30 [00:33<05:05, 11.33s/it, loss_test=0.479]

 13%|██████████▍                                                                   | 4/30 [00:45<04:54, 11.33s/it, loss_test=0.456]
Epoch: 03, Training Loss: 0.4456, Test Loss: 0.4556


 20%|███████████████▌                                                              | 6/30 [01:07<04:31, 11.33s/it, loss_test=0.432]
Epoch: 05, Training Loss: 0.4259, Test Loss: 0.4320

 23%|██████████████████▏                                                           | 7/30 [01:19<04:20, 11.33s/it, loss_test=0.426]


 30%|███████████████████████▍                                                      | 9/30 [01:41<03:57, 11.33s/it, loss_test=0.418]
Epoch: 08, Training Loss: 0.4139, Test Loss: 0.4178



 37%|████████████████████████████▏                                                | 11/30 [02:12<04:06, 13.00s/it, loss_test=0.414]

 40%|██████████████████████████████▊                                              | 12/30 [02:23<03:44, 12.50s/it, loss_test=0.413]
Epoch: 11, Training Loss: 0.4097, Test Loss: 0.4134

 43%|█████████████████████████████████▎                                           | 13/30 [02:35<03:26, 12.15s/it, loss_test=0.412]


 50%|██████████████████████████████████████▌                                      | 15/30 [02:57<02:56, 11.74s/it, loss_test=0.412]

 53%|█████████████████████████████████████████                                    | 16/30 [03:09<02:42, 11.62s/it, loss_test=0.411]
Epoch: 15, Training Loss: 0.4074, Test Loss: 0.4110


 60%|██████████████████████████████████████████████▏                              | 18/30 [03:31<02:17, 11.47s/it, loss_test=0.411]

 63%|████████████████████████████████████████████████▊                            | 19/30 [03:43<02:05, 11.43s/it, loss_test=0.410]

 67%|███████████████████████████████████████████████████▎                         | 20/30 [03:54<01:54, 11.41s/it, loss_test=0.410]

 70%|█████████████████████████████████████████████████████▉                       | 21/30 [04:05<01:42, 11.38s/it, loss_test=0.410]

 73%|████████████████████████████████████████████████████████▍                    | 22/30 [04:17<01:31, 11.38s/it, loss_test=0.410]

 77%|███████████████████████████████████████████████████████████                  | 23/30 [04:28<01:19, 11.38s/it, loss_test=0.410]

 80%|█████████████████████████████████████████████████████████████▌               | 24/30 [04:39<01:08, 11.37s/it, loss_test=0.410]

 83%|████████████████████████████████████████████████████████████████▏            | 25/30 [04:51<00:56, 11.37s/it, loss_test=0.410]
Epoch: 24, Training Loss: 0.4051, Test Loss: 0.4096



 90%|█████████████████████████████████████████████████████████████████████▎       | 27/30 [05:22<00:39, 13.11s/it, loss_test=0.410]

 93%|███████████████████████████████████████████████████████████████████████▊     | 28/30 [05:33<00:25, 12.57s/it, loss_test=0.409]
Epoch: 27, Training Loss: 0.4046, Test Loss: 0.4095


100%|█████████████████████████████████████████████████████████████████████████████| 30/30 [05:56<00:00, 11.88s/it, loss_test=0.409]
Epoch: 29, Training Loss: 0.4044, Test Loss: 0.4094
Model saved as model_9624821np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-12-6200000-9624821np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 12, 'output_window': 6, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-30E-HORIZON', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 2438, 'num_of_params': 217886, 'loss_train': [0.682258116468201, 0.49844059285393355, 0.4637659168363381, 0.44560026010022946, 0.43390453990620426, 0.4258578783148271, 0.4203250853707784, 0.41655097494186444, 0.4139024084408351, 0.41203130011370936, 0.41069782949977257, 0.4097206727529161, 0.40894333580602554, 0.4083231192658172, 0.40782698699889225, 0.4073800169483632, 0.406985058139904, 0.40668210984367026, 0.40637967178609974, 0.4061059775913078, 0.40586953128245806, 0.40568564893560244, 0.40549313035015655, 0.40528447417523594, 0.40511643523921254, 0.4049597545599348, 0.40481982215870876, 0.4046400049522396, 0.4045075214683519, 0.4043529997532889], 'loss_test': [0.9944963304278178, 0.5299839106125709, 0.47902265334358585, 0.4555852203988112, 0.4414820679678367, 0.4319699975924614, 0.4255895971869811, 0.42081633200630164, 0.4178161548498349, 0.41570568600526225, 0.4142460480141334, 0.41340624254483443, 0.41241624464209264, 0.41182978756916827, 0.4117853368322055, 0.41104384712301767, 0.41090535859648997, 0.41095120679491604, 0.41029776594577694, 0.4099730049761442, 0.40997333308825123, 0.40970912881386584, 0.4098478996982941, 0.4100773636347208, 0.40961794431010884, 0.409883520924128, 0.4096375059049863, 0.40945187927438664, 0.40942054538008493, 0.40935982009157157], 'identifier': '9624821np'}