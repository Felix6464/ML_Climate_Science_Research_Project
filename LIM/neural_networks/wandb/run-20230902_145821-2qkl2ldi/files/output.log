

  3%|██▊                                                                                 | 1/30 [00:09<04:29,  9.29s/it, loss_test=1.005]
Epoch: 00, Training Loss: 0.9125, Test Loss: 1.0049

  7%|█████▌                                                                              | 2/30 [00:18<04:12,  9.03s/it, loss_test=0.813]


 13%|███████████▏                                                                        | 4/30 [00:35<03:52,  8.92s/it, loss_test=0.670]
Epoch: 03, Training Loss: 0.6525, Test Loss: 0.6699

 17%|██████████████                                                                      | 5/30 [00:44<03:41,  8.85s/it, loss_test=0.648]

 20%|████████████████▊                                                                   | 6/30 [00:53<03:35,  8.97s/it, loss_test=0.637]

 23%|███████████████████▌                                                                | 7/30 [01:02<03:26,  8.99s/it, loss_test=0.628]

 27%|██████████████████████▍                                                             | 8/30 [01:11<03:17,  8.99s/it, loss_test=0.622]

 30%|█████████████████████████▏                                                          | 9/30 [01:20<03:06,  8.89s/it, loss_test=0.617]


 37%|██████████████████████████████▍                                                    | 11/30 [01:37<02:47,  8.80s/it, loss_test=0.609]
Epoch: 10, Training Loss: 0.5980, Test Loss: 0.6089

 40%|█████████████████████████████████▏                                                 | 12/30 [01:46<02:37,  8.77s/it, loss_test=0.606]


 47%|██████████████████████████████████████▋                                            | 14/30 [02:03<02:19,  8.69s/it, loss_test=0.601]
Epoch: 13, Training Loss: 0.5896, Test Loss: 0.6013


 53%|████████████████████████████████████████████▎                                      | 16/30 [02:22<02:05,  8.96s/it, loss_test=0.598]
Epoch: 15, Training Loss: 0.5856, Test Loss: 0.5979

 57%|███████████████████████████████████████████████                                    | 17/30 [02:31<01:56,  8.97s/it, loss_test=0.597]


 63%|████████████████████████████████████████████████████▌                              | 19/30 [02:49<01:40,  9.13s/it, loss_test=0.594]
Epoch: 18, Training Loss: 0.5811, Test Loss: 0.5942


 70%|██████████████████████████████████████████████████████████                         | 21/30 [03:08<01:22,  9.17s/it, loss_test=0.592]
Epoch: 20, Training Loss: 0.5787, Test Loss: 0.5922


 77%|███████████████████████████████████████████████████████████████▋                   | 23/30 [03:26<01:03,  9.05s/it, loss_test=0.591]
Epoch: 22, Training Loss: 0.5769, Test Loss: 0.5909

 80%|██████████████████████████████████████████████████████████████████▍                | 24/30 [03:35<00:54,  9.12s/it, loss_test=0.590]


 87%|███████████████████████████████████████████████████████████████████████▉           | 26/30 [03:54<00:37,  9.32s/it, loss_test=0.590]
Epoch: 25, Training Loss: 0.5746, Test Loss: 0.5896


 93%|█████████████████████████████████████████████████████████████████████████████▍     | 28/30 [04:12<00:18,  9.14s/it, loss_test=0.589]
Epoch: 27, Training Loss: 0.5734, Test Loss: 0.5893


100%|███████████████████████████████████████████████████████████████████████████████████| 30/30 [04:30<00:00,  9.00s/it, loss_test=0.589]
Epoch: 29, Training Loss: 0.5723, Test Loss: 0.5892
Model saved as model_5298674np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-12100000-5298674np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-SPREAD', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.912532933029063, 0.7547838997928215, 0.684501826108157, 0.6525011224187774, 0.6356943719116322, 0.6252731526945974, 0.6175576344732836, 0.6113977857998439, 0.6062370033272894, 0.6018269541281047, 0.5979844155984048, 0.5947719425945491, 0.5919894054259136, 0.5895676883585724, 0.5874370486090035, 0.5855869484908415, 0.5839504984927265, 0.58241785183931, 0.5811047080235604, 0.5798768275605016, 0.5787223807839683, 0.5777404334518935, 0.576906966857421, 0.5760285884906085, 0.5752621236301604, 0.5745735824544788, 0.5740466041442676, 0.573373522513952, 0.5728594815774715, 0.5722899012294881], 'loss_test': [1.0049028377502391, 0.8129956049796863, 0.7174676702572749, 0.6699098860606169, 0.647918803187517, 0.636698665145116, 0.6282634093211248, 0.6220886768438877, 0.6167715176557883, 0.6130057802567115, 0.6089133658470252, 0.6056898706234418, 0.6031563209417539, 0.6013061885650341, 0.5993574785116391, 0.5978784324266971, 0.5965877935672418, 0.5949176947275797, 0.5941660885627453, 0.5927790067134759, 0.5921982110310824, 0.5914355711295054, 0.590909670942869, 0.5902934616956955, 0.5899813591669767, 0.5896022182244521, 0.5893236352847173, 0.5893336343459594, 0.5887912129744505, 0.589206833869983], 'identifier': '5298674np'}