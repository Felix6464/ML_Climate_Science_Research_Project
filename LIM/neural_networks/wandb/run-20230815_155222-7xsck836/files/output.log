

  0%|▎                                                                                        | 1/250 [00:09<38:28,  9.27s/it, loss_test=1.006]
Epoch: 00, Training Loss: 0.9648, Test Loss: 1.0056


  1%|█                                                                                        | 3/250 [00:27<37:56,  9.22s/it, loss_test=0.797]
Epoch: 02, Training Loss: 0.7667, Test Loss: 0.7973

  2%|█▍                                                                                       | 4/250 [00:36<37:46,  9.21s/it, loss_test=0.752]


  2%|██▏                                                                                      | 6/250 [00:55<37:33,  9.24s/it, loss_test=0.694]
Epoch: 05, Training Loss: 0.6793, Test Loss: 0.6939


  3%|██▊                                                                                      | 8/250 [01:13<36:58,  9.17s/it, loss_test=0.667]
Epoch: 07, Training Loss: 0.6555, Test Loss: 0.6671


  4%|███▌                                                                                    | 10/250 [01:31<36:37,  9.15s/it, loss_test=0.649]
Epoch: 09, Training Loss: 0.6378, Test Loss: 0.6485


  5%|████▏                                                                                   | 12/250 [01:50<36:21,  9.17s/it, loss_test=0.635]
Epoch: 11, Training Loss: 0.6258, Test Loss: 0.6355


  6%|████▉                                                                                   | 14/250 [02:08<35:44,  9.09s/it, loss_test=0.627]
Epoch: 13, Training Loss: 0.6174, Test Loss: 0.6269

  6%|█████▎                                                                                  | 15/250 [02:17<35:29,  9.06s/it, loss_test=0.624]


  7%|█████▉                                                                                  | 17/250 [02:35<35:21,  9.11s/it, loss_test=0.618]
Epoch: 16, Training Loss: 0.6082, Test Loss: 0.6181


  8%|██████▋                                                                                 | 19/250 [02:53<34:51,  9.06s/it, loss_test=0.613]
Epoch: 18, Training Loss: 0.6034, Test Loss: 0.6133


  8%|███████▍                                                                                | 21/250 [03:12<35:01,  9.18s/it, loss_test=0.609]

  9%|███████▋                                                                                | 22/250 [03:21<35:06,  9.24s/it, loss_test=0.608]
Epoch: 21, Training Loss: 0.5975, Test Loss: 0.6080


 10%|████████▍                                                                               | 24/250 [03:39<34:42,  9.21s/it, loss_test=0.605]
Epoch: 23, Training Loss: 0.5941, Test Loss: 0.6051

 10%|████████▊                                                                               | 25/250 [03:49<34:40,  9.25s/it, loss_test=0.604]


 11%|█████████▌                                                                              | 27/250 [04:07<34:29,  9.28s/it, loss_test=0.601]
Epoch: 26, Training Loss: 0.5901, Test Loss: 0.6013


 12%|██████████▏                                                                             | 29/250 [04:25<33:47,  9.18s/it, loss_test=0.600]
Epoch: 28, Training Loss: 0.5879, Test Loss: 0.5997


 12%|██████████▉                                                                             | 31/250 [04:44<33:11,  9.09s/it, loss_test=0.598]
Epoch: 30, Training Loss: 0.5860, Test Loss: 0.5977


 13%|███████████▌                                                                            | 33/250 [05:02<32:53,  9.10s/it, loss_test=0.597]
Epoch: 32, Training Loss: 0.5842, Test Loss: 0.5967


 14%|████████████▎                                                                           | 35/250 [05:20<32:30,  9.07s/it, loss_test=0.595]
Epoch: 34, Training Loss: 0.5827, Test Loss: 0.5954

 14%|████████████▋                                                                           | 36/250 [05:29<32:19,  9.06s/it, loss_test=0.595]


 15%|█████████████▍                                                                          | 38/250 [05:47<32:17,  9.14s/it, loss_test=0.594]
Epoch: 37, Training Loss: 0.5807, Test Loss: 0.5936


 16%|██████████████                                                                          | 40/250 [06:06<31:59,  9.14s/it, loss_test=0.593]
Epoch: 39, Training Loss: 0.5795, Test Loss: 0.5932


 17%|██████████████▊                                                                         | 42/250 [06:24<31:46,  9.17s/it, loss_test=0.592]
Epoch: 41, Training Loss: 0.5784, Test Loss: 0.5922

 17%|███████████████▏                                                                        | 43/250 [06:33<31:25,  9.11s/it, loss_test=0.592]


 18%|███████████████▊                                                                        | 45/250 [06:51<31:22,  9.18s/it, loss_test=0.592]
Epoch: 44, Training Loss: 0.5769, Test Loss: 0.5915


 19%|████████████████▌                                                                       | 47/250 [07:10<31:13,  9.23s/it, loss_test=0.591]

 19%|████████████████▉                                                                       | 48/250 [07:19<31:05,  9.23s/it, loss_test=0.590]
Epoch: 47, Training Loss: 0.5757, Test Loss: 0.5904


 20%|█████████████████▌                                                                      | 50/250 [07:38<30:44,  9.22s/it, loss_test=0.590]
Epoch: 49, Training Loss: 0.5750, Test Loss: 0.5902


 21%|██████████████████▎                                                                     | 52/250 [07:56<30:20,  9.20s/it, loss_test=0.590]

 21%|██████████████████▋                                                                     | 53/250 [08:05<30:15,  9.21s/it, loss_test=0.590]
Epoch: 52, Training Loss: 0.5740, Test Loss: 0.5896


 22%|███████████████████▎                                                                    | 55/250 [08:23<29:40,  9.13s/it, loss_test=0.589]
Epoch: 54, Training Loss: 0.5733, Test Loss: 0.5895


 23%|████████████████████                                                                    | 57/250 [08:42<29:24,  9.14s/it, loss_test=0.589]
Epoch: 56, Training Loss: 0.5728, Test Loss: 0.5894


 24%|████████████████████▊                                                                   | 59/250 [09:00<28:55,  9.08s/it, loss_test=0.589]
Epoch: 58, Training Loss: 0.5723, Test Loss: 0.5891


 24%|█████████████████████▍                                                                  | 61/250 [09:18<28:50,  9.15s/it, loss_test=0.589]

 25%|█████████████████████▊                                                                  | 62/250 [09:27<28:40,  9.15s/it, loss_test=0.589]
Epoch: 61, Training Loss: 0.5716, Test Loss: 0.5888


 26%|██████████████████████▌                                                                 | 64/250 [09:46<28:20,  9.14s/it, loss_test=0.589]
Epoch: 63, Training Loss: 0.5711, Test Loss: 0.5886


 26%|███████████████████████▏                                                                | 66/250 [10:04<28:10,  9.19s/it, loss_test=0.589]

 27%|███████████████████████▌                                                                | 67/250 [10:13<28:10,  9.24s/it, loss_test=0.588]
Epoch: 66, Training Loss: 0.5705, Test Loss: 0.5885

 27%|███████████████████████▉                                                                | 68/250 [10:23<28:11,  9.29s/it, loss_test=0.589]


 28%|████████████████████████▋                                                               | 70/250 [10:42<28:25,  9.47s/it, loss_test=0.588]

 28%|████████████████████████▋                                                               | 70/250 [10:52<28:25,  9.47s/it, loss_test=0.589]

 28%|████████████████████████▉                                                               | 71/250 [10:52<28:17,  9.48s/it, loss_test=0.589]

 29%|█████████████████████████▎                                                              | 72/250 [11:01<28:15,  9.53s/it, loss_test=0.589]


 30%|██████████████████████████                                                              | 74/250 [11:20<27:48,  9.48s/it, loss_test=0.589]

 30%|██████████████████████████▍                                                             | 75/250 [11:30<27:38,  9.48s/it, loss_test=0.589]
Epoch: 74, Training Loss: 0.5691, Test Loss: 0.5885

 30%|██████████████████████████▊                                                             | 76/250 [11:39<27:38,  9.53s/it, loss_test=0.588]


 31%|███████████████████████████▍                                                            | 78/250 [11:58<26:53,  9.38s/it, loss_test=0.588]
Epoch: 77, Training Loss: 0.5685, Test Loss: 0.5884


 32%|████████████████████████████▏                                                           | 80/250 [12:16<26:17,  9.28s/it, loss_test=0.589]

 32%|████████████████████████████▌                                                           | 81/250 [12:26<26:17,  9.34s/it, loss_test=0.589]
Epoch: 80, Training Loss: 0.5681, Test Loss: 0.5890


 33%|█████████████████████████████▏                                                          | 83/250 [12:44<26:00,  9.35s/it, loss_test=0.589]

 34%|█████████████████████████████▌                                                          | 84/250 [12:54<25:46,  9.31s/it, loss_test=0.589]
Epoch: 83, Training Loss: 0.5676, Test Loss: 0.5891

 34%|█████████████████████████████▉                                                          | 85/250 [13:03<25:40,  9.34s/it, loss_test=0.589]


 35%|██████████████████████████████▌                                                         | 87/250 [13:22<25:28,  9.37s/it, loss_test=0.589]
Epoch: 86, Training Loss: 0.5671, Test Loss: 0.5894

 35%|██████████████████████████████▉                                                         | 88/250 [13:31<25:17,  9.37s/it, loss_test=0.589]


 36%|███████████████████████████████▋                                                        | 90/250 [13:50<25:04,  9.40s/it, loss_test=0.589]
Epoch: 89, Training Loss: 0.5667, Test Loss: 0.5894


 37%|████████████████████████████████▍                                                       | 92/250 [14:09<24:28,  9.30s/it, loss_test=0.590]

 37%|████████████████████████████████▋                                                       | 93/250 [14:18<24:19,  9.29s/it, loss_test=0.590]
Epoch: 92, Training Loss: 0.5663, Test Loss: 0.5896


 38%|█████████████████████████████████▍                                                      | 95/250 [14:36<24:01,  9.30s/it, loss_test=0.590]
Epoch: 94, Training Loss: 0.5660, Test Loss: 0.5897


 39%|██████████████████████████████████▏                                                     | 97/250 [14:55<23:27,  9.20s/it, loss_test=0.590]

 39%|██████████████████████████████████▍                                                     | 98/250 [15:04<23:22,  9.22s/it, loss_test=0.590]
Epoch: 97, Training Loss: 0.5656, Test Loss: 0.5902


 40%|██████████████████████████████████▊                                                    | 100/250 [15:23<23:11,  9.28s/it, loss_test=0.590]

 40%|███████████████████████████████████▏                                                   | 101/250 [15:32<23:05,  9.30s/it, loss_test=0.590]

 41%|███████████████████████████████████▍                                                   | 102/250 [15:42<23:14,  9.43s/it, loss_test=0.590]
Epoch: 101, Training Loss: 0.5650, Test Loss: 0.5905


 42%|████████████████████████████████████▏                                                  | 104/250 [16:00<22:51,  9.39s/it, loss_test=0.591]
Epoch: 103, Training Loss: 0.5648, Test Loss: 0.5906

 42%|████████████████████████████████████▌                                                  | 105/250 [16:10<22:29,  9.31s/it, loss_test=0.591]


 43%|█████████████████████████████████████▏                                                 | 107/250 [16:28<22:01,  9.24s/it, loss_test=0.591]
Epoch: 106, Training Loss: 0.5644, Test Loss: 0.5910


 44%|█████████████████████████████████████▉                                                 | 109/250 [16:46<21:42,  9.24s/it, loss_test=0.591]
Epoch: 108, Training Loss: 0.5642, Test Loss: 0.5910

 44%|██████████████████████████████████████▎                                                | 110/250 [16:56<21:28,  9.20s/it, loss_test=0.591]


 45%|██████████████████████████████████████▉                                                | 112/250 [17:14<21:27,  9.33s/it, loss_test=0.591]

 45%|███████████████████████████████████████▎                                               | 113/250 [17:24<21:21,  9.36s/it, loss_test=0.592]
Epoch: 112, Training Loss: 0.5636, Test Loss: 0.5915


 46%|████████████████████████████████████████                                               | 115/250 [17:42<20:52,  9.28s/it, loss_test=0.592]
Epoch: 114, Training Loss: 0.5634, Test Loss: 0.5917


 47%|████████████████████████████████████████▋                                              | 117/250 [18:01<20:28,  9.24s/it, loss_test=0.592]
Epoch: 116, Training Loss: 0.5631, Test Loss: 0.5919

 47%|█████████████████████████████████████████                                              | 118/250 [18:10<20:13,  9.19s/it, loss_test=0.592]


 48%|█████████████████████████████████████████▊                                             | 120/250 [18:28<19:56,  9.20s/it, loss_test=0.592]
Epoch: 119, Training Loss: 0.5627, Test Loss: 0.5918


 49%|██████████████████████████████████████████▍                                            | 122/250 [18:47<19:30,  9.15s/it, loss_test=0.592]
Epoch: 121, Training Loss: 0.5625, Test Loss: 0.5921


 50%|███████████████████████████████████████████▏                                           | 124/250 [19:05<19:05,  9.09s/it, loss_test=0.592]
Epoch: 123, Training Loss: 0.5623, Test Loss: 0.5925


 50%|███████████████████████████████████████████▊                                           | 126/250 [19:23<18:47,  9.09s/it, loss_test=0.594]

 51%|████████████████████████████████████████████▏                                          | 127/250 [19:32<18:46,  9.16s/it, loss_test=0.593]
Epoch: 126, Training Loss: 0.5619, Test Loss: 0.5933


 52%|████████████████████████████████████████████▉                                          | 129/250 [19:51<18:34,  9.21s/it, loss_test=0.594]
Epoch: 128, Training Loss: 0.5616, Test Loss: 0.5935


 52%|█████████████████████████████████████████████▌                                         | 131/250 [20:09<18:00,  9.08s/it, loss_test=0.594]
Epoch: 130, Training Loss: 0.5614, Test Loss: 0.5935


 53%|██████████████████████████████████████████████▎                                        | 133/250 [20:27<17:46,  9.11s/it, loss_test=0.594]

 54%|██████████████████████████████████████████████▋                                        | 134/250 [20:36<17:40,  9.14s/it, loss_test=0.593]
Epoch: 133, Training Loss: 0.5610, Test Loss: 0.5933


 54%|███████████████████████████████████████████████▎                                       | 136/250 [20:54<17:21,  9.14s/it, loss_test=0.594]
Epoch: 135, Training Loss: 0.5608, Test Loss: 0.5939


 55%|████████████████████████████████████████████████                                       | 138/250 [21:13<17:13,  9.23s/it, loss_test=0.594]
Epoch: 137, Training Loss: 0.5605, Test Loss: 0.5938


 56%|████████████████████████████████████████████████▋                                      | 140/250 [21:31<16:41,  9.10s/it, loss_test=0.594]
Epoch: 139, Training Loss: 0.5603, Test Loss: 0.5941

 56%|█████████████████████████████████████████████████                                      | 141/250 [21:40<16:28,  9.07s/it, loss_test=0.594]


 57%|█████████████████████████████████████████████████▊                                     | 143/250 [21:58<16:14,  9.11s/it, loss_test=0.595]
Epoch: 142, Training Loss: 0.5599, Test Loss: 0.5954


 58%|██████████████████████████████████████████████████▍                                    | 145/250 [22:17<15:57,  9.12s/it, loss_test=0.595]
Epoch: 144, Training Loss: 0.5596, Test Loss: 0.5948


 59%|███████████████████████████████████████████████████▏                                   | 147/250 [22:35<15:42,  9.15s/it, loss_test=0.595]
Epoch: 146, Training Loss: 0.5593, Test Loss: 0.5950


 60%|███████████████████████████████████████████████████▊                                   | 149/250 [22:53<15:23,  9.15s/it, loss_test=0.596]

 60%|████████████████████████████████████████████████████▏                                  | 150/250 [23:02<15:11,  9.12s/it, loss_test=0.596]

 60%|████████████████████████████████████████████████████▌                                  | 151/250 [23:11<14:52,  9.02s/it, loss_test=0.596]

 61%|████████████████████████████████████████████████████▉                                  | 152/250 [23:20<14:49,  9.08s/it, loss_test=0.596]
Epoch: 151, Training Loss: 0.5587, Test Loss: 0.5964


 62%|█████████████████████████████████████████████████████▌                                 | 154/250 [23:39<14:39,  9.16s/it, loss_test=0.596]
Epoch: 153, Training Loss: 0.5585, Test Loss: 0.5963


 62%|██████████████████████████████████████████████████████▎                                | 156/250 [23:57<14:11,  9.06s/it, loss_test=0.596]
Epoch: 155, Training Loss: 0.5583, Test Loss: 0.5964


 63%|██████████████████████████████████████████████████████▉                                | 158/250 [24:15<13:50,  9.02s/it, loss_test=0.596]
Epoch: 157, Training Loss: 0.5580, Test Loss: 0.5965


 64%|███████████████████████████████████████████████████████▋                               | 160/250 [24:33<13:29,  8.99s/it, loss_test=0.597]
Epoch: 159, Training Loss: 0.5578, Test Loss: 0.5969


 65%|████████████████████████████████████████████████████████▍                              | 162/250 [24:51<13:22,  9.12s/it, loss_test=0.598]
Epoch: 161, Training Loss: 0.5575, Test Loss: 0.5981


 66%|█████████████████████████████████████████████████████████                              | 164/250 [25:09<13:02,  9.10s/it, loss_test=0.598]

 66%|█████████████████████████████████████████████████████████▍                             | 165/250 [25:18<12:56,  9.14s/it, loss_test=0.598]

 66%|█████████████████████████████████████████████████████████▊                             | 166/250 [25:27<12:43,  9.09s/it, loss_test=0.598]
Epoch: 165, Training Loss: 0.5570, Test Loss: 0.5982


 67%|██████████████████████████████████████████████████████████▍                            | 168/250 [25:45<12:16,  8.98s/it, loss_test=0.598]
Epoch: 167, Training Loss: 0.5568, Test Loss: 0.5982


 68%|███████████████████████████████████████████████████████████▏                           | 170/250 [26:03<12:02,  9.03s/it, loss_test=0.599]

 68%|███████████████████████████████████████████████████████████▌                           | 171/250 [26:12<11:54,  9.04s/it, loss_test=0.599]

 69%|███████████████████████████████████████████████████████████▊                           | 172/250 [26:21<11:45,  9.05s/it, loss_test=0.600]

 69%|████████████████████████████████████████████████████████████▏                          | 173/250 [26:31<11:40,  9.09s/it, loss_test=0.599]
Epoch: 172, Training Loss: 0.5561, Test Loss: 0.5990


 70%|████████████████████████████████████████████████████████████▉                          | 175/250 [26:49<11:19,  9.06s/it, loss_test=0.599]
Epoch: 174, Training Loss: 0.5559, Test Loss: 0.5994


 71%|█████████████████████████████████████████████████████████████▌                         | 177/250 [27:07<11:04,  9.10s/it, loss_test=0.600]
Epoch: 176, Training Loss: 0.5556, Test Loss: 0.6001


 72%|██████████████████████████████████████████████████████████████▎                        | 179/250 [27:25<10:37,  8.97s/it, loss_test=0.600]
Epoch: 178, Training Loss: 0.5553, Test Loss: 0.6004


 72%|██████████████████████████████████████████████████████████████▉                        | 181/250 [27:43<10:18,  8.96s/it, loss_test=0.600]

 73%|███████████████████████████████████████████████████████████████▎                       | 182/250 [27:51<10:07,  8.94s/it, loss_test=0.600]
Epoch: 181, Training Loss: 0.5549, Test Loss: 0.6002


 74%|████████████████████████████████████████████████████████████████                       | 184/250 [28:09<09:46,  8.89s/it, loss_test=0.600]
Epoch: 183, Training Loss: 0.5547, Test Loss: 0.6004


 74%|████████████████████████████████████████████████████████████████▋                      | 186/250 [28:27<09:32,  8.95s/it, loss_test=0.601]
Epoch: 185, Training Loss: 0.5545, Test Loss: 0.6012


 75%|█████████████████████████████████████████████████████████████████▍                     | 188/250 [28:45<09:15,  8.96s/it, loss_test=0.601]
Epoch: 187, Training Loss: 0.5542, Test Loss: 0.6009


 76%|██████████████████████████████████████████████████████████████████                     | 190/250 [29:03<08:57,  8.97s/it, loss_test=0.601]
Epoch: 189, Training Loss: 0.5540, Test Loss: 0.6009


 77%|██████████████████████████████████████████████████████████████████▊                    | 192/250 [29:21<08:40,  8.97s/it, loss_test=0.602]
Epoch: 191, Training Loss: 0.5537, Test Loss: 0.6016


 78%|███████████████████████████████████████████████████████████████████▌                   | 194/250 [29:39<08:20,  8.93s/it, loss_test=0.602]
Epoch: 193, Training Loss: 0.5534, Test Loss: 0.6020


 78%|████████████████████████████████████████████████████████████████████▏                  | 196/250 [29:57<08:04,  8.97s/it, loss_test=0.602]

 79%|████████████████████████████████████████████████████████████████████▌                  | 197/250 [30:06<07:54,  8.95s/it, loss_test=0.603]

 79%|████████████████████████████████████████████████████████████████████▉                  | 198/250 [30:15<07:45,  8.96s/it, loss_test=0.603]

 80%|█████████████████████████████████████████████████████████████████████▎                 | 199/250 [30:24<07:38,  8.98s/it, loss_test=0.603]

 80%|█████████████████████████████████████████████████████████████████████▌                 | 200/250 [30:33<07:28,  8.97s/it, loss_test=0.603]
Epoch: 199, Training Loss: 0.5527, Test Loss: 0.6027


 81%|██████████████████████████████████████████████████████████████████████▎                | 202/250 [30:51<07:16,  9.10s/it, loss_test=0.603]
Epoch: 201, Training Loss: 0.5524, Test Loss: 0.6031


 82%|██████████████████████████████████████████████████████████████████████▉                | 204/250 [31:09<06:54,  9.02s/it, loss_test=0.603]
Epoch: 203, Training Loss: 0.5522, Test Loss: 0.6035

 82%|███████████████████████████████████████████████████████████████████████▎               | 205/250 [31:18<06:46,  9.02s/it, loss_test=0.604]

 82%|███████████████████████████████████████████████████████████████████████▋               | 206/250 [31:27<06:39,  9.07s/it, loss_test=0.603]


 83%|████████████████████████████████████████████████████████████████████████▍              | 208/250 [31:45<06:20,  9.05s/it, loss_test=0.604]
Epoch: 207, Training Loss: 0.5517, Test Loss: 0.6044


 84%|█████████████████████████████████████████████████████████████████████████              | 210/250 [32:03<06:01,  9.04s/it, loss_test=0.605]
Epoch: 209, Training Loss: 0.5514, Test Loss: 0.6048


 85%|█████████████████████████████████████████████████████████████████████████▊             | 212/250 [32:21<05:44,  9.06s/it, loss_test=0.604]
Epoch: 211, Training Loss: 0.5512, Test Loss: 0.6044


 86%|██████████████████████████████████████████████████████████████████████████▍            | 214/250 [32:39<05:24,  9.01s/it, loss_test=0.605]
Epoch: 213, Training Loss: 0.5509, Test Loss: 0.6051


 86%|███████████████████████████████████████████████████████████████████████████▏           | 216/250 [32:57<05:05,  8.99s/it, loss_test=0.605]
Epoch: 215, Training Loss: 0.5507, Test Loss: 0.6047


 87%|███████████████████████████████████████████████████████████████████████████▊           | 218/250 [33:15<04:47,  8.99s/it, loss_test=0.606]
Epoch: 217, Training Loss: 0.5504, Test Loss: 0.6059


 88%|████████████████████████████████████████████████████████████████████████████▌          | 220/250 [33:33<04:30,  9.02s/it, loss_test=0.606]
Epoch: 219, Training Loss: 0.5501, Test Loss: 0.6064


 89%|█████████████████████████████████████████████████████████████████████████████▎         | 222/250 [33:52<04:14,  9.09s/it, loss_test=0.605]
Epoch: 221, Training Loss: 0.5499, Test Loss: 0.6052


 90%|█████████████████████████████████████████████████████████████████████████████▉         | 224/250 [34:10<03:54,  9.01s/it, loss_test=0.606]
Epoch: 223, Training Loss: 0.5497, Test Loss: 0.6062


 90%|██████████████████████████████████████████████████████████████████████████████▋        | 226/250 [34:27<03:35,  8.97s/it, loss_test=0.607]
Epoch: 225, Training Loss: 0.5494, Test Loss: 0.6068


 91%|███████████████████████████████████████████████████████████████████████████████▎       | 228/250 [34:45<03:16,  8.92s/it, loss_test=0.608]
Epoch: 227, Training Loss: 0.5492, Test Loss: 0.6076


 92%|████████████████████████████████████████████████████████████████████████████████       | 230/250 [35:03<02:59,  8.98s/it, loss_test=0.608]
Epoch: 229, Training Loss: 0.5488, Test Loss: 0.6076


 93%|████████████████████████████████████████████████████████████████████████████████▋      | 232/250 [35:22<02:43,  9.08s/it, loss_test=0.607]
Epoch: 231, Training Loss: 0.5486, Test Loss: 0.6072


 94%|█████████████████████████████████████████████████████████████████████████████████▍     | 234/250 [35:40<02:25,  9.09s/it, loss_test=0.608]
Epoch: 233, Training Loss: 0.5484, Test Loss: 0.6078


 94%|██████████████████████████████████████████████████████████████████████████████████▏    | 236/250 [35:58<02:05,  8.98s/it, loss_test=0.609]
Epoch: 235, Training Loss: 0.5481, Test Loss: 0.6085


 95%|██████████████████████████████████████████████████████████████████████████████████▊    | 238/250 [36:15<01:47,  8.97s/it, loss_test=0.608]
Epoch: 237, Training Loss: 0.5478, Test Loss: 0.6081


 96%|███████████████████████████████████████████████████████████████████████████████████▌   | 240/250 [36:34<01:30,  9.01s/it, loss_test=0.608]
Epoch: 239, Training Loss: 0.5475, Test Loss: 0.6080


 97%|████████████████████████████████████████████████████████████████████████████████████▏  | 242/250 [36:51<01:11,  8.96s/it, loss_test=0.608]
Epoch: 241, Training Loss: 0.5474, Test Loss: 0.6080


 98%|████████████████████████████████████████████████████████████████████████████████████▉  | 244/250 [37:09<00:53,  8.96s/it, loss_test=0.609]
Epoch: 243, Training Loss: 0.5471, Test Loss: 0.6094


 98%|█████████████████████████████████████████████████████████████████████████████████████▌ | 246/250 [37:27<00:35,  8.99s/it, loss_test=0.611]
Epoch: 245, Training Loss: 0.5469, Test Loss: 0.6110


 99%|██████████████████████████████████████████████████████████████████████████████████████▎| 248/250 [37:45<00:17,  8.99s/it, loss_test=0.611]

100%|██████████████████████████████████████████████████████████████████████████████████████▋| 249/250 [37:54<00:08,  8.95s/it, loss_test=0.610]

100%|███████████████████████████████████████████████████████████████████████████████████████| 250/250 [38:03<00:00,  9.14s/it, loss_test=0.610]
Epoch: 249, Training Loss: 0.5464, Test Loss: 0.6098
Model saved as model_8767596np.pt
Config : {'wandb': True, 'name': 'lstm-enc-dec-5e-05-2-12-8767596np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 5e-05, 'num_layers': 1, 'num_epochs': 250, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-100k-WINDOW', 'teacher_forcing_ratio': -4.198030811863873e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9648477725493603, 0.8306218476304205, 0.7666980213734693, 0.7289633445250683, 0.6991854046945607, 0.679270320213758, 0.6659960044827653, 0.6555254651513291, 0.6462546320625278, 0.6377902780915354, 0.6309787722734305, 0.6257651925305308, 0.6212686811174665, 0.6173827482230497, 0.6140155224573045, 0.6109051964221857, 0.6081689458626968, 0.6056861932024414, 0.6034356239951137, 0.6012985295865125, 0.5992520670969408, 0.5974650220338241, 0.5957067865373451, 0.59412817913534, 0.5926592363106026, 0.591310135719977, 0.5900543794963823, 0.588939884752581, 0.5878950012472522, 0.5869218963624794, 0.5860018292407849, 0.585108336293217, 0.5842231045930814, 0.5834931052211441, 0.5827169070095369, 0.5819871100313935, 0.5813140275277497, 0.5807189360643045, 0.5800585572099511, 0.5794924338221986, 0.57895483595111, 0.5784125807302776, 0.5778583584032653, 0.5774354522044842, 0.5769148902360336, 0.5764901130409031, 0.5761147166564787, 0.5757195891696455, 0.5753535962366796, 0.5749504811816163, 0.5745675420804774, 0.5742686714008177, 0.5739978892462594, 0.5736931136676243, 0.5733438807747739, 0.573088580762947, 0.5727847325496185, 0.5725190177723601, 0.5723058769117781, 0.5720045757599366, 0.5717542087420439, 0.5715711275081494, 0.5713025758336315, 0.5710857085910909, 0.5708866741631057, 0.5706649044931154, 0.570491244832238, 0.5702929430173866, 0.570055189368489, 0.5699174000230027, 0.5697256192401216, 0.5695303033341418, 0.5692959598132542, 0.5691789993436345, 0.5690603443991133, 0.5688148030649611, 0.5686351581589206, 0.5684906745349968, 0.5682882513755407, 0.568157033715056, 0.5680504597368694, 0.567887109823716, 0.5676846631935665, 0.5676157355526865, 0.5674018344599685, 0.5672527501434633, 0.5671125873104557, 0.5669611907485641, 0.5668392909533811, 0.5666812826425601, 0.5665570187481331, 0.566393663704177, 0.5662599272562034, 0.5661350258322426, 0.5660068412403484, 0.5658504786072197, 0.5656919818876427, 0.565606917544599, 0.5654459949378129, 0.565348295829235, 0.5651942313590765, 0.5650252348337418, 0.5649322448195991, 0.5648043140386924, 0.564690941965187, 0.5645518140260116, 0.5643853482964275, 0.5642794638107984, 0.5641684916429904, 0.5640894853588425, 0.5639142105867575, 0.5638118935373676, 0.5636469480537233, 0.5634756898268675, 0.5634455883895958, 0.5632488951359913, 0.5631058879824349, 0.5629780330719092, 0.5629303540502276, 0.5627462990554698, 0.5626016966589205, 0.5625299021001264, 0.5624148615332314, 0.5622908719730028, 0.5620896402514461, 0.5620356870221568, 0.5618581400686131, 0.5617156130271953, 0.5616353634512905, 0.5615612643978971, 0.5614022626763299, 0.5613116339231149, 0.5611687615895883, 0.5610198975701035, 0.5609100821254017, 0.5607770526365483, 0.5606417531495566, 0.5604643023712731, 0.5604257249570155, 0.5602963275306827, 0.5601289930579426, 0.5600296988155379, 0.5598844223188393, 0.5597767923777793, 0.5596100302624615, 0.5594865559658289, 0.5593362017210587, 0.5593125576719696, 0.5590771570965484, 0.5590175679533473, 0.5589111607808334, 0.5587345403192681, 0.558668029941482, 0.5585445270433531, 0.5584275647179111, 0.558274521277501, 0.5581219663550129, 0.5580413413571788, 0.5579345364928682, 0.5578063202428294, 0.5576104660392244, 0.5575047600400317, 0.5573857212677981, 0.5572221331543975, 0.5571421957932986, 0.5570206207670135, 0.5569196158931369, 0.5567732554870647, 0.5565976926258632, 0.5564565035231385, 0.5563847730447958, 0.5562362859755645, 0.5560682125580616, 0.5559583897992368, 0.5559024323910584, 0.5557717936379569, 0.5556320000044156, 0.555474246596242, 0.5553351639609634, 0.555226722916404, 0.5551354338179578, 0.554937054058571, 0.5548705332008473, 0.5547419567029555, 0.5545817387628031, 0.5544608345616868, 0.5543649668221945, 0.5542162967907204, 0.554089273070241, 0.5539781406467215, 0.5538153731342637, 0.5536664953598609, 0.5535749431713161, 0.5534280168486165, 0.5533511381009559, 0.5531676264254601, 0.5531523664355714, 0.5529264683251852, 0.5528079185075375, 0.552716260100459, 0.5525219726475167, 0.5524320079511775, 0.5522941917508513, 0.5521686321649796, 0.5520403846934602, 0.5519057707690493, 0.5518330127109975, 0.5517068650477972, 0.5514720770028921, 0.5514209810849074, 0.5512595997625218, 0.5512023108564453, 0.5510376923250191, 0.5509166284140213, 0.5508095707212176, 0.5507061266418778, 0.5505322830362634, 0.5503843881926693, 0.5502333880125821, 0.5501403894834903, 0.550051116899693, 0.5498757982428694, 0.5497766865260435, 0.5496901214777768, 0.5494743272280082, 0.5493874783480998, 0.5492891361425211, 0.5492234986561996, 0.5490108988223932, 0.5488385275388376, 0.5487876271371877, 0.5486089678911062, 0.5484439995917645, 0.5483696998912336, 0.5482311701818263, 0.5481457310718495, 0.5479663427059467, 0.5478405401165232, 0.5476927236541287, 0.547548811623465, 0.5475017427306472, 0.5474045854130071, 0.5472067527936928, 0.5470780851421776, 0.5469742667325687, 0.5468616384071309, 0.5467114716004102, 0.5466205767004482, 0.5464188403043991, 0.5463738131435799], 'loss_test': [1.00562318892051, 0.8882035647447293, 0.7973085913138512, 0.7516801685858996, 0.7182927337976602, 0.6938678232523111, 0.6784949692396017, 0.6670803794494042, 0.6576761030233823, 0.6485375330234185, 0.6412295783177401, 0.6354675980714651, 0.630969083462006, 0.6268765995135674, 0.6235604022557919, 0.6204849053651859, 0.6180892242835119, 0.6157745676927078, 0.6133129860346134, 0.6115661022754816, 0.6094398888257834, 0.6079971702435077, 0.6064780117609562, 0.6050941271659656, 0.6035287758478751, 0.6025620446755335, 0.6013239205647738, 0.6000661307420486, 0.5996724172280385, 0.5986110063699576, 0.597742001979779, 0.5972234633488532, 0.5967457546637609, 0.595560976710075, 0.5954331713609207, 0.5948110398573753, 0.5941661997483327, 0.5935844717881619, 0.5934960666375283, 0.5931638846030602, 0.5927001646695993, 0.5921996403963138, 0.5918795034671441, 0.5912784143136098, 0.5915411489132123, 0.5909241380599829, 0.5907603227175199, 0.5904180541252478, 0.5900149429455782, 0.5901560420409228, 0.5897457771576368, 0.5897411971520155, 0.5896344853517337, 0.5896705041329066, 0.5894505614653612, 0.5889983968092845, 0.58940900518344, 0.5888749873026823, 0.5890977814411505, 0.5890995260232534, 0.589056243117039, 0.5887531271347632, 0.5889849043809451, 0.5885798858526425, 0.5887044163850638, 0.5886596475656216, 0.5884583359345411, 0.5888174107441535, 0.5887788702280093, 0.5884519949173316, 0.5889010949012561, 0.5887282750545404, 0.588426818832373, 0.5887032464528695, 0.588534931341807, 0.5883221687414707, 0.5884360010043169, 0.5883711786606373, 0.5888697703679403, 0.5885800956151425, 0.5890339964475387, 0.5887219095841433, 0.589384369361095, 0.5891370861194073, 0.5893798909890346, 0.5892171397423133, 0.5894177017303613, 0.5894224804181319, 0.5896245053945444, 0.5893534200313764, 0.5894878147504269, 0.5896193014505582, 0.5895951252717239, 0.589620291804656, 0.5896740177502999, 0.5897337931853074, 0.5903220875905111, 0.5901856185534061, 0.5896654755641253, 0.5902098142183744, 0.5902896863527787, 0.5904525766770045, 0.5904548959090159, 0.5906135909832441, 0.5908334751923879, 0.5903654587574494, 0.5909523341136101, 0.5909478461895233, 0.5909669808088205, 0.5911234590487603, 0.5910215817200832, 0.5909489293893179, 0.5915036679078371, 0.5911609217142447, 0.5916949862088913, 0.5917276239547974, 0.5918916181111947, 0.5919806861724609, 0.5930125319804901, 0.5917801860815439, 0.5919369187874671, 0.5921344520189823, 0.5925636016405545, 0.5924572130808463, 0.5930232275754977, 0.5936047851275175, 0.5933029422393212, 0.5929929946477597, 0.5935409218072891, 0.5931184723591193, 0.5935170753644063, 0.593373335706882, 0.593872586504007, 0.593262200936293, 0.5944220947149472, 0.593920614474859, 0.5946738582391006, 0.5938064505656561, 0.5940697716596799, 0.594148888419836, 0.5940913248520631, 0.5944748788307874, 0.5953571540422928, 0.595178138369169, 0.5947864590547024, 0.5951492969806378, 0.5950363679574087, 0.5957974493503571, 0.5958888821112804, 0.5961371595278765, 0.5958609336461776, 0.5963571770833089, 0.5959353760266916, 0.5963471925411469, 0.5971600848894852, 0.5963913939702206, 0.5967796739095297, 0.596450999761239, 0.5966012607782315, 0.5969127649680163, 0.5973691401573328, 0.5980612138907114, 0.5976427732369839, 0.5976848365404667, 0.5979670270895346, 0.5981921056906382, 0.5979201354277439, 0.5982197232735462, 0.598947999569086, 0.5990884758723087, 0.5986318699060342, 0.5995827114734894, 0.5989988870345629, 0.5989133539872292, 0.5994287373927923, 0.599083967315845, 0.6001060540095354, 0.6000853440700433, 0.6004388756476916, 0.6001626799503962, 0.6004450741486672, 0.6002214421064426, 0.6006885602688178, 0.6004353631765414, 0.6008600092087036, 0.6012189029118954, 0.6009522340236566, 0.600898401477398, 0.6010312487681707, 0.6008935035803379, 0.6014689073348657, 0.6016328059709989, 0.6018096988017743, 0.6019702057043711, 0.6020041375588148, 0.6021953030274465, 0.6029887734315335, 0.6025265875535134, 0.6027349822032146, 0.6027383296153485, 0.6031168852096949, 0.6030889501174291, 0.6031736055245767, 0.6034612342333182, 0.6037455117091154, 0.6034781669194882, 0.6033531878239069, 0.6044000318417182, 0.6045913172838016, 0.604840698150488, 0.604639300169089, 0.6044078916311264, 0.6050045933478918, 0.6050693430961707, 0.6049844320767965, 0.6047343886815585, 0.6061556339263916, 0.605935350442544, 0.6052731344333062, 0.6063703936644089, 0.6066733598709106, 0.6052232247132522, 0.6071376987756827, 0.606220298470595, 0.6080580682326586, 0.6067699216879331, 0.6060817627570568, 0.6076330007650913, 0.60641715885737, 0.6076078327038349, 0.6071156641611686, 0.6071970749359864, 0.608026976004625, 0.6077918670116327, 0.6087421962083914, 0.6085320478066419, 0.6082336765069228, 0.6081230705365156, 0.6084900658864242, 0.6079618185758591, 0.6084043093216724, 0.6080139500972552, 0.609294953636634, 0.6093535751868517, 0.6085791801794981, 0.6109807670880587, 0.6097793430089951, 0.6107950619398019, 0.6099340827801288, 0.6098253004826032], 'identifier': '8767596np'}