

  3%|██▊                                                                                 | 1/30 [00:09<04:38,  9.62s/it, loss_test=1.005]
Epoch: 00, Training Loss: 0.9094, Test Loss: 1.0047


 10%|████████▍                                                                           | 3/30 [00:28<04:13,  9.38s/it, loss_test=0.719]
Epoch: 02, Training Loss: 0.6880, Test Loss: 0.7188


 17%|██████████████                                                                      | 5/30 [00:46<03:48,  9.13s/it, loss_test=0.650]
Epoch: 04, Training Loss: 0.6370, Test Loss: 0.6497

 20%|████████████████▊                                                                   | 6/30 [00:55<03:40,  9.18s/it, loss_test=0.637]


 27%|██████████████████████▍                                                             | 8/30 [01:14<03:25,  9.32s/it, loss_test=0.622]
Epoch: 07, Training Loss: 0.6117, Test Loss: 0.6219

 30%|█████████████████████████▏                                                          | 9/30 [01:23<03:13,  9.22s/it, loss_test=0.617]


 37%|██████████████████████████████▍                                                    | 11/30 [01:41<02:55,  9.24s/it, loss_test=0.608]
Epoch: 10, Training Loss: 0.5974, Test Loss: 0.6077


 43%|███████████████████████████████████▉                                               | 13/30 [02:00<02:36,  9.19s/it, loss_test=0.602]
Epoch: 12, Training Loss: 0.5912, Test Loss: 0.6021


 50%|█████████████████████████████████████████▌                                         | 15/30 [02:18<02:17,  9.17s/it, loss_test=0.598]
Epoch: 14, Training Loss: 0.5867, Test Loss: 0.5976

 53%|████████████████████████████████████████████▎                                      | 16/30 [02:27<02:08,  9.17s/it, loss_test=0.596]


 60%|█████████████████████████████████████████████████▊                                 | 18/30 [02:45<01:50,  9.21s/it, loss_test=0.594]
Epoch: 17, Training Loss: 0.5819, Test Loss: 0.5940


 67%|███████████████████████████████████████████████████████▎                           | 20/30 [03:04<01:31,  9.11s/it, loss_test=0.592]
Epoch: 19, Training Loss: 0.5795, Test Loss: 0.5917


 73%|████████████████████████████████████████████████████████████▊                      | 22/30 [03:21<01:12,  9.05s/it, loss_test=0.590]
Epoch: 21, Training Loss: 0.5775, Test Loss: 0.5902


 80%|██████████████████████████████████████████████████████████████████▍                | 24/30 [03:39<00:54,  9.01s/it, loss_test=0.590]
Epoch: 23, Training Loss: 0.5759, Test Loss: 0.5901

 83%|█████████████████████████████████████████████████████████████████████▏             | 25/30 [03:49<00:45,  9.11s/it, loss_test=0.589]

 87%|███████████████████████████████████████████████████████████████████████▉           | 26/30 [03:58<00:36,  9.18s/it, loss_test=0.589]


 93%|█████████████████████████████████████████████████████████████████████████████▍     | 28/30 [04:16<00:18,  9.04s/it, loss_test=0.588]
Epoch: 27, Training Loss: 0.5735, Test Loss: 0.5885


100%|███████████████████████████████████████████████████████████████████████████████████| 30/30 [04:34<00:00,  9.14s/it, loss_test=0.588]
Epoch: 29, Training Loss: 0.5725, Test Loss: 0.5878
Model saved as model_2286937np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-12100000-2286937np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-SPREAD', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9094410562689924, 0.7529523120476649, 0.6880380024403443, 0.6546738254718292, 0.6369565856325757, 0.6259432473243811, 0.6180926621396899, 0.6116629627161411, 0.6061419510579371, 0.6014552730998713, 0.5974149830612071, 0.5941338230183709, 0.5911910297014774, 0.5888140271434854, 0.58665254733938, 0.5848877934309152, 0.5832620739063501, 0.5818776589828533, 0.5806147145045982, 0.5794558808917091, 0.5784522293906509, 0.5775386396345201, 0.5766682668483301, 0.575902765923804, 0.5752257804075877, 0.5745822624627487, 0.5740329113417056, 0.5734813887994368, 0.5729545453092554, 0.5724544065557556], 'loss_test': [1.0047276306610842, 0.813355320921311, 0.718770064222507, 0.6716263714509133, 0.6496864775052438, 0.6368908095054138, 0.6281608056563598, 0.6218519382751905, 0.6165856210849224, 0.6116146109043024, 0.6076627839834262, 0.604978621770174, 0.6021042481446878, 0.599625098781708, 0.5975628441725022, 0.5962298294672599, 0.5950379188244159, 0.5940169000472778, 0.5928960625941937, 0.5916884262592365, 0.5912942527196346, 0.5901865867468027, 0.5898646895702069, 0.5900849000765727, 0.588983409679853, 0.5891159566549155, 0.588543543066734, 0.5884624792215152, 0.5883280038833618, 0.5878384174444736], 'identifier': '2286937np'}