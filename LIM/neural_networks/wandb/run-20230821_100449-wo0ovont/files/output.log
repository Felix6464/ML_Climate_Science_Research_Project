Epoch: 00, Training Loss: 0.9929, Test Loss: 1.0894
Epoch: 01, Training Loss: 0.9959, Test Loss: 1.0681
Epoch: 02, Training Loss: 0.9931, Test Loss: 1.0784
Epoch: 03, Training Loss: 0.9908, Test Loss: 1.0854
Epoch: 04, Training Loss: 0.9929, Test Loss: 1.0769
Epoch: 05, Training Loss: 0.9919, Test Loss: 1.0919
Epoch: 06, Training Loss: 0.9880, Test Loss: 1.0823
Epoch: 07, Training Loss: 0.9937, Test Loss: 1.0787
Epoch: 08, Training Loss: 0.9871, Test Loss: 1.0949
Epoch: 09, Training Loss: 0.9916, Test Loss: 1.0780
Epoch: 10, Training Loss: 0.9850, Test Loss: 1.0840
Epoch: 11, Training Loss: 0.9919, Test Loss: 1.0804
Epoch: 12, Training Loss: 0.9918, Test Loss: 1.0902
Epoch: 13, Training Loss: 0.9896, Test Loss: 1.0900
Epoch: 14, Training Loss: 0.9885, Test Loss: 1.0865
Epoch: 15, Training Loss: 0.9857, Test Loss: 1.0806
Epoch: 16, Training Loss: 0.9866, Test Loss: 1.0732
Epoch: 17, Training Loss: 0.9950, Test Loss: 1.0863
Epoch: 18, Training Loss: 0.9821, Test Loss: 1.0807
Epoch: 19, Training Loss: 0.9872, Test Loss: 1.0843
 20%|███████████████████▌                                                                              | 20/100 [00:01<00:06, 12.22it/s, loss_test=1.084]
Epoch: 20, Training Loss: 0.9838, Test Loss: 1.0795
Epoch: 21, Training Loss: 0.9831, Test Loss: 1.0821
Epoch: 22, Training Loss: 0.9793, Test Loss: 1.0713
Epoch: 23, Training Loss: 0.9837, Test Loss: 1.0762
Epoch: 24, Training Loss: 0.9889, Test Loss: 1.0829
Epoch: 25, Training Loss: 0.9850, Test Loss: 1.0750
Epoch: 26, Training Loss: 0.9829, Test Loss: 1.0912
Epoch: 27, Training Loss: 0.9777, Test Loss: 1.0696
Epoch: 28, Training Loss: 0.9819, Test Loss: 1.0847
Epoch: 29, Training Loss: 0.9790, Test Loss: 1.0688
Epoch: 30, Training Loss: 0.9747, Test Loss: 1.0749
Epoch: 31, Training Loss: 0.9827, Test Loss: 1.0748
Epoch: 32, Training Loss: 0.9768, Test Loss: 1.0732
Epoch: 33, Training Loss: 0.9699, Test Loss: 1.0841
Epoch: 34, Training Loss: 0.9684, Test Loss: 1.0769
Epoch: 35, Training Loss: 0.9601, Test Loss: 1.0600
Epoch: 36, Training Loss: 0.9576, Test Loss: 1.0557
Epoch: 37, Training Loss: 0.9520, Test Loss: 1.0567
Epoch: 38, Training Loss: 0.9417, Test Loss: 1.0292
Epoch: 39, Training Loss: 0.9386, Test Loss: 1.0394
Epoch: 40, Training Loss: 0.9282, Test Loss: 1.0200
Epoch: 41, Training Loss: 0.9170, Test Loss: 1.0073
Epoch: 42, Training Loss: 0.9091, Test Loss: 1.0205

 44%|███████████████████████████████████████████                                                       | 44/100 [00:03<00:04, 11.85it/s, loss_test=0.989]
Epoch: 44, Training Loss: 0.8920, Test Loss: 0.9885
Epoch: 45, Training Loss: 0.8829, Test Loss: 0.9829
Epoch: 46, Training Loss: 0.8810, Test Loss: 0.9735
Epoch: 47, Training Loss: 0.8715, Test Loss: 0.9747
Epoch: 48, Training Loss: 0.8668, Test Loss: 0.9548
Epoch: 49, Training Loss: 0.8554, Test Loss: 0.9527
Epoch: 50, Training Loss: 0.8553, Test Loss: 0.9619
Epoch: 51, Training Loss: 0.8519, Test Loss: 0.9608
Epoch: 52, Training Loss: 0.8409, Test Loss: 0.9366
Epoch: 53, Training Loss: 0.8405, Test Loss: 0.9353
Epoch: 54, Training Loss: 0.8325, Test Loss: 0.9382
Epoch: 55, Training Loss: 0.8278, Test Loss: 0.9419
Epoch: 56, Training Loss: 0.8216, Test Loss: 0.9309
Epoch: 57, Training Loss: 0.8175, Test Loss: 0.9264
Epoch: 58, Training Loss: 0.8125, Test Loss: 0.9225
Epoch: 59, Training Loss: 0.8091, Test Loss: 0.9350
Epoch: 60, Training Loss: 0.8006, Test Loss: 0.9258
Epoch: 61, Training Loss: 0.7970, Test Loss: 0.8982
Epoch: 62, Training Loss: 0.7946, Test Loss: 0.9054
Epoch: 63, Training Loss: 0.7890, Test Loss: 0.9045
Epoch: 64, Training Loss: 0.7844, Test Loss: 0.9073
Epoch: 65, Training Loss: 0.7813, Test Loss: 0.9068
Epoch: 66, Training Loss: 0.7768, Test Loss: 0.9073
Epoch: 67, Training Loss: 0.7746, Test Loss: 0.8915

 68%|██████████████████████████████████████████████████████████████████▋                               | 68/100 [00:05<00:02, 12.21it/s, loss_test=0.907]
Epoch: 69, Training Loss: 0.7634, Test Loss: 0.9147
Epoch: 70, Training Loss: 0.7570, Test Loss: 0.9056
Epoch: 71, Training Loss: 0.7540, Test Loss: 0.9071
Epoch: 72, Training Loss: 0.7524, Test Loss: 0.9057
Epoch: 73, Training Loss: 0.7483, Test Loss: 0.9068
Epoch: 74, Training Loss: 0.7461, Test Loss: 0.8984
Epoch: 75, Training Loss: 0.7394, Test Loss: 0.9078
Epoch: 76, Training Loss: 0.7336, Test Loss: 0.9038
Epoch: 77, Training Loss: 0.7303, Test Loss: 0.8987
Epoch: 78, Training Loss: 0.7293, Test Loss: 0.9042
Epoch: 79, Training Loss: 0.7247, Test Loss: 0.9079
Epoch: 80, Training Loss: 0.7190, Test Loss: 0.8918
Epoch: 81, Training Loss: 0.7167, Test Loss: 0.8968
Epoch: 82, Training Loss: 0.7112, Test Loss: 0.8943
Epoch: 83, Training Loss: 0.7061, Test Loss: 0.9022
Epoch: 84, Training Loss: 0.7060, Test Loss: 0.8972
Epoch: 85, Training Loss: 0.7003, Test Loss: 0.8963
Epoch: 86, Training Loss: 0.6995, Test Loss: 0.8978
Epoch: 87, Training Loss: 0.6945, Test Loss: 0.8890
Epoch: 88, Training Loss: 0.6904, Test Loss: 0.8982
Epoch: 89, Training Loss: 0.6882, Test Loss: 0.9063
Epoch: 90, Training Loss: 0.6845, Test Loss: 0.8935
Epoch: 91, Training Loss: 0.6784, Test Loss: 0.8988


100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.13it/s, loss_test=0.890]
Epoch: 93, Training Loss: 0.6692, Test Loss: 0.8935
Epoch: 94, Training Loss: 0.6671, Test Loss: 0.8902
Epoch: 95, Training Loss: 0.6629, Test Loss: 0.8993
Epoch: 96, Training Loss: 0.6591, Test Loss: 0.9001
Epoch: 97, Training Loss: 0.6577, Test Loss: 0.8916
Epoch: 98, Training Loss: 0.6548, Test Loss: 0.9022
Epoch: 99, Training Loss: 0.6472, Test Loss: 0.8898
Model saved as model_7345471np.pt
Config : {'wandb': True, 'name': 'lstm-enc-dec-0.0001-2-126000-7345471np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 100, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-DATA', 'teacher_forcing_ratio': -4.198030811863873e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9928564310073853, 0.9959112644195557, 0.9930765986442566, 0.9907928466796875, 0.9929111003875732, 0.9918512344360352, 0.9879948496818542, 0.9936605453491211, 0.9870788335800171, 0.9915560603141784, 0.9849887490272522, 0.9919248580932617, 0.9918390035629272, 0.9895723462104797, 0.9884691596031189, 0.9856659650802613, 0.9866078495979309, 0.9949900507926941, 0.9820703744888306, 0.9872285842895507, 0.9838290572166443, 0.9830641865730285, 0.979296350479126, 0.9837466359138489, 0.9889141917228699, 0.9850366473197937, 0.9829158067703248, 0.9777159929275513, 0.9818945288658142, 0.9789557337760926, 0.9746739029884338, 0.9826571106910705, 0.9767768502235412, 0.9699290752410888, 0.9684252738952637, 0.9601048231124878, 0.9576285243034363, 0.9519579887390137, 0.9416962504386902, 0.9385706782341003, 0.9282310009002686, 0.9169897913932801, 0.9091346263885498, 0.896242618560791, 0.8920092105865478, 0.8829004526138305, 0.8810391902923584, 0.8714893460273743, 0.866785192489624, 0.855444860458374, 0.855289626121521, 0.8518779277801514, 0.8409035325050354, 0.8404698252677918, 0.8325038433074952, 0.8278432846069336, 0.821641457080841, 0.8175451278686523, 0.812450110912323, 0.8090752243995667, 0.8006429314613343, 0.7970063805580139, 0.7945734739303589, 0.7890125274658203, 0.7843821167945861, 0.7812936663627624, 0.7767788410186768, 0.774623441696167, 0.767948055267334, 0.7634189486503601, 0.7570232510566711, 0.7540096163749694, 0.7523998022079468, 0.7482875108718872, 0.746132230758667, 0.7393612742424012, 0.7335634112358094, 0.7302583694458008, 0.7293028235435486, 0.7246743679046631, 0.7189583897590637, 0.7166782498359681, 0.711223304271698, 0.7060822725296021, 0.7059602260589599, 0.7002895593643188, 0.6995012640953064, 0.6944987654685975, 0.6904291987419129, 0.6882123112678528, 0.6845123171806335, 0.6783798217773438, 0.6762718558311462, 0.6692001223564148, 0.6671196699142456, 0.6629174828529358, 0.6591118693351745, 0.6576982259750366, 0.6547516703605651, 0.6471914887428284], 'loss_test': [1.089431643486023, 1.0680701732635498, 1.0783714056015015, 1.0853995084762573, 1.076874852180481, 1.0919076204299927, 1.0822598934173584, 1.0786702632904053, 1.0949448347091675, 1.0780034065246582, 1.0840400457382202, 1.0803788900375366, 1.0902013778686523, 1.0900006294250488, 1.0865124464035034, 1.0806386470794678, 1.0731735229492188, 1.0862857103347778, 1.0806605815887451, 1.0843100547790527, 1.0795013904571533, 1.0820561647415161, 1.0712854862213135, 1.076182246208191, 1.082911491394043, 1.075018286705017, 1.0911792516708374, 1.0695550441741943, 1.0847326517105103, 1.0687860250473022, 1.0748636722564697, 1.074752688407898, 1.0731806755065918, 1.084091305732727, 1.0768526792526245, 1.059959053993225, 1.0557454824447632, 1.0567156076431274, 1.0292143821716309, 1.0394442081451416, 1.0200194120407104, 1.0072863101959229, 1.020477533340454, 0.979710578918457, 0.9885311126708984, 0.9828687310218811, 0.9735361933708191, 0.9746814370155334, 0.9547999501228333, 0.9527420997619629, 0.9618603587150574, 0.960760772228241, 0.9365561604499817, 0.9353075623512268, 0.9381739497184753, 0.9419398307800293, 0.9309408664703369, 0.9263979196548462, 0.9225296378135681, 0.9350169897079468, 0.9257585406303406, 0.8981555700302124, 0.9053583741188049, 0.9045223593711853, 0.9072917103767395, 0.9068101644515991, 0.907336950302124, 0.8915490508079529, 0.90706866979599, 0.9147342443466187, 0.9055891633033752, 0.9071068167686462, 0.9057249426841736, 0.9068174958229065, 0.8984451293945312, 0.9077757596969604, 0.903845489025116, 0.8986984491348267, 0.9041576981544495, 0.9079437255859375, 0.8917826414108276, 0.8967838287353516, 0.8942904472351074, 0.9022098183631897, 0.8971928954124451, 0.8962751626968384, 0.89784836769104, 0.8890345692634583, 0.8982483148574829, 0.9063166379928589, 0.8935281038284302, 0.8987653255462646, 0.8858484029769897, 0.8935233354568481, 0.8901760578155518, 0.8993452787399292, 0.9001203775405884, 0.891647219657898, 0.9021903276443481, 0.8898361325263977], 'identifier': '7345471np'}