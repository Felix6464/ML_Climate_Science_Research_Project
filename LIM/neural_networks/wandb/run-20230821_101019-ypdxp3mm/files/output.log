
 20%|███████████████████▌                                                                              | 20/100 [00:01<00:06, 12.11it/s, loss_test=1.074]
Epoch: 00, Training Loss: 0.9955, Test Loss: 1.0869
Epoch: 01, Training Loss: 0.9965, Test Loss: 1.0964
Epoch: 02, Training Loss: 0.9907, Test Loss: 1.0894
Epoch: 03, Training Loss: 0.9922, Test Loss: 1.0927
Epoch: 04, Training Loss: 0.9921, Test Loss: 1.0903
Epoch: 05, Training Loss: 0.9937, Test Loss: 1.0961
Epoch: 06, Training Loss: 0.9888, Test Loss: 1.0992
Epoch: 07, Training Loss: 0.9871, Test Loss: 1.0890
Epoch: 08, Training Loss: 0.9928, Test Loss: 1.0981
Epoch: 09, Training Loss: 0.9852, Test Loss: 1.0952
Epoch: 10, Training Loss: 0.9903, Test Loss: 1.0926
Epoch: 11, Training Loss: 0.9916, Test Loss: 1.0876
Epoch: 12, Training Loss: 0.9925, Test Loss: 1.0998
Epoch: 13, Training Loss: 0.9910, Test Loss: 1.0802
Epoch: 14, Training Loss: 0.9889, Test Loss: 1.0740
Epoch: 15, Training Loss: 0.9855, Test Loss: 1.0822
Epoch: 16, Training Loss: 0.9889, Test Loss: 1.0963
Epoch: 17, Training Loss: 0.9864, Test Loss: 1.0835
Epoch: 18, Training Loss: 0.9871, Test Loss: 1.0755
Epoch: 19, Training Loss: 0.9858, Test Loss: 1.0843
Epoch: 20, Training Loss: 0.9849, Test Loss: 1.0737
Epoch: 21, Training Loss: 0.9862, Test Loss: 1.0857
Epoch: 22, Training Loss: 0.9787, Test Loss: 1.0949
Epoch: 23, Training Loss: 0.9876, Test Loss: 1.0970
Epoch: 24, Training Loss: 0.9823, Test Loss: 1.0729
Epoch: 25, Training Loss: 0.9821, Test Loss: 1.0895
Epoch: 26, Training Loss: 0.9831, Test Loss: 1.0795
Epoch: 27, Training Loss: 0.9757, Test Loss: 1.0766
Epoch: 28, Training Loss: 0.9798, Test Loss: 1.0920
Epoch: 29, Training Loss: 0.9753, Test Loss: 1.0670
Epoch: 30, Training Loss: 0.9765, Test Loss: 1.0701
Epoch: 31, Training Loss: 0.9722, Test Loss: 1.0578
Epoch: 32, Training Loss: 0.9660, Test Loss: 1.0815
Epoch: 33, Training Loss: 0.9623, Test Loss: 1.0652
Epoch: 34, Training Loss: 0.9524, Test Loss: 1.0761
Epoch: 35, Training Loss: 0.9394, Test Loss: 1.0538
Epoch: 36, Training Loss: 0.9378, Test Loss: 1.0477
Epoch: 37, Training Loss: 0.9275, Test Loss: 1.0403
Epoch: 38, Training Loss: 0.9219, Test Loss: 1.0489
Epoch: 39, Training Loss: 0.9167, Test Loss: 1.0272
Epoch: 40, Training Loss: 0.9129, Test Loss: 1.0221
Epoch: 41, Training Loss: 0.9099, Test Loss: 1.0151
Epoch: 42, Training Loss: 0.9008, Test Loss: 1.0248
Epoch: 43, Training Loss: 0.8983, Test Loss: 1.0089

 44%|███████████████████████████████████████████                                                       | 44/100 [00:03<00:04, 11.85it/s, loss_test=0.995]
Epoch: 45, Training Loss: 0.8869, Test Loss: 0.9817
Epoch: 46, Training Loss: 0.8793, Test Loss: 0.9935
Epoch: 47, Training Loss: 0.8767, Test Loss: 0.9856
Epoch: 48, Training Loss: 0.8712, Test Loss: 0.9742
Epoch: 49, Training Loss: 0.8693, Test Loss: 0.9801
Epoch: 50, Training Loss: 0.8634, Test Loss: 0.9604
Epoch: 51, Training Loss: 0.8568, Test Loss: 0.9821
Epoch: 52, Training Loss: 0.8549, Test Loss: 0.9559
Epoch: 53, Training Loss: 0.8471, Test Loss: 0.9548
Epoch: 54, Training Loss: 0.8474, Test Loss: 0.9476
Epoch: 55, Training Loss: 0.8393, Test Loss: 0.9413
Epoch: 56, Training Loss: 0.8350, Test Loss: 0.9455
Epoch: 57, Training Loss: 0.8324, Test Loss: 0.9354
Epoch: 58, Training Loss: 0.8249, Test Loss: 0.9433
Epoch: 59, Training Loss: 0.8239, Test Loss: 0.9430
Epoch: 60, Training Loss: 0.8161, Test Loss: 0.9383
Epoch: 61, Training Loss: 0.8150, Test Loss: 0.9190
Epoch: 62, Training Loss: 0.8093, Test Loss: 0.9323
Epoch: 63, Training Loss: 0.8048, Test Loss: 0.9173
Epoch: 64, Training Loss: 0.8020, Test Loss: 0.9315
Epoch: 65, Training Loss: 0.7985, Test Loss: 0.9222
Epoch: 66, Training Loss: 0.7950, Test Loss: 0.9194
Epoch: 67, Training Loss: 0.7924, Test Loss: 0.9116


 94%|████████████████████████████████████████████████████████████████████████████████████████████      | 94/100 [00:07<00:00, 12.48it/s, loss_test=0.885]
Epoch: 69, Training Loss: 0.7801, Test Loss: 0.8939
Epoch: 70, Training Loss: 0.7762, Test Loss: 0.8998
Epoch: 71, Training Loss: 0.7682, Test Loss: 0.9039
Epoch: 72, Training Loss: 0.7702, Test Loss: 0.8828
Epoch: 73, Training Loss: 0.7616, Test Loss: 0.9093
Epoch: 74, Training Loss: 0.7566, Test Loss: 0.8865
Epoch: 75, Training Loss: 0.7529, Test Loss: 0.8875
Epoch: 76, Training Loss: 0.7468, Test Loss: 0.8882
Epoch: 77, Training Loss: 0.7471, Test Loss: 0.8746
Epoch: 78, Training Loss: 0.7404, Test Loss: 0.8906
Epoch: 79, Training Loss: 0.7355, Test Loss: 0.8885
Epoch: 80, Training Loss: 0.7282, Test Loss: 0.8864
Epoch: 81, Training Loss: 0.7288, Test Loss: 0.8848
Epoch: 82, Training Loss: 0.7249, Test Loss: 0.8909
Epoch: 83, Training Loss: 0.7194, Test Loss: 0.8936
Epoch: 84, Training Loss: 0.7146, Test Loss: 0.8835
Epoch: 85, Training Loss: 0.7105, Test Loss: 0.8768
Epoch: 86, Training Loss: 0.7069, Test Loss: 0.8837
Epoch: 87, Training Loss: 0.7021, Test Loss: 0.8907
Epoch: 88, Training Loss: 0.6976, Test Loss: 0.8923
Epoch: 89, Training Loss: 0.6923, Test Loss: 0.8819
Epoch: 90, Training Loss: 0.6892, Test Loss: 0.8798
Epoch: 91, Training Loss: 0.6893, Test Loss: 0.8828
Epoch: 92, Training Loss: 0.6838, Test Loss: 0.8780

100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.13it/s, loss_test=0.895]
Epoch: 94, Training Loss: 0.6743, Test Loss: 0.8935
Epoch: 95, Training Loss: 0.6697, Test Loss: 0.8888
Epoch: 96, Training Loss: 0.6663, Test Loss: 0.8931
Epoch: 97, Training Loss: 0.6637, Test Loss: 0.8870
Epoch: 98, Training Loss: 0.6581, Test Loss: 0.8890
Epoch: 99, Training Loss: 0.6550, Test Loss: 0.8948
Model saved as model_9840994np.pt
Config : {'wandb': True, 'name': 'lstm-enc-dec-0.0001-2-12140000-9840994np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 100, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-DATA', 'teacher_forcing_ratio': -4.198030811863873e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9954532146453857, 0.9964833378791809, 0.9907170057296752, 0.9922111868858338, 0.9920625448226928, 0.9936807751655579, 0.9887570142745972, 0.9870631217956543, 0.9928248286247253, 0.9851986646652222, 0.9903162837028503, 0.9915711522102356, 0.9924562096595764, 0.9909845590591431, 0.9888581037521362, 0.9854990005493164, 0.988866662979126, 0.9864254355430603, 0.9871364831924438, 0.9857715010643006, 0.9848647713661194, 0.9862155199050904, 0.9787127733230591, 0.9875930666923523, 0.9823058485984802, 0.9820864200592041, 0.9831076264381409, 0.975688362121582, 0.9797575950622559, 0.9753329396247864, 0.9765326619148255, 0.9721565961837768, 0.9659819841384888, 0.9623183488845826, 0.9524158358573913, 0.939369010925293, 0.9378302693367004, 0.9274812579154968, 0.9218917489051819, 0.9167483806610107, 0.9128549814224243, 0.9098930954933167, 0.9008339643478394, 0.8983124017715454, 0.8918824434280396, 0.8869402885437012, 0.8793457865715026, 0.8766624450683593, 0.8711832404136658, 0.8692894816398621, 0.8634018659591675, 0.8568454265594483, 0.854886817932129, 0.8470639109611511, 0.8474255800247192, 0.8393470764160156, 0.8349699974060059, 0.8323642492294312, 0.8248658061027527, 0.8238933563232422, 0.8161014318466187, 0.8150328040122986, 0.8092911005020141, 0.8048267960548401, 0.8020193696022033, 0.7984691500663758, 0.7949960350990295, 0.792433226108551, 0.7850481867790222, 0.7800681114196777, 0.7761657476425171, 0.768171489238739, 0.770228910446167, 0.761594808101654, 0.7566453099250794, 0.7529304265975952, 0.7467958807945252, 0.7470715284347534, 0.7403828501701355, 0.7354910373687744, 0.7282169699668884, 0.7288161039352417, 0.7249380707740783, 0.7194359421730041, 0.714611804485321, 0.7104629278182983, 0.7069194078445434, 0.7020511746406555, 0.6976114630699157, 0.6922936558723449, 0.6892083048820495, 0.6892931342124939, 0.6838077545166016, 0.6772144794464111, 0.6742838859558106, 0.6697012782096863, 0.6662815093994141, 0.663661801815033, 0.6580526828765869, 0.6549897789955139], 'loss_test': [1.0869466066360474, 1.096367597579956, 1.0894496440887451, 1.092679500579834, 1.0902539491653442, 1.0961319208145142, 1.0991597175598145, 1.0889593362808228, 1.0980716943740845, 1.0951975584030151, 1.0925630331039429, 1.0876343250274658, 1.0997645854949951, 1.0802439451217651, 1.073965311050415, 1.0822190046310425, 1.0962698459625244, 1.083458423614502, 1.0755218267440796, 1.0842829942703247, 1.0736632347106934, 1.0857055187225342, 1.0948830842971802, 1.096981406211853, 1.0728753805160522, 1.0894629955291748, 1.079487681388855, 1.0765793323516846, 1.091961145401001, 1.0669876337051392, 1.0700756311416626, 1.0577667951583862, 1.0815465450286865, 1.065197467803955, 1.0761219263076782, 1.0538192987442017, 1.0477246046066284, 1.0402705669403076, 1.048871397972107, 1.0272023677825928, 1.022128939628601, 1.0150574445724487, 1.024778127670288, 1.0088543891906738, 0.9954124689102173, 0.9817496538162231, 0.9935274720191956, 0.9855783581733704, 0.9741777181625366, 0.9801035523414612, 0.9604172110557556, 0.9821372628211975, 0.9558871984481812, 0.954766035079956, 0.9475952386856079, 0.9413276314735413, 0.9454694390296936, 0.935427725315094, 0.9433306455612183, 0.9429600238800049, 0.9383375644683838, 0.9190472364425659, 0.9322788119316101, 0.9173163771629333, 0.9315392374992371, 0.9221553802490234, 0.919350802898407, 0.9116053581237793, 0.8919044137001038, 0.8938903212547302, 0.8997699618339539, 0.9038852453231812, 0.8828293681144714, 0.9092590808868408, 0.886497437953949, 0.8874645233154297, 0.8882187008857727, 0.8746383786201477, 0.8906056880950928, 0.8884700536727905, 0.8864490985870361, 0.8848201632499695, 0.8908741474151611, 0.8936256766319275, 0.8835261464118958, 0.8767910599708557, 0.8836653232574463, 0.8906640410423279, 0.8923447132110596, 0.8818809986114502, 0.8798016905784607, 0.8827871084213257, 0.8779515027999878, 0.88539719581604, 0.8934624791145325, 0.888796865940094, 0.8931257724761963, 0.8869637846946716, 0.888958752155304, 0.8948188424110413], 'identifier': '9840994np'}