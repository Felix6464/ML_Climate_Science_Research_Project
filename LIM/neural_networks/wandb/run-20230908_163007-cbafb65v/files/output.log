
 17%|████████████████                                                                                | 5/30 [00:01<00:08,  2.80it/s, loss_test=1.008]
Epoch: 00, Training Loss: 0.9964, Test Loss: 1.0071
Epoch: 01, Training Loss: 0.9946, Test Loss: 1.0082
Epoch: 02, Training Loss: 0.9938, Test Loss: 1.0070
Epoch: 03, Training Loss: 0.9925, Test Loss: 1.0088

 33%|███████████████████████████████▋                                                               | 10/30 [00:03<00:07,  2.66it/s, loss_test=0.985]
Epoch: 05, Training Loss: 0.9898, Test Loss: 1.0083
Epoch: 06, Training Loss: 0.9880, Test Loss: 1.0058
Epoch: 07, Training Loss: 0.9831, Test Loss: 1.0024
Epoch: 08, Training Loss: 0.9723, Test Loss: 1.0018

 50%|███████████████████████████████████████████████▌                                               | 15/30 [00:05<00:05,  2.57it/s, loss_test=0.895]
Epoch: 10, Training Loss: 0.9190, Test Loss: 0.9632
Epoch: 11, Training Loss: 0.8927, Test Loss: 0.9365
Epoch: 12, Training Loss: 0.8757, Test Loss: 0.9177
Epoch: 13, Training Loss: 0.8621, Test Loss: 0.9053

 67%|███████████████████████████████████████████████████████████████▎                               | 20/30 [00:07<00:04,  2.46it/s, loss_test=0.866]
Epoch: 15, Training Loss: 0.8436, Test Loss: 0.8886
Epoch: 16, Training Loss: 0.8353, Test Loss: 0.8803
Epoch: 17, Training Loss: 0.8287, Test Loss: 0.8764
Epoch: 18, Training Loss: 0.8212, Test Loss: 0.8718

 83%|███████████████████████████████████████████████████████████████████████████████▏               | 25/30 [00:09<00:01,  2.57it/s, loss_test=0.836]
Epoch: 20, Training Loss: 0.8077, Test Loss: 0.8579
Epoch: 21, Training Loss: 0.7990, Test Loss: 0.8559
Epoch: 22, Training Loss: 0.7927, Test Loss: 0.8516
Epoch: 23, Training Loss: 0.7848, Test Loss: 0.8433
Epoch: 24, Training Loss: 0.7768, Test Loss: 0.8363
Epoch: 25, Training Loss: 0.7697, Test Loss: 0.8322
Epoch: 26, Training Loss: 0.7624, Test Loss: 0.8277
Epoch: 27, Training Loss: 0.7552, Test Loss: 0.8210
Epoch: 28, Training Loss: 0.7501, Test Loss: 0.8155

100%|███████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.60it/s, loss_test=0.811]
Model saved as model_9065818np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-124000-9065818np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-30E-HORIZON-DATA', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9963752286774772, 0.9946456863766625, 0.9937831248555865, 0.9925207921436855, 0.9910383707001096, 0.9898369596118018, 0.9879704486756098, 0.9830849170684814, 0.9723333886691502, 0.9506128487132844, 0.9190316909835452, 0.8926540045511155, 0.8757161668368748, 0.8620616793632507, 0.852007249991099, 0.8435671357881456, 0.8352798166729155, 0.8286601021176293, 0.8212244084903172, 0.8155515080406552, 0.8076796105929783, 0.7990319558552333, 0.7926962404024034, 0.7848172074272519, 0.7767600871267772, 0.7696616479328701, 0.7623939258711678, 0.7551849143845695, 0.750075121720632, 0.7429499115262713], 'loss_test': [1.0070733825365703, 1.0081722637017567, 1.0070019662380219, 1.0087825457255046, 1.0078123609224956, 1.0083129107952118, 1.0057590107123058, 1.002413402001063, 1.0018361111481984, 0.9852657914161682, 0.9631940523783366, 0.936544140179952, 0.9176564613978068, 0.9053203066190084, 0.894682248433431, 0.888619065284729, 0.880251814921697, 0.8763957222302755, 0.8717898726463318, 0.8657902280489603, 0.8579345444838206, 0.8559447924296061, 0.8515766660372416, 0.8433007001876831, 0.8363005220890045, 0.8321548600991567, 0.8276920914649963, 0.8209887146949768, 0.8155125280221304, 0.8107597331206003], 'identifier': '9065818np'}