
 10%|███████▊                                                                      | 3/30 [00:01<00:12,  2.24it/s, loss_test=0.966]
Epoch: 00, Training Loss: 1.0116, Test Loss: 0.9630
Epoch: 01, Training Loss: 1.0123, Test Loss: 0.9699
Epoch: 02, Training Loss: 1.0098, Test Loss: 0.9656

 27%|████████████████████▊                                                         | 8/30 [00:03<00:09,  2.27it/s, loss_test=0.975]
Epoch: 04, Training Loss: 1.0074, Test Loss: 0.9707
Epoch: 05, Training Loss: 1.0058, Test Loss: 0.9711
Epoch: 06, Training Loss: 1.0039, Test Loss: 0.9735

 40%|██████████████████████████████▊                                              | 12/30 [00:05<00:08,  2.23it/s, loss_test=0.950]
Epoch: 08, Training Loss: 1.0021, Test Loss: 0.9691
Epoch: 09, Training Loss: 0.9953, Test Loss: 0.9683
Epoch: 10, Training Loss: 0.9834, Test Loss: 0.9662
Epoch: 11, Training Loss: 0.9599, Test Loss: 0.9498

 53%|█████████████████████████████████████████                                    | 16/30 [00:07<00:06,  2.18it/s, loss_test=0.904]
Epoch: 13, Training Loss: 0.9277, Test Loss: 0.9131
Epoch: 14, Training Loss: 0.9199, Test Loss: 0.9090
Epoch: 15, Training Loss: 0.9129, Test Loss: 0.9040

 70%|█████████████████████████████████████████████████████▉                       | 21/30 [00:09<00:04,  2.15it/s, loss_test=0.886]
Epoch: 17, Training Loss: 0.9010, Test Loss: 0.8966
Epoch: 18, Training Loss: 0.8960, Test Loss: 0.8910
Epoch: 19, Training Loss: 0.8910, Test Loss: 0.8911

 83%|████████████████████████████████████████████████████████████████▏            | 25/30 [00:11<00:02,  2.21it/s, loss_test=0.867]
Epoch: 21, Training Loss: 0.8793, Test Loss: 0.8785
Epoch: 22, Training Loss: 0.8728, Test Loss: 0.8762
Epoch: 23, Training Loss: 0.8666, Test Loss: 0.8714
Epoch: 24, Training Loss: 0.8610, Test Loss: 0.8672

100%|█████████████████████████████████████████████████████████████████████████████| 30/30 [00:13<00:00,  2.19it/s, loss_test=0.848]
Epoch: 26, Training Loss: 0.8515, Test Loss: 0.8577
Epoch: 27, Training Loss: 0.8466, Test Loss: 0.8553
Epoch: 28, Training Loss: 0.8411, Test Loss: 0.8546
Epoch: 29, Training Loss: 0.8358, Test Loss: 0.8480
Model saved as model_4567627np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-123000-4567627np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-50E-DATA', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [1.0116085447371006, 1.012340471148491, 1.0097813308238983, 1.0083343349397182, 1.0073663778603077, 1.0058259926736355, 1.0038772001862526, 1.0044018141925335, 1.00211988016963, 0.9953351058065891, 0.9833989515900612, 0.9599118754267693, 0.9410049803555012, 0.9276915863156319, 0.9199373088777065, 0.9129296094179153, 0.907825481146574, 0.9009562507271767, 0.8959839418530464, 0.8910457156598568, 0.8835096433758736, 0.8792533315718174, 0.8728001937270164, 0.8666439466178417, 0.8609635457396507, 0.8558472879230976, 0.8514805026352406, 0.8466467596590519, 0.8410964980721474, 0.8358163237571716], 'loss_test': [0.962985560297966, 0.9699184149503708, 0.965635359287262, 0.9695561826229095, 0.97072733938694, 0.9710779786109924, 0.973477691411972, 0.9751654714345932, 0.969131350517273, 0.9682511538267136, 0.9661908596754074, 0.9497679471969604, 0.929401770234108, 0.9130683094263077, 0.9090036451816559, 0.9039951115846634, 0.8997583091259003, 0.8966260850429535, 0.8910419642925262, 0.8911154121160507, 0.8861769437789917, 0.8785030990839005, 0.8762158751487732, 0.8714324533939362, 0.8671813011169434, 0.863146185874939, 0.8576529771089554, 0.8552671074867249, 0.8545901626348495, 0.8480485081672668], 'identifier': '4567627np'}