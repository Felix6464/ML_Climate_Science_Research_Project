
 13%|█████████▏                                                           | 4/30 [00:01<00:11,  2.35it/s, loss_test=0.973]
Epoch: 00, Training Loss: 1.0038, Test Loss: 0.9793
Epoch: 01, Training Loss: 1.0017, Test Loss: 0.9770
Epoch: 02, Training Loss: 1.0009, Test Loss: 0.9738

 27%|██████████████████▍                                                  | 8/30 [00:03<00:10,  2.19it/s, loss_test=0.933]
Epoch: 04, Training Loss: 0.9959, Test Loss: 0.9742
Epoch: 05, Training Loss: 0.9899, Test Loss: 0.9706
Epoch: 06, Training Loss: 0.9689, Test Loss: 0.9587

 40%|███████████████████████████▏                                        | 12/30 [00:05<00:08,  2.19it/s, loss_test=0.865]
Epoch: 08, Training Loss: 0.9203, Test Loss: 0.9061
Epoch: 09, Training Loss: 0.9048, Test Loss: 0.8884
Epoch: 10, Training Loss: 0.8899, Test Loss: 0.8744
Epoch: 11, Training Loss: 0.8735, Test Loss: 0.8653

 57%|██████████████████████████████████████▌                             | 17/30 [00:07<00:05,  2.22it/s, loss_test=0.824]
Epoch: 13, Training Loss: 0.8503, Test Loss: 0.8463
Epoch: 14, Training Loss: 0.8419, Test Loss: 0.8403
Epoch: 15, Training Loss: 0.8330, Test Loss: 0.8344

 70%|███████████████████████████████████████████████▌                    | 21/30 [00:09<00:04,  2.12it/s, loss_test=0.798]
Epoch: 17, Training Loss: 0.8156, Test Loss: 0.8168
Epoch: 18, Training Loss: 0.8068, Test Loss: 0.8162
Epoch: 19, Training Loss: 0.7976, Test Loss: 0.8056

 83%|████████████████████████████████████████████████████████▋           | 25/30 [00:11<00:02,  2.17it/s, loss_test=0.770]
Epoch: 21, Training Loss: 0.7786, Test Loss: 0.7944
Epoch: 22, Training Loss: 0.7696, Test Loss: 0.7856
Epoch: 23, Training Loss: 0.7605, Test Loss: 0.7815
Epoch: 24, Training Loss: 0.7524, Test Loss: 0.7701

100%|████████████████████████████████████████████████████████████████████| 30/30 [00:13<00:00,  2.19it/s, loss_test=0.751]
Epoch: 26, Training Loss: 0.7385, Test Loss: 0.7613
Epoch: 27, Training Loss: 0.7320, Test Loss: 0.7619
Epoch: 28, Training Loss: 0.7263, Test Loss: 0.7575
Epoch: 29, Training Loss: 0.7206, Test Loss: 0.7515
Model saved as model_5242218np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-125000-5242218np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-50E-DATA', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [1.003846925717813, 1.0017252939718742, 1.000929918554094, 0.998622801568773, 0.9958711023683902, 0.9899306142771686, 0.9688771344997265, 0.9398205876350403, 0.9202680102101078, 0.904814565623248, 0.8898513736548247, 0.8734558003920095, 0.8611154997790301, 0.8502549330393473, 0.8419325020578172, 0.8330071082821598, 0.8244885471132066, 0.8155800501505533, 0.8067956368128458, 0.7976056160750212, 0.788259278844904, 0.7785932885275947, 0.7695526944266425, 0.7604893070680124, 0.7523771502353527, 0.7447064651383294, 0.7384786053940102, 0.7319664579850657, 0.7262514211513378, 0.7205812467469109], 'loss_test': [0.9793448533330645, 0.9770329254014152, 0.9737542867660522, 0.9733620626585824, 0.9742267046655927, 0.9705512779099601, 0.9587337970733643, 0.9332017387662616, 0.9060899700437274, 0.8884435040610177, 0.8744449189731053, 0.8652670128004891, 0.8531459825379508, 0.846306962626321, 0.8403464896338326, 0.8343584963253566, 0.8237376298223223, 0.8167660662106105, 0.8162321533475604, 0.8056406038148063, 0.7975130592073713, 0.7944078530584063, 0.7855935096740723, 0.7815216864858355, 0.7701108370508466, 0.76961806842259, 0.7612777096884591, 0.7619048016411918, 0.7575471826962062, 0.7514829380171639], 'identifier': '5242218np'}