
 20%|███████████████████▌                                                                              | 20/100 [00:01<00:06, 12.49it/s, loss_test=1.088]
Epoch: 00, Training Loss: 0.9963, Test Loss: 1.0706
Epoch: 01, Training Loss: 0.9891, Test Loss: 1.0936
Epoch: 02, Training Loss: 0.9911, Test Loss: 1.0855
Epoch: 03, Training Loss: 0.9871, Test Loss: 1.0857
Epoch: 04, Training Loss: 0.9910, Test Loss: 1.0716
Epoch: 05, Training Loss: 0.9925, Test Loss: 1.0876
Epoch: 06, Training Loss: 0.9935, Test Loss: 1.0749
Epoch: 07, Training Loss: 0.9917, Test Loss: 1.0817
Epoch: 08, Training Loss: 0.9851, Test Loss: 1.0773
Epoch: 09, Training Loss: 0.9874, Test Loss: 1.0815
Epoch: 10, Training Loss: 0.9861, Test Loss: 1.0825
Epoch: 11, Training Loss: 0.9880, Test Loss: 1.0818
Epoch: 12, Training Loss: 0.9842, Test Loss: 1.0695
Epoch: 13, Training Loss: 0.9874, Test Loss: 1.0764
Epoch: 14, Training Loss: 0.9849, Test Loss: 1.0887
Epoch: 15, Training Loss: 0.9792, Test Loss: 1.0813
Epoch: 16, Training Loss: 0.9851, Test Loss: 1.0780
Epoch: 17, Training Loss: 0.9872, Test Loss: 1.0789
Epoch: 18, Training Loss: 0.9861, Test Loss: 1.0775
Epoch: 19, Training Loss: 0.9846, Test Loss: 1.0686

 44%|███████████████████████████████████████████                                                       | 44/100 [00:03<00:04, 12.29it/s, loss_test=0.988]
Epoch: 21, Training Loss: 0.9795, Test Loss: 1.0793
Epoch: 22, Training Loss: 0.9850, Test Loss: 1.0652
Epoch: 23, Training Loss: 0.9794, Test Loss: 1.1009
Epoch: 24, Training Loss: 0.9870, Test Loss: 1.0759
Epoch: 25, Training Loss: 0.9810, Test Loss: 1.0814
Epoch: 26, Training Loss: 0.9818, Test Loss: 1.0887
Epoch: 27, Training Loss: 0.9829, Test Loss: 1.0829
Epoch: 28, Training Loss: 0.9820, Test Loss: 1.0730
Epoch: 29, Training Loss: 0.9726, Test Loss: 1.0801
Epoch: 30, Training Loss: 0.9693, Test Loss: 1.0794
Epoch: 31, Training Loss: 0.9708, Test Loss: 1.0833
Epoch: 32, Training Loss: 0.9631, Test Loss: 1.0678
Epoch: 33, Training Loss: 0.9517, Test Loss: 1.0558
Epoch: 34, Training Loss: 0.9458, Test Loss: 1.0699
Epoch: 35, Training Loss: 0.9343, Test Loss: 1.0516
Epoch: 36, Training Loss: 0.9272, Test Loss: 1.0292
Epoch: 37, Training Loss: 0.9165, Test Loss: 1.0387
Epoch: 38, Training Loss: 0.9110, Test Loss: 1.0363
Epoch: 39, Training Loss: 0.9061, Test Loss: 1.0008
Epoch: 40, Training Loss: 0.9050, Test Loss: 1.0111
Epoch: 41, Training Loss: 0.8947, Test Loss: 1.0057
Epoch: 42, Training Loss: 0.8899, Test Loss: 1.0097
Epoch: 43, Training Loss: 0.8894, Test Loss: 0.9989
Epoch: 44, Training Loss: 0.8842, Test Loss: 0.9931
Epoch: 45, Training Loss: 0.8770, Test Loss: 0.9881
Epoch: 46, Training Loss: 0.8737, Test Loss: 0.9812
Epoch: 47, Training Loss: 0.8699, Test Loss: 0.9898
Epoch: 48, Training Loss: 0.8612, Test Loss: 0.9646
Epoch: 49, Training Loss: 0.8596, Test Loss: 0.9901
Epoch: 50, Training Loss: 0.8557, Test Loss: 0.9744
Epoch: 51, Training Loss: 0.8501, Test Loss: 0.9580
Epoch: 52, Training Loss: 0.8431, Test Loss: 0.9614
Epoch: 53, Training Loss: 0.8433, Test Loss: 0.9626
Epoch: 54, Training Loss: 0.8388, Test Loss: 0.9759
Epoch: 55, Training Loss: 0.8323, Test Loss: 0.9481
Epoch: 56, Training Loss: 0.8288, Test Loss: 0.9343
Epoch: 57, Training Loss: 0.8277, Test Loss: 0.9595
Epoch: 58, Training Loss: 0.8221, Test Loss: 0.9503
Epoch: 59, Training Loss: 0.8169, Test Loss: 0.9534
Epoch: 60, Training Loss: 0.8153, Test Loss: 0.9367
Epoch: 61, Training Loss: 0.8109, Test Loss: 0.9471
Epoch: 62, Training Loss: 0.8063, Test Loss: 0.9370
Epoch: 63, Training Loss: 0.8035, Test Loss: 0.9228
Epoch: 64, Training Loss: 0.7973, Test Loss: 0.9266
Epoch: 65, Training Loss: 0.7949, Test Loss: 0.9277
Epoch: 66, Training Loss: 0.7918, Test Loss: 0.9128
Epoch: 67, Training Loss: 0.7893, Test Loss: 0.9224
Epoch: 68, Training Loss: 0.7827, Test Loss: 0.9326

 70%|████████████████████████████████████████████████████████████████████▌                             | 70/100 [00:05<00:02, 11.78it/s, loss_test=0.937]
Epoch: 70, Training Loss: 0.7753, Test Loss: 0.9132
Epoch: 71, Training Loss: 0.7704, Test Loss: 0.9246
Epoch: 72, Training Loss: 0.7655, Test Loss: 0.9129
Epoch: 73, Training Loss: 0.7632, Test Loss: 0.9054
Epoch: 74, Training Loss: 0.7570, Test Loss: 0.9118
Epoch: 75, Training Loss: 0.7508, Test Loss: 0.8969
Epoch: 76, Training Loss: 0.7502, Test Loss: 0.9122
Epoch: 77, Training Loss: 0.7421, Test Loss: 0.9047
Epoch: 78, Training Loss: 0.7414, Test Loss: 0.9158
Epoch: 79, Training Loss: 0.7362, Test Loss: 0.9002
Epoch: 80, Training Loss: 0.7298, Test Loss: 0.9070
Epoch: 81, Training Loss: 0.7271, Test Loss: 0.9041
Epoch: 82, Training Loss: 0.7231, Test Loss: 0.9154
Epoch: 83, Training Loss: 0.7158, Test Loss: 0.8959
Epoch: 84, Training Loss: 0.7124, Test Loss: 0.8930
Epoch: 85, Training Loss: 0.7092, Test Loss: 0.9093
Epoch: 86, Training Loss: 0.7053, Test Loss: 0.9061
Epoch: 87, Training Loss: 0.6997, Test Loss: 0.8999
Epoch: 88, Training Loss: 0.6988, Test Loss: 0.9028
Epoch: 89, Training Loss: 0.6943, Test Loss: 0.8989
Epoch: 90, Training Loss: 0.6888, Test Loss: 0.9042
Epoch: 91, Training Loss: 0.6821, Test Loss: 0.8882
Epoch: 92, Training Loss: 0.6804, Test Loss: 0.9034


100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.10it/s, loss_test=0.899]
Epoch: 94, Training Loss: 0.6754, Test Loss: 0.8960
Epoch: 95, Training Loss: 0.6708, Test Loss: 0.8940
Epoch: 96, Training Loss: 0.6670, Test Loss: 0.8883
Epoch: 97, Training Loss: 0.6645, Test Loss: 0.8866
Epoch: 98, Training Loss: 0.6604, Test Loss: 0.9066
Epoch: 99, Training Loss: 0.6561, Test Loss: 0.8985
Model saved as model_6937475np.pt
Config : {'wandb': True, 'name': 'lstm-enc-dec-0.0001-2-123000-6937475np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 100, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-DATA', 'teacher_forcing_ratio': -4.198030811863873e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.99630206823349, 0.9890681147575379, 0.9910598278045655, 0.9871464133262634, 0.9909678339958191, 0.9924890041351319, 0.993529987335205, 0.9916653990745544, 0.9851445436477662, 0.9873965859413147, 0.9860991954803466, 0.9880311727523804, 0.9841874241828918, 0.9874203681945801, 0.9848786234855652, 0.9792052388191224, 0.9851083040237427, 0.9872141361236573, 0.986086654663086, 0.9845679044723511, 0.9833887577056885, 0.9794899582862854, 0.9850343585014343, 0.9793596506118775, 0.986995530128479, 0.9809808254241943, 0.9817728281021119, 0.9828724503517151, 0.9820046186447143, 0.9725710868835449, 0.9693190693855286, 0.9707884788513184, 0.963097608089447, 0.9516916871070862, 0.9458041310310363, 0.9343444585800171, 0.9272361159324646, 0.9165402412414551, 0.9110439777374267, 0.9060643196105957, 0.9050083160400391, 0.8947048902511596, 0.8898719549179077, 0.8894421935081482, 0.8842210650444031, 0.8770019888877869, 0.8737212896347046, 0.8698879599571228, 0.8611603140830993, 0.8595856189727783, 0.8556827187538147, 0.8500596284866333, 0.8431012868881226, 0.8432629108428955, 0.838845682144165, 0.8322578310966492, 0.8288342118263244, 0.8276974320411682, 0.8220554471015931, 0.8169212698936462, 0.8153215885162354, 0.8108547329902649, 0.8062628149986267, 0.8034643650054931, 0.7973085880279541, 0.7948557615280152, 0.7917574048042297, 0.7892764449119568, 0.7826663017272949, 0.778303074836731, 0.7753164172172546, 0.7704010844230652, 0.7654648423194885, 0.7632420778274536, 0.7570204019546509, 0.7508342146873475, 0.7502042412757873, 0.7421497225761413, 0.7413928627967834, 0.7361980676651001, 0.7298102259635926, 0.7270572066307068, 0.7231316328048706, 0.7158165335655212, 0.712371551990509, 0.709160041809082, 0.7053439974784851, 0.6996828079223633, 0.6987576007843017, 0.6943087577819824, 0.6887683033943176, 0.6820829749107361, 0.6804067730903626, 0.6786558747291564, 0.6753663301467896, 0.6707602500915527, 0.6670473933219909, 0.6644755959510803, 0.6604389071464538, 0.6561261177062988], 'loss_test': [1.0705578327178955, 1.0935652256011963, 1.0854538679122925, 1.0857089757919312, 1.0715638399124146, 1.0876413583755493, 1.0749257802963257, 1.0816570520401, 1.0772851705551147, 1.0814619064331055, 1.0825014114379883, 1.0818315744400024, 1.069481611251831, 1.076366662979126, 1.0886732339859009, 1.0812759399414062, 1.0779643058776855, 1.0788588523864746, 1.0774564743041992, 1.0685768127441406, 1.088370680809021, 1.0793228149414062, 1.0652244091033936, 1.1009033918380737, 1.07587468624115, 1.0813733339309692, 1.088669776916504, 1.0828988552093506, 1.0729516744613647, 1.080139398574829, 1.079382061958313, 1.0833293199539185, 1.067785382270813, 1.055788516998291, 1.0699125528335571, 1.0516456365585327, 1.0292322635650635, 1.0387310981750488, 1.0362896919250488, 1.0007975101470947, 1.0111331939697266, 1.0056806802749634, 1.0097171068191528, 0.99887615442276, 0.9930837154388428, 0.9880847930908203, 0.9811678528785706, 0.9898120760917664, 0.9645857214927673, 0.9900869727134705, 0.9743937253952026, 0.9579924941062927, 0.9614329934120178, 0.9625800251960754, 0.97592693567276, 0.9481136798858643, 0.9343355894088745, 0.9594581127166748, 0.950259268283844, 0.9533634185791016, 0.9366748332977295, 0.9471179842948914, 0.9369825720787048, 0.9227812886238098, 0.926618218421936, 0.9276508092880249, 0.9128244519233704, 0.9223887324333191, 0.932572603225708, 0.9370463490486145, 0.913154125213623, 0.9245883822441101, 0.9128504395484924, 0.90535569190979, 0.9117644429206848, 0.8969302773475647, 0.9121504426002502, 0.9047173857688904, 0.9158130288124084, 0.9002377390861511, 0.9069671630859375, 0.9041014313697815, 0.9153549671173096, 0.8958944082260132, 0.8930416107177734, 0.909287691116333, 0.9061254262924194, 0.8998547196388245, 0.9028130769729614, 0.8989413976669312, 0.9042283892631531, 0.8881533741950989, 0.9033820629119873, 0.9032437205314636, 0.8959878087043762, 0.8940017819404602, 0.8882548213005066, 0.8866090774536133, 0.9065746665000916, 0.8985369801521301], 'identifier': '6937475np'}