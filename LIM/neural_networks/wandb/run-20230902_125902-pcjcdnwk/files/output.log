

  3%|███                                                                                       | 1/30 [00:08<04:16,  8.84s/it, loss_test=1.006]

  7%|██████                                                                                    | 2/30 [00:17<04:12,  9.01s/it, loss_test=0.809]

 10%|█████████                                                                                 | 3/30 [00:26<04:02,  8.98s/it, loss_test=0.726]

 13%|████████████                                                                              | 4/30 [00:35<03:52,  8.96s/it, loss_test=0.676]

 17%|███████████████                                                                           | 5/30 [00:44<03:45,  9.02s/it, loss_test=0.652]

 20%|██████████████████                                                                        | 6/30 [00:53<03:35,  8.96s/it, loss_test=0.638]

 23%|█████████████████████                                                                     | 7/30 [01:02<03:27,  9.01s/it, loss_test=0.629]

 27%|████████████████████████                                                                  | 8/30 [01:11<03:15,  8.90s/it, loss_test=0.622]
Epoch: 07, Training Loss: 0.6115, Test Loss: 0.6220


 33%|█████████████████████████████▋                                                           | 10/30 [01:29<02:56,  8.85s/it, loss_test=0.612]

 37%|████████████████████████████████▋                                                        | 11/30 [01:38<02:49,  8.92s/it, loss_test=0.609]

 40%|███████████████████████████████████▌                                                     | 12/30 [01:47<02:41,  8.98s/it, loss_test=0.605]
Epoch: 11, Training Loss: 0.5946, Test Loss: 0.6050


 47%|█████████████████████████████████████████▌                                               | 14/30 [02:05<02:24,  9.04s/it, loss_test=0.601]
Epoch: 13, Training Loss: 0.5894, Test Loss: 0.6007


 53%|███████████████████████████████████████████████▍                                         | 16/30 [02:23<02:05,  8.93s/it, loss_test=0.597]

 57%|██████████████████████████████████████████████████▍                                      | 17/30 [02:31<01:54,  8.79s/it, loss_test=0.595]

 60%|█████████████████████████████████████████████████████▍                                   | 18/30 [02:40<01:44,  8.74s/it, loss_test=0.594]
Epoch: 17, Training Loss: 0.5825, Test Loss: 0.5943


 67%|███████████████████████████████████████████████████████████▎                             | 20/30 [02:57<01:26,  8.66s/it, loss_test=0.593]

 70%|██████████████████████████████████████████████████████████████▎                          | 21/30 [03:06<01:17,  8.66s/it, loss_test=0.592]

 73%|█████████████████████████████████████████████████████████████████▎                       | 22/30 [03:15<01:09,  8.75s/it, loss_test=0.591]

 77%|████████████████████████████████████████████████████████████████████▏                    | 23/30 [03:23<01:01,  8.72s/it, loss_test=0.591]
Epoch: 22, Training Loss: 0.5771, Test Loss: 0.5905


 83%|██████████████████████████████████████████████████████████████████████████▏              | 25/30 [03:41<00:44,  8.87s/it, loss_test=0.589]

 87%|█████████████████████████████████████████████████████████████████████████████▏           | 26/30 [03:50<00:35,  8.78s/it, loss_test=0.589]
Epoch: 25, Training Loss: 0.5749, Test Loss: 0.5891


 93%|███████████████████████████████████████████████████████████████████████████████████      | 28/30 [04:07<00:17,  8.75s/it, loss_test=0.589]
Epoch: 27, Training Loss: 0.5736, Test Loss: 0.5887


100%|█████████████████████████████████████████████████████████████████████████████████████████| 30/30 [04:25<00:00,  8.85s/it, loss_test=0.589]
Epoch: 29, Training Loss: 0.5726, Test Loss: 0.5886
Model saved as model_3684351np.pt
Config : {'wandb': True, 'name': 'lstm_enc_dec-0.0001-2-12100000-3684351np', 'num_features': 30, 'hidden_size': 128, 'dropout': 0, 'weight_decay': 0, 'input_window': 2, 'output_window': 12, 'learning_rate': 0.0001, 'num_layers': 1, 'num_epochs': 30, 'batch_size': 128, 'train_data_len': 200000, 'training_prediction': 'recursive', 'loss_type': 'MSE', 'model_label': 'ENC-DEC-SPREAD', 'teacher_forcing_ratio': -3.0878077872387166e-16, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 1932, 'num_of_params': 217886, 'loss_train': [0.9080198104783292, 0.7617923625004597, 0.6921613661797492, 0.657113526330326, 0.6384570665193565, 0.6266540140459389, 0.6180683517412389, 0.6114847210300711, 0.6062322526406019, 0.6017890206841758, 0.5979525171793424, 0.5945725521761855, 0.5917793413003286, 0.5893802646097246, 0.5873187321882981, 0.5855532042927795, 0.5839040831768469, 0.5825171171527206, 0.5812243044158041, 0.5800918885421403, 0.578936136795051, 0.5779843984287737, 0.5771270907405532, 0.5762237834406423, 0.5755080624377771, 0.5748510262468359, 0.5741715204148066, 0.5736054099086441, 0.5731082532432054, 0.5726463204120105], 'loss_test': [1.0058538634807637, 0.8094983754249719, 0.7261166912622941, 0.6762493034968009, 0.6517652991490487, 0.6382921857711596, 0.6290060912187283, 0.6220319316937373, 0.6162179792538668, 0.6121644561107342, 0.6086048919420975, 0.6049519658852847, 0.6025422490560092, 0.600670670469602, 0.5986555975217086, 0.5969231999837435, 0.5954047926725485, 0.5943359388754919, 0.5933651939416543, 0.5927611440420151, 0.591824831870886, 0.5913445980120928, 0.5905005568877245, 0.5903471437020179, 0.589460191436303, 0.5890749371968783, 0.5889382400573828, 0.5886792410642673, 0.588462389432467, 0.5886088395730044], 'identifier': '3684351np'}