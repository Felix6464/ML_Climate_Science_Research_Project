{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import utils as ut\n",
    "import LIM_class\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import itertools\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "plt.style.use(\"../plotting.mplstyle\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "outputs": [],
   "source": [
    "data = xr.open_dataset(\"./data/ts_Amon_CESM2_piControl_r1i1p1f1.nc\")[\"ts\"]\n",
    "#data = xr.open_dataset(\"./data/zos_Amon_CESM2_piControl_r1i1p1f1.nc\")[\"zos\"]\n",
    "#data_old = xr.open_dataset(\"./data/ssta_1950_2021.nc\")[\"ssta\"]\n",
    "mask = xr.open_dataset(\"./data/sftlf_fx_CESM2_historical_r1i1p1f1.nc\")[\"sftlf\"]\n",
    "\n",
    "#14400 orginial size\n",
    "data = data[:1000, :, :]\n",
    "\n",
    "data = ut.apply_mask(mask, data)\n",
    "#print(\"Data : {} + shape {}\".format(data, data.shape))\n",
    "\n",
    "data_anomalies = ut.calculate_monthly_anomalies(data)\n",
    "#print(\"Month mean : {} + shape : {}\".format(data_anomalies, data_anomalies.shape))\n",
    "\n",
    "data_cropped =ut.crop_xarray(data_anomalies)\n",
    "#print(\"Data cropped : {} + shape : {}\".format(data_cropped, data_cropped.shape))\n",
    "\n",
    "\n",
    "pca_10 = ut.SpatioTemporalPCA(data_cropped, n_components=20)\n",
    "#pca_10 = ut.SpatioTemporalPCA(data_anomalies, n_components=20)\n",
    "eof_10 = pca_10.eofs()\n",
    "pc_10 = pca_10.principal_components()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Covariance matrix has negative values!\n"
     ]
    }
   ],
   "source": [
    "# Create training and test data\n",
    "data = pca_10.principal_components()\n",
    "index_train = int(0.8 * len(data[\"time\"]))\n",
    "data_train = data[:, :index_train]\n",
    "data_test = data[:, index_train:]\n",
    "\n",
    "# Creating an example LIM object\n",
    "tau = 1\n",
    "model = LIM_class.LIM(tau)\n",
    "model.fit(data_train.data)\n",
    "#print(\"Data train : {} + shape: {} + type: {}\".format(data_train.data[:5], data_train.data.shape, type(data_train.data)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data : [[ 11.683785    15.96394     18.439566   ... -22.256952   -15.723967\n",
      "   -5.0476418 ]\n",
      " [-15.7863245  -14.464781    -7.952202   ...  14.711998    17.332537\n",
      "   17.448133  ]\n",
      " [ -2.649037     4.804161     4.3103786  ... -13.695016   -17.783976\n",
      "  -18.565268  ]\n",
      " ...\n",
      " [ -2.7199492   -1.5206968   -0.4635413  ...   1.8401012    1.5570866\n",
      "    3.420623  ]\n",
      " [  0.39527023   2.331261     2.800027   ...   0.04977342  -2.955885\n",
      "   -2.7341406 ]\n",
      " [  2.1327453   -2.886382     0.02464208 ...  -1.5233226    0.24590252\n",
      "   -0.606391  ]] + shape: (20, 1000) + type: <class 'numpy.ndarray'>\n",
      "Testing parameter combination 1/4: (32, 0.01, 3000)\n",
      "Epoch [1/3000], Loss: 51.331617184432154\n",
      "Epoch [101/3000], Loss: 42.50839155792711\n",
      "Epoch [201/3000], Loss: 46.79941790697565\n",
      "Epoch [301/3000], Loss: 46.65927815437317\n",
      "Epoch [401/3000], Loss: 46.660426543898375\n",
      "Epoch [501/3000], Loss: 46.66170070736284\n",
      "Epoch [601/3000], Loss: 46.662495964502234\n"
     ]
    }
   ],
   "source": [
    "from FNN_model import *\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def hyperparameter_training_loop(dataloader, input_size, output_size):\n",
    "\n",
    "    # Generate all possible combinations of hyperparameters\n",
    "    combinations = list(itertools.product(*hyperparams.values()))\n",
    "\n",
    "    overall_best_model = {\"hidden_size\": None,\n",
    "                         \"learning_rate\": None,\n",
    "                         \"num_epochs\": None,\n",
    "                         \"loss\": float('inf')}\n",
    "\n",
    "    # Iterate over each hyperparameter combination\n",
    "    for i, params in enumerate(combinations):\n",
    "        print(f\"Testing parameter combination {i+1}/{len(combinations)}: {params}\")\n",
    "\n",
    "        hidden_size = params[0]\n",
    "        learning_rate = params[1]\n",
    "        num_epochs = params[2]\n",
    "\n",
    "        # Train the model\n",
    "        model = FeedforwardNetwork(input_size, hidden_size, output_size)\n",
    "        losses = train(model, dataloader, num_epochs, learning_rate, input_size)\n",
    "\n",
    "        # Save the model and hyperparameters to a file\n",
    "        result = {\n",
    "            'hyperparameters': {\n",
    "                'hidden_size': params[0],\n",
    "                'learning_rate': params[1],\n",
    "                'num_epochs': params[2],\n",
    "                'best_loss': losses[-1],\n",
    "                \"losses\": losses,\n",
    "            }\n",
    "        }\n",
    "        if losses[-1] < overall_best_model[\"loss\"]:\n",
    "            overall_best_model[\"hidden_size\"] = params[0]\n",
    "            overall_best_model[\"learning_rate\"] = params[1]\n",
    "            overall_best_model[\"num_epochs\"] = params[2]\n",
    "            overall_best_model[\"loss\"] = losses[-1]\n",
    "            overall_best_model[\"losses\"] = losses\n",
    "\n",
    "        filename = f\"./model_trained/fnn_model_{i+1}.pt\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(result, f)\n",
    "\n",
    "        print(f\"Saved model and hyperparameters to {filename}\\n\")\n",
    "\n",
    "    return overall_best_model\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "sequence_length = 4\n",
    "\n",
    "# Create the DataLoader for first principal component\n",
    "data = np.array(data)[:, :1000]\n",
    "print(\"Data : {} + shape: {} + type: {}\".format(data, data.shape, type(data)))\n",
    "dataloader = create_dataloader(data, batch_size, sequence_length)\n",
    "\n",
    "# Hyperparameter search space\n",
    "hyperparams = {\n",
    "    'hidden_size': [32, 64],\n",
    "    'learning_rate': [0.01, 0.001],\n",
    "    'num_epochs': [3000]\n",
    "}\n",
    "\n",
    "#Train the model\n",
    "input_size =  data.shape[0] * sequence_length\n",
    "output_size = data.shape[0] * 1\n",
    "\n",
    "#print(\"Input size : {}\".format(input_size))\n",
    "#train(model, dataloader, num_epochs, learning_rate)\n",
    "best_model = hyperparameter_training_loop(dataloader, input_size, output_size)\n",
    "\n",
    "print(f\"Best model: {best_model}\")\n",
    "#plot_loss_evolution(best_model[\"losses\"], np.arange(0,best_model[\"num_epochs\"], dtype=int), best_model[\"learning_rate\"], best_model[\"hidden_size\"])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}